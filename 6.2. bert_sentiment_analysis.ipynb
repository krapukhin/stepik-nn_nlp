{"cells":[{"cell_type":"markdown","metadata":{"id":"jNKaJz5j_ylj"},"source":["# Определение эмоциональной окраски твитов с помощью BERT"]},{"cell_type":"markdown","metadata":{"id":"4bxBeSWsuEN0"},"source":["Решим достаточно простую, но интересную задачу: будем определять эмоциональную окраску твитов с помощью BERT. Для дообучения BERT на такую простую задачу не потребуется много вычислительных ресурсов — при желании, можно дообучить сеть даже на CPU. Итак, мы возьмём предобученный BERT и добавим к нему слой нейронов, чтобы обучить полученную модель для классификации предложений. Возникает резонный вопрос — если, в среднем, файнтюнинг BERT занимает много времени и много ресурсов, зачем же нам это нужно, если можно взять, и с нуля обучить какую-нибудь сеть (например, LSTM) для решения той же самой задачи? Давайте отвечать на этот вопрос постепенно. Во-первых, веса BERT уже содержат много информации о том, как устроен язык. А значит, на файнтюнинг модели уйдёт совсем немного времени. Авторы статьи про BERT советуют запускать всего от двух до четырёх эпох, чтобы получить хороший результат. Кроме того, для файнтюринга нам нужно достаточно мало данных — небольшого количества данных, зачастую, оказывается достаточно, чтобы получить хорошие результаты. Ну, ещё одна причина немаловажная. Один и тот же BERT (одну и ту же сеть с одними и теми же весами) можно использовать как основу для дообучения для совершенно разных задач, начиная от классификации и заканчивая вопросно-ответными системами или машинным переводом, или чем-то ещё. "]},{"cell_type":"markdown","metadata":{"id":"VqgifyduuEN1"},"source":["Немного повторим теорию про BERT. Выберите правильные утверждения:\n","\n","-BERT обучается только на задаче маскированного языкового моделирования: 15 процентов токенов заменяются на токен [MASK] (эти выбираются произвольно), а BERT пытается предсказать эти слова, учитывая немаскированный контекст\n","\n","-Для каждого языка нужно использовать особую версию BERT, предобученную на текстах, написанных только на выбранном языке\n","\n","-Для решения задач классификации текстов и перевода предложений с английского на русский нужно обязательно использовать разные предобученные модели, так как задачи сильно отличаются друг от друга\n","\n","+Во время обучения BERT используется два подхода: маскированное языковое моделирование (Mask Language Model) и определение, является ли второе предложение логически связанным с первым (Next Sentence Prediction)"]},{"cell_type":"markdown","metadata":{"id":"g2aoc8-5uEN1"},"source":["Сегодня мы не будем кодить руками обучение BERT, а покажем, как, максимально просто, максимально быстро, найти готовый предобученный BERT и, минимальным количеством кода, дофайнтюнить его для решения вашей задачи. Это значит что мы будем использовать готовые библиотеки. Одна из них называется pytorch-transformers. В ней есть pytorch-интерфейс BERT, а также в этой библиотеке есть удобные обёртки и для других популярных моделей (например, для XL трансформера, или GPT-2, или каких-то других моделей — например, для RoBERTa[2]). На сегодняшний день, пожалуй, эта библиотека является самой популярной обёрткой для удобного использования BERT. Ещё про эту библиотеку хочется отметить, что в ней есть не только удобное выкачивание предобученного BERT, но и специальные модификации для конкретных задач. Например, для задачи классификации предложений (классификации текстов), которую мы собственно и будем использовать.  "]},{"cell_type":"markdown","metadata":{"id":"RX_ZDhicpHkV"},"source":["## Установка библиотек"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":372,"status":"ok","timestamp":1643709743204,"user":{"displayName":"Дмитрий Крапухин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggc2v_CQHmxf2sl_IRluFRrUm2MTBhbfr-oOZ_PGnk=s64","userId":"11342788103765688294"},"user_tz":-180},"id":"Jmcvq4uJuEN2"},"outputs":[],"source":["# Если Вы запускаете ноутбук на colab или kaggle,\n","# выполните следующие строчки, чтобы подгрузить библиотеку dlnlputils:\n","\n","# !git clone https://github.com/Samsung-IT-Academy/stepik-dl-nlp.git && pip install -r stepik-dl-nlp/requirements.txt\n","# import sys; sys.path.append('./stepik-dl-nlp')\n","# !pip install pytorch-transformers\n","# !pip install keras\n","# !pip install tensorflow \n","import torch\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","from keras.preprocessing.sequence import pad_sequences\n","from sklearn.model_selection import train_test_split\n","from transformers import BertTokenizer, BertConfig\n","from transformers import AdamW, BertForSequenceClassification\n","from tqdm import tqdm, trange\n","import pandas as pd\n","import io\n","import numpy as np\n","from sklearn.metrics import accuracy_score\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":383,"status":"ok","timestamp":1643709761189,"user":{"displayName":"Дмитрий Крапухин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggc2v_CQHmxf2sl_IRluFRrUm2MTBhbfr-oOZ_PGnk=s64","userId":"11342788103765688294"},"user_tz":-180},"id":"oYsV4H8fCpZ-","outputId":"626e213c-2329-427b-e9dc-d1524c4c16a7"},"outputs":[{"name":"stdout","output_type":"stream","text":["NVIDIA GeForce RTX 3060\n"]}],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","if device == 'cpu':\n","    print('cpu')\n","else:\n","    n_gpu = torch.cuda.device_count()\n","    print(torch.cuda.get_device_name(0))"]},{"cell_type":"markdown","metadata":{"id":"guw6ZNtaswKc"},"source":["## Загрузка данных\n"]},{"cell_type":"markdown","metadata":{"id":"6xro9MY7uEN6"},"source":["Дальше посмотрим на данные, на которых мы будем дообучать нашу модель. Мы выбрали достаточно интересный датасет с разметкой сентимента русскоязычных твитов.[1] Корпус содержит около 115 тысяч записей с положительной эмоциональной окраской и около 112 000 — с отрицательной эмоциональной окраской. И этот датасет был размечен вручную. Давайте посмотрим на наши данные. Загружаем наши тексты и смотрим на произвольные 5 записей. Как вы видите, лексика здесь достаточно неформальная, ну собственно, как в твитах. Есть какие-то слова (вот такие, например) забавные, есть смайлики.  "]},{"cell_type":"markdown","metadata":{"id":"VctzwQ-cuEN6"},"source":["Мы выбрали необычный датасет с разметкой сентимента русскоязычных твитов (подробнее про него в [статье](http://www.swsys.ru/index.php?page=article&id=3962&lang=)). В корпусе, который мы использовали 114,911 положительных и 111,923 отрицательных записей. Загрузить его можно [тут](https://study.mokoron.com/)."]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"elapsed":1783,"status":"ok","timestamp":1643709810308,"user":{"displayName":"Дмитрий Крапухин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggc2v_CQHmxf2sl_IRluFRrUm2MTBhbfr-oOZ_PGnk=s64","userId":"11342788103765688294"},"user_tz":-180},"id":"KTujhfy0uEN6","outputId":"757f0ac8-dfd5-4c8d-8e18-8057b3f7254b"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>10</th>\n","      <th>11</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>5321</th>\n","      <td>409063006149279744</td>\n","      <td>1386363195</td>\n","      <td>YarikOfficial</td>\n","      <td>Невероятных снов вам ! Как мне вчера ночью или...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>3958</td>\n","      <td>356</td>\n","      <td>74</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>80114</th>\n","      <td>410740357807476736</td>\n","      <td>1386763107</td>\n","      <td>malinina_00</td>\n","      <td>@marina1999_81 несиии уж, только принесу через...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2450</td>\n","      <td>25</td>\n","      <td>16</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>19673</th>\n","      <td>409406708235005952</td>\n","      <td>1386445140</td>\n","      <td>Sergey_Styepin</td>\n","      <td>@Varfolomeev она там все уравновесила \"белой о...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>29008</td>\n","      <td>707</td>\n","      <td>74</td>\n","      <td>22</td>\n","    </tr>\n","    <tr>\n","      <th>22383</th>\n","      <td>409433368632504320</td>\n","      <td>1386451496</td>\n","      <td>zibrov_yuriy</td>\n","      <td>RT @ciao_lucine: Эх... Люблю же я ересь в лент...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>949</td>\n","      <td>46</td>\n","      <td>44</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>30656</th>\n","      <td>409644758488068096</td>\n","      <td>1386501895</td>\n","      <td>MazaevMaxim</td>\n","      <td>Очень важная победа в конце года) привет, пере...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1139</td>\n","      <td>53</td>\n","      <td>50</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                       0           1               2   \\\n","5321   409063006149279744  1386363195   YarikOfficial   \n","80114  410740357807476736  1386763107     malinina_00   \n","19673  409406708235005952  1386445140  Sergey_Styepin   \n","22383  409433368632504320  1386451496    zibrov_yuriy   \n","30656  409644758488068096  1386501895     MazaevMaxim   \n","\n","                                                      3   4   5   6   7   \\\n","5321   Невероятных снов вам ! Как мне вчера ночью или...   1   0   0   0   \n","80114  @marina1999_81 несиии уж, только принесу через...   1   0   0   0   \n","19673  @Varfolomeev она там все уравновесила \"белой о...   1   0   0   0   \n","22383  RT @ciao_lucine: Эх... Люблю же я ересь в лент...   1   0   1   0   \n","30656  Очень важная победа в конце года) привет, пере...   1   0   0   0   \n","\n","          8    9   10  11  \n","5321    3958  356  74   4  \n","80114   2450   25  16   0  \n","19673  29008  707  74  22  \n","22383    949   46  44   0  \n","30656   1139   53  50   0  "]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["import pandas as pd\n","\n","# Если Вы запускаете ноутбук на colab или kaggle, добавьте в начало пути ./stepik-dl-nlp\n","pos_texts = pd.read_csv('datasets/bert_sentiment_analysis/positive.csv', encoding='utf8', sep=';', header=None)\n","neg_texts = pd.read_csv('datasets/bert_sentiment_analysis/negative.csv', encoding='utf8', sep=';', header=None)\n","pos_texts.sample(5)"]},{"cell_type":"markdown","metadata":{"id":"o03hDfJFuEN7"},"source":["Теперь давайте приготовим наши данные так, чтобы их можно было подать в BERT для дообучения. Обратите внимание на специальные токены — \"CLS\" и \"SEP\", которые мы будем добавлять в начало и конец наших предложений. Как вы помните, именно такой формат нужен BERT для того, чтобы работать с входными предложениями. Посмотрим, что всё у нас нормально — все размерности сошлись, и распечатаем пример — ну, например, 1000-ое предложение. Видим какой-то твит — в начале метка \"CLS\", в конце — метка \"SEP\".  "]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":764,"status":"ok","timestamp":1643709815403,"user":{"displayName":"Дмитрий Крапухин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggc2v_CQHmxf2sl_IRluFRrUm2MTBhbfr-oOZ_PGnk=s64","userId":"11342788103765688294"},"user_tz":-180},"id":"xztpHiVEuEN7","outputId":"6a26e3b7-e9ae-4d51-fae0-8bef8f31c83e"},"outputs":[{"name":"stdout","output_type":"stream","text":["[CLS] Дим, ты помогаешь мне, я тебе, все взаимно, все правильно) [SEP]\n"]}],"source":["sentences = np.concatenate([pos_texts[3].values, neg_texts[3].values])\n","\n","sentences = [\"[CLS] \" + sentence + \" [SEP]\" for sentence in sentences]\n","labels = [[1] for _ in range(pos_texts.shape[0])] + [[0] for _ in range(neg_texts.shape[0])]\n","\n","assert len(sentences) == len(labels) == pos_texts.shape[0] + neg_texts.shape[0]\n","print(sentences[1000])"]},{"cell_type":"markdown","metadata":{"id":"pUxWBqPOuEN7"},"source":["Теперь поделим наши данные на обучающую выборку и холдаут (holdout) — то есть, некоторые данные отложим и не будем их использовать в процессе дообучения, а затем на этой отложенной выборке померим качество нашей дообученной модели. Делим наши данные в пропорции 70/30%, смотрим, какие данные у нас получились: в обучающей выборке примерно 158 000 записей, а в холдауте 68 000.  \n","\n","[1] Корпус коротких текстов Юлии Рубцовой: http://study.mokoron.com/  \n","[2] Liu Y. et al. Roberta: A robustly optimized bert pretraining approach //arXiv preprint arXiv:1907.11692. – 2019."]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":421,"status":"ok","timestamp":1643709829265,"user":{"displayName":"Дмитрий Крапухин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggc2v_CQHmxf2sl_IRluFRrUm2MTBhbfr-oOZ_PGnk=s64","userId":"11342788103765688294"},"user_tz":-180},"id":"b_kPiji4uEN7","outputId":"cd28c9e7-a1b0-459b-daf2-524d135b2568"},"outputs":[{"name":"stdout","output_type":"stream","text":["158783 68051\n"]}],"source":["from sklearn.model_selection import train_test_split\n","\n","train_sentences, test_sentences, train_gt, test_gt = train_test_split(sentences, labels, test_size=0.3)\n","print(len(train_gt), len(test_gt))"]},{"cell_type":"markdown","metadata":{"id":"ex5O1eV-Pfct"},"source":["## Inputs"]},{"cell_type":"markdown","metadata":{"id":"zirhGWcMuEN8"},"source":["Теперь импортируем токенизатор для BERT, который превратит наши тексты в набор токенов, соответствующих тем, что встречались в словаре предобученной модели. Импортируем из pytorch-transformers \"bert_tokenizer\" и затем загрузим модель, которая называется \"bert_base_uncased\". Это означает, что мы используем токенизатор для модели BERT Base — это та самая модель, которая меньше, чем BERT Large, и содержит внутри 12 self-attention модулей. \"Uncased\" означает, что все слова в словаре этого токенайзера написаны в нижнем регистре (то есть, все слова написаны с маленькой буквы). Посмотрим, на какие токены наш токенайзер разобьёт, ну, например, первое предложение из наших данных. BERT требует специальный формат входных данных. Нам нужно предоставить четыре сущности. Первая называется input_ids — это последовательность чисел, которая отождествляет каждый токен с его номером в словаре. Вторая сущность называется labels — это вектор из нулей и единиц. В нашем случае, нули и обозначают негативную эмоциональную окраску, а единицы — положительную эмоциональную окраску. А ещё есть две сущности, два параметра, не обязательных. Они называются segment_mask и attention_mask. segment_mask — это последовательность нулей и единиц, которая показывает, состоит ли наш входной текст из двух предложений или из одного. Соответственно, в случае одного предложения, мы просто подаём вектор из одних нулей. Как вы помните, BERT предобучается на двух задачах. Первая задача — это предсказание маскированных слов в тексте, а вторая задача — определение, является ли одно предложение продолжением другого предложения. И, соответственно, для того, чтобы дать BERT информацию о том, есть ли у нас два предложения в нашем входе, либо одно, нам нужен этот параметр segment_mask. Следующий параметр (attention mask) — это также последовательность нулей и единиц, где единицы обозначают токены предложения, а нули — паддинг. Паддинг нужен для того, чтобы BERT мог работать с предложениями разной длины. Ну, например, в нашем случае, мы можем сказать, что максимальная длина предложения у нас будет равна 100, можно выбрать какую-то другую длину, это не сильно важно. И теперь более длинные предложения мы будем обрезать до 100 токенов, а для более коротких предложений использовать паддинг. Для того, чтобы добавить паддинг нашим предложениям, мы будем использовать готовую функцию из keras под названием pad_sequences. "]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":98685,"status":"ok","timestamp":1643709930053,"user":{"displayName":"Дмитрий Крапухин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggc2v_CQHmxf2sl_IRluFRrUm2MTBhbfr-oOZ_PGnk=s64","userId":"11342788103765688294"},"user_tz":-180},"id":"Z474sSC6oe7A","outputId":"a87af549-44db-49fb-d676-a4d7ee17099c"},"outputs":[{"name":"stdout","output_type":"stream","text":["['[CLS]', 'о', '##ч', '##е', '##н', '##ь', 'с', '##к', '##у', '##ч', '##а', '##ю', 'п', '##о', 'т', '##в', '##и', '##т', '##а', '##м', 'и', 'ч', '##е', '##к', '##и', '##на', '##м', '@', 'ko', '_', 'omar', '##off', '[SEP]']\n"]}],"source":["from transformers import BertTokenizer, BertConfig\n","\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n","\n","tokenized_texts = [tokenizer.tokenize(sent) for sent in train_sentences]\n","print (tokenized_texts[0])"]},{"cell_type":"markdown","metadata":{"id":"87_kXUeT2-br"},"source":["BERTу нужно предоставить специальный формат входных данных.\n","\n","\n","- **input ids**: последовательность чисел, отождествляющих каждый токен с его номером в словаре.\n","- **labels**: вектор из нулей и единиц. В нашем случае нули обозначают негативную эмоциональную окраску, единицы - положительную.\n","- **segment mask**: (необязательно) последовательность нулей и единиц, которая показывает, состоит ли входной текст из одного или двух предложений. Для случая одного предложения получится вектор из одних нулей. Для двух: <length_of_sent_1> нулей и <length_of_sent_2> единиц.\n","- **attention mask**: (необязательно) последовательность нулей и единиц, где единицы обозначают токены предложения, нули - паддинг."]},{"cell_type":"markdown","metadata":{"id":"Ue2fE2suuEN9"},"source":["Первое предложение из нашей обучающей выборки разбилось на токены, почти все токены здесь состоят из одной буквы, но встречаются иногда и двухбуквенные токены, иногда встречаются символы пунктуации.\n","\n","Здесь написан код, который добавляет паддинг к нашим предложениям. \n"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":24103,"status":"ok","timestamp":1643709954147,"user":{"displayName":"Дмитрий Крапухин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggc2v_CQHmxf2sl_IRluFRrUm2MTBhbfr-oOZ_PGnk=s64","userId":"11342788103765688294"},"user_tz":-180},"id":"Cp9BPRd1tMIo"},"outputs":[],"source":["input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n","input_ids = pad_sequences(\n","    input_ids,\n","    maxlen=100,\n","    dtype=\"long\",\n","    truncating=\"post\",\n","    padding=\"post\"\n",")\n","attention_masks = [[float(i>0) for i in seq] for seq in input_ids]"]},{"cell_type":"markdown","metadata":{"id":"omhUKXMjuEN-"},"source":["Теперь нам нужно поделить наши данные на тренировку и валидацию. Отложенную выборку мы уже отложили в переменную test_data или test_sentences, и теперь давайте поделим оставшийся данные на обучение и валидацию. Делаем мы это точно так же, с помощью функции train_test_split, делим в пропорции 90% оставшихся данных — на обучение, 10% — на валидацию. "]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1643709954148,"user":{"displayName":"Дмитрий Крапухин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggc2v_CQHmxf2sl_IRluFRrUm2MTBhbfr-oOZ_PGnk=s64","userId":"11342788103765688294"},"user_tz":-180},"id":"aFbE-UHvsb7-"},"outputs":[],"source":["train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(\n","    input_ids, train_gt, \n","    random_state=42,\n","    test_size=0.1\n",")\n","\n","train_masks, validation_masks, _, _ = train_test_split(\n","    attention_masks,\n","    input_ids,\n","    random_state=42,\n","    test_size=0.1\n",")"]},{"cell_type":"markdown","metadata":{"id":"y9MrMa_QuEN-"},"source":["Дальше мы превращаем наши данные в pytorch тензоры, и давайте посмотрим на формат, в котором у нас лежат наши лэйблы. Обратите внимание на формат лейблов в наших данных. Мы подаём не просто list() из нулей и единиц, а мы подаём list(list()). Это нужно для того, чтобы поддерживать также возможность работы с задачами, где мы каждому объекту присваиваем несколько классов. Например, если бы мы хотели присваивать некоторые метки (лейблы) тем для наших предложений (ну, или скорее для наших текстов), то мы хотели бы уметь присваивать несколько тем одному тексту. В нашем же более простом случае, у каждого предложения есть только одна метка — положительная или отрицательная эмоциональная окраска. Но, тем не менее, данные мы подаём в таком формате. "]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1500,"status":"ok","timestamp":1643709955644,"user":{"displayName":"Дмитрий Крапухин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggc2v_CQHmxf2sl_IRluFRrUm2MTBhbfr-oOZ_PGnk=s64","userId":"11342788103765688294"},"user_tz":-180},"id":"jw5K2A5Ko1RF","outputId":"4b07665c-c3f9-41b1-ff60-2be09c809e85"},"outputs":[{"data":{"text/plain":["tensor([[0],\n","        [0],\n","        [1],\n","        ...,\n","        [0],\n","        [1],\n","        [1]])"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["train_inputs = torch.tensor(train_inputs)\n","train_labels = torch.tensor(train_labels)\n","train_masks = torch.tensor(train_masks)\n","\n","validation_inputs = torch.tensor(validation_inputs)\n","validation_labels = torch.tensor(validation_labels)\n","validation_masks = torch.tensor(validation_masks)\n","\n","train_labels"]},{"cell_type":"markdown","metadata":{"id":"mh_3cafsuEN_"},"source":["Нужно создать итераторы с помощью DataLoader. Данные по батчам мы будем разбивать произвольно с помощью RandomSampler. Разбитие данных на батчи позволит нам более эффективно использовать память во время обучения, поскольку нам не придётся загружать весь датасет в память. И, также, обратите внимание на размер батча. Здесь мы пишем число \"32\", но, если вы обнаружите, что во время тренировки у вас появляется, \"memory error\" — значит, можно попробовать уменьшить размер батча (все как обычно)."]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1643709955645,"user":{"displayName":"Дмитрий Крапухин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggc2v_CQHmxf2sl_IRluFRrUm2MTBhbfr-oOZ_PGnk=s64","userId":"11342788103765688294"},"user_tz":-180},"id":"GEgLpFVlo1Z-"},"outputs":[],"source":["train_data = TensorDataset(train_inputs, train_masks, train_labels)\n","train_dataloader = DataLoader(\n","    train_data,\n","    sampler=RandomSampler(train_data),\n","    batch_size=32\n",")\n","\n","validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n","validation_dataloader = DataLoader(\n","    validation_data,\n","    sampler=SequentialSampler(validation_data),\n","    batch_size=32\n",")"]},{"cell_type":"markdown","metadata":{"id":"_D7J7WksuEN_"},"source":["Вы подаете на вход BERTу segment_mask = [0,0,0,0,0,0,0] и attention_mask = [1,1,1,1,1,1,1,0,0,0]. Выберите верные утверждения:\n","\n","+Вы подаете на вход одно предложение  \n","\n","-Предложение имеет положительную эмоциональную окраску с вероятностью 70%  \n","\n","-Максимально возможная длина входа равна 10 символам  \n","\n","-Для этого инпута паддинг не используется, предложение и так имеет максимально возможную длину  \n","\n","-В словаре содержится 10 токенов  \n","\n","+Максимально возможная длина входа равна 10 токенам  "]},{"cell_type":"markdown","metadata":{"id":"pNl8khAhPYju"},"source":["## Обучение модели"]},{"cell_type":"markdown","metadata":{"id":"7x_Pjl-FuEOA"},"source":["Для начала мы хотим изменить предобученный BERT так, чтобы он выдавал метки для классификации. А затем — дофайнтюнить полученную сеть на наших данных. Мы берём готовую модификацию BERT для классификации из pytorch-transformers, она называется \"BertForSequenceClassification\". Импортируем её. Это обычный BERT с добавленным одним линейным слоем для классификации. Аналогичные модели есть и для решения других задач, например, есть \"BertForQuestionAnswering\", есть \"BertForTokenClassification\". Все эти модели построены на основе одной и той же архитектуры и различаются только верхними слоями. Рассмотрим сам процесс файнтюнинга. Как мы помним, первый токен в каждом предложении в наших данных — это метка \"CLS\". Скрытое состояние, относящееся к этой метке, должно содержать в себе агрегированное представление всего предложения, которое дальше будет использоваться для классификации. Таким образом, когда мы скормили предложение в процессе обучения сети, выходом должен быть вектор со скрытым состоянием, относящийся к метке \"CLS\". Дополнительный полносвязный слой, который мы добавили, имеет размер [\"hidden state\", \"количество классов\"] — это двухмерный вектор. В нашем случае, количество классов равно \"2\", то есть, на выходе мы получим два числа, представляющих классы \"положительная эмоциональная окраска\", \"отрицательная эмоциональная окраска\". По факту, мы тренируем наш верхний слой и немного меняем веса во всех остальных слоях. Иногда некоторые слои специально замораживают или применяют разные стратегии работы с learning rate. В общем делают всё, чтобы сохранить хорошие веса в нижних слоях и ускорить процесс дообучения. В целом, замораживание слоёв BERT обычно не сильно сказывается на итоговом качестве, однако стоит помнить о тех случаях, когда домен для предобучения и дообучения был разным. Например, когда мы предобучили нашу сеть на каких-то официальных текстах (на правовых актах или на научных статьях), а дообучаем её на, например, твитах, на неформальной лексике. В таких случаях лучше тренировать все слои сети, не замораживая ничего.\n"]},{"cell_type":"markdown","metadata":{"id":"IsLWv1i0uEOA"},"source":["Загружаем [BertForSequenceClassification](https://github.com/huggingface/pytorch-pretrained-BERT/blob/master/pytorch_pretrained_bert/modeling.py#L1129):"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1643709955646,"user":{"displayName":"Дмитрий Крапухин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggc2v_CQHmxf2sl_IRluFRrUm2MTBhbfr-oOZ_PGnk=s64","userId":"11342788103765688294"},"user_tz":-180},"id":"tW6ecXjuuEOA"},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"data":{"text/plain":["BertForSequenceClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",")"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["from transformers import AdamW, BertForSequenceClassification\n","\n","# Аналогичные модели есть и для других задач:\n","from transformers import BertForQuestionAnswering, BertForTokenClassification\n","\n","model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n","model.cuda()"]},{"cell_type":"markdown","metadata":{"id":"JMSRG7wcuEOB"},"source":["Отлично, теперь давайте обсудим гиперпараметры для обучения нашей модели. Авторы статьи про BERT советуют выбирать learning rate из следующего списка: 5\\*10^(-5), 3\\*10^(-5), 2\\*10^(-5). А количество эпох делать не слишком большим (2 или 4 будет достаточно). Мы же пробуем дообучать нашу сеть за одну эпоху, а в качестве learning rate давайте выберем 2\\*10^(-5). Вы можете попробовать другие параметры и убедиться, что это не слишком сильно повлияет на итоговое качество вашей модели. "]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":456,"status":"ok","timestamp":1643710216981,"user":{"displayName":"Дмитрий Крапухин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggc2v_CQHmxf2sl_IRluFRrUm2MTBhbfr-oOZ_PGnk=s64","userId":"11342788103765688294"},"user_tz":-180},"id":"QxSMw0FrptiL"},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/dmitry/anaconda3/envs/stpk_nlp/lib/python3.7/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n"]}],"source":["param_optimizer = list(model.named_parameters())\n","no_decay = ['bias', 'gamma', 'beta']\n","optimizer_grouped_parameters = [\n","    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n","     'weight_decay_rate': 0.01},\n","    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n","     'weight_decay_rate': 0.0}\n","]\n","\n","optimizer = AdamW(optimizer_grouped_parameters, lr=2e-5)"]},{"cell_type":"markdown","metadata":{"id":"fw6tJ73OuEOD"},"source":["Что происходит в коде с циклом обучения. Цикл в нашем случае весьма номинален, поскольку он состоит из всего одной итерации. Вот наш код для дообучения модели. В процессе обучения, сначала мы переводим нашу модель в train mode, затем распаковываем входные данные — распаковываем вектор с индексами токенов и метки классов. Затем не забываем очистить градиенты с прошлого шага с помощью zero_grad(). Делаем forward pass, считаем loss, затем делаем backward pass, считаем градиенты, и дальше — стандартно — делаем optimizer.step(). Кроме того, в процессе обучения мы будем рисовать график и считать лосс. В конце каждой эпохи (в нашем случае — в конце единственной эпохи) посчитаем лосс на нашей обучающей выборке"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":346},"executionInfo":{"elapsed":5579425,"status":"ok","timestamp":1643715802347,"user":{"displayName":"Дмитрий Крапухин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggc2v_CQHmxf2sl_IRluFRrUm2MTBhbfr-oOZ_PGnk=s64","userId":"11342788103765688294"},"user_tz":-180},"id":"6J-FYdx6nFE_","outputId":"b4ac29f3-55e1-4edb-b9c4-c51e38ddf650"},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Loss на обучающей выборке: 0.03692\n","CPU times: user 20min 57s, sys: 31.7 s, total: 21min 29s\n","Wall time: 21min 26s\n"]}],"source":["%%time\n","from IPython.display import clear_output\n","\n","# Будем сохранять loss во время обучения\n","# и рисовать график в режиме реального времени\n","train_loss_set = []\n","train_loss = 0\n","\n","\n","# Обучение\n","# Переводим модель в training mode\n","model.train()\n","\n","\n","for step, batch in enumerate(train_dataloader):\n","    # добавляем батч для вычисления на GPU\n","    batch = tuple(t.to(device) for t in batch)\n","    # Распаковываем данные из dataloader\n","    b_input_ids, b_input_mask, b_labels = batch\n","    \n","    # если не сделать .zero_grad(), градиенты будут накапливаться\n","    optimizer.zero_grad()\n","    \n","    # Forward pass\n","    loss = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n","\n","    train_loss_set.append(loss[0].item())  \n","    \n","    # Backward pass\n","    loss[0].backward()\n","    \n","    # Обновляем параметры и делаем шаг используя посчитанные градиенты\n","    optimizer.step()\n","\n","    # Обновляем loss\n","    train_loss += loss[0].item()\n","    \n","    # Рисуем график\n","    clear_output(True)\n","    plt.plot(train_loss_set)\n","    plt.title(\"Training loss\")\n","    plt.xlabel(\"Batch\")\n","    plt.ylabel(\"Loss\")\n","    plt.show()\n","    \n","print(\"Loss на обучающей выборке: {0:.5f}\".format(train_loss / len(train_dataloader)))\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"u53Rvbu1uEOE"},"source":["По графику видно, что лосс, с первых батчей, достаточно сильно просел, потом сильно не менялся, но достаточно сильно флуктуировал. "]},{"cell_type":"markdown","metadata":{"id":"5eWAAomcuEOE"},"source":["Теперь посмотрим, какое качество мы можем получить на наших валидационных данных после одной эпохи. Вот наш код для валидации. Сначала переводим нашу модель в evaluation mode. Также, как в процессе обучения, распаковываем наш батч, загружаем данные на GPU, скармливаем данные сети (то есть делаем forward pass) и считаем лосс на валидационных данных (мониторим прогресс). Также — обратите внимание — мы используем torch.no_grad, при этом модель не будет считать и хранить градиенты, это ускорит процесс предсказания меток для наших валидационных данных. И давайте посмотрим, что у нас получилось, какой score у нас получился на валидационных данных. Процент правильных предсказаний на валидационной выборке составил 97.87%. Кажется, вполне неплохо всего для одной эпохи дообучения и 15-20 минут обучения на одной GPU. "]},{"cell_type":"code","execution_count":14,"metadata":{"id":"5TVLVhZduEOE"},"outputs":[{"name":"stdout","output_type":"stream","text":["Процент правильных предсказаний на валидационной выборке: 98.31%\n","Процент правильных предсказаний на валидационной выборке: 98.31%\n"]}],"source":["# Валидация\n","# Переводим модель в evaluation mode\n","model.eval()\n","\n","valid_preds, valid_labels = [], []\n","\n","for batch in validation_dataloader:   \n","    # добавляем батч для вычисления на GPU\n","    batch = tuple(t.to(device) for t in batch)\n","    \n","    # Распаковываем данные из dataloader\n","    b_input_ids, b_input_mask, b_labels = batch\n","    \n","    # При использовании .no_grad() модель не будет считать и хранить градиенты.\n","    # Это ускорит процесс предсказания меток для валидационных данных.\n","    with torch.no_grad():\n","        logits = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n","\n","    # Перемещаем logits и метки классов на CPU для дальнейшей работы\n","    logits = logits[0].detach().cpu().numpy()\n","    label_ids = b_labels.to('cpu').numpy()\n","    \n","    batch_preds = np.argmax(logits, axis=1)\n","    batch_labels = np.concatenate(label_ids)     \n","    valid_preds.extend(batch_preds)\n","    valid_labels.extend(batch_labels)\n","\n","print(\"Процент правильных предсказаний на валидационной выборке: {0:.2f}%\".format(\n","    accuracy_score(valid_labels, valid_preds) * 100\n","))\n","print(\"Процент правильных предсказаний на валидационной выборке: {0:.2f}%\".format(\n","    accuracy_score(valid_labels, valid_preds) * 100\n","))"]},{"cell_type":"markdown","metadata":{"id":"mkyubuJSOzg3"},"source":["# Оценка качества на отложенной выборке"]},{"cell_type":"markdown","metadata":{"id":"qbOspPY_uEOF"},"source":["Теперь оценим качество нашей модели на отложенной выборке. Для этого нам нужно сделать точно такую же предобработку наших тестовых данных, как мы делали для обучающей и валидационной выборки. По сути, мы просто копируем два кусочка кода из предыдущих частей ноутбука. Делаем токенизацию тем же самым токенайзером, готовим переменные input_ids, добавляем паддинг, делаем attention-маски. И, затем, запускаем код, который посчитает нам accuracy на наших тестовых данных.  "]},{"cell_type":"code","execution_count":15,"metadata":{"id":"mAN0LZBOOPVh"},"outputs":[],"source":["tokenized_texts = [tokenizer.tokenize(sent) for sent in test_sentences]\n","input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n","\n","input_ids = pad_sequences(\n","    input_ids,\n","    maxlen=100,\n","    dtype=\"long\",\n","    truncating=\"post\",\n","    padding=\"post\"\n",")"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"EnrhitgkuEOG"},"outputs":[],"source":["attention_masks = [[float(i>0) for i in seq] for seq in input_ids]\n","\n","prediction_inputs = torch.tensor(input_ids)\n","prediction_masks = torch.tensor(attention_masks)\n","prediction_labels = torch.tensor(test_gt)\n","\n","prediction_data = TensorDataset(\n","    prediction_inputs,\n","    prediction_masks,\n","    prediction_labels\n",")\n","\n","prediction_dataloader = DataLoader(\n","    prediction_data, \n","    sampler=SequentialSampler(prediction_data),\n","    batch_size=32\n",")"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"Hba10sXR7Xi6"},"outputs":[],"source":["model.eval()\n","test_preds, test_labels = [], []\n","\n","for batch in prediction_dataloader:\n","    # добавляем батч для вычисления на GPU\n","    batch = tuple(t.to(device) for t in batch)\n","    \n","    # Распаковываем данные из dataloader\n","    b_input_ids, b_input_mask, b_labels = batch\n","    \n","    # При использовании .no_grad() модель не будет считать и хранить градиенты.\n","    # Это ускорит процесс предсказания меток для тестовых данных.\n","    with torch.no_grad():\n","        logits = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n","\n","    # Перемещаем logits и метки классов на CPU для дальнейшей работы\n","    logits = logits[0].detach().cpu().numpy()\n","    label_ids = b_labels.to('cpu').numpy()\n","\n","    # Сохраняем предсказанные классы и ground truth\n","    batch_preds = np.argmax(logits, axis=1)\n","    batch_labels = np.concatenate(label_ids)  \n","    test_preds.extend(batch_preds)\n","    test_labels.extend(batch_labels)"]},{"cell_type":"markdown","metadata":{"id":"VwsnVT7ZuEOH"},"source":["Процент правильных предсказаний на отложенной выборке составил 98% (если точнее, 98.12%). Очень похоже на то, что получилось на валидационной выборке. Чуть точнее — у нас оказалось всего около 1300 неправильных предсказаний из 68 тысяч. Для такого недолгого и простого процесса дообучения это очень и очень здорово."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2cxf0_etuEOH"},"outputs":[{"name":"stdout","output_type":"stream","text":["Процент правильных предсказаний на отложенной выборке составил: 98.11%\n"]}],"source":["acc_score = accuracy_score(test_labels, test_preds)\n","print('Процент правильных предсказаний на отложенной выборке составил: {0:.2f}%'.format(\n","    acc_score*100\n","))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OCYseYTnuEOH"},"outputs":[{"name":"stdout","output_type":"stream","text":["Неправильных предсказаний: 1285/68051\n"]}],"source":["print('Неправильных предсказаний: {0}/{1}'.format(\n","    sum(np.array(test_labels) != test_preds),\n","    len(test_labels)\n","))"]},{"cell_type":"markdown","metadata":{"id":"rb0skjl5uEOH"},"source":["Мы показали, что предобученный BERT может быстро (всего за одну эпоху) давать хорошее качество при решении задачи анализа эмоциональной окраски текстов. Кроме того, обратите внимание, что мы не тюнили параметры и использовали сравнительно маленький размеченный корпус, чтобы получить accuracy больше 98%. Тем не менее, если не делать дообучение под конкретную задачу вовсе, то получить хорошее качество вряд ли выйдет. Кроме того, на этом семинаре мы познакомились с библиотекой pytorch-transformers, которая позволяет использовать готовые обёртки над моделями, специально созданными для решения той или иной задачи. Использовать BERT при решении повседневных NLP задач совсем не трудно. Не нужно даже вручную скачивать веса модели, искать их где-то в интернете — библиотека абсолютно всё сделает за вас. Отбросив необходимость небольшой предобработки текстов, сложность применения предобученного BERT с использованием библиотеки pytorch-transformers оказывается не сильно больше, чем — ну, например, импортировать лог-регрессию из sk-learn, и примените её, а качество итоговое получается гораздо выше. Вы можете использовать предобученный BERT, GPT-2 или какие-то другие сети для решения других задач — не только классификации, но и чего-то более сложного, например, для решения задачи вопросно-ответного поиска, или, может быть, машинного перевода или выделения именованных сущностей. Единственное, что вам нужно будет сделать — это импортировать другую модель из pytorch-transformers и подготовить ваши данные для обучения в чуть-чуть другом формате."]},{"cell_type":"markdown","metadata":{"id":"3w5lphb2uEOH"},"source":["### Домашнее задание"]},{"cell_type":"markdown","metadata":{"id":"l4pdpPJzuEOH"},"source":["Скачайте датасет с отзывами на фильмы. Например, используйте датасет [IMDB Dataset of 50K Movie Reviews](https://www.kaggle.com/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews). "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fGc3QM3EuEOI"},"outputs":[],"source":["import pandas as pd\n","\n","dataset = pd.read_csv('datasets/bert_sentiment_analysis/homework/IMDB_Dataset.csv')\n","dataset.head()"]},{"cell_type":"markdown","metadata":{"id":"x1LF3CSxuEOI"},"source":["Используйте для дообучения BERT датасет IMDB. "]},{"cell_type":"markdown","metadata":{"id":"kKIQZrE-uEOI"},"source":["Ответьте на вопросы:\n","1. удалось ли достичь такого же accuracy (98\\%) при использовании IMDB датасета?\n","2. удалось ли получить хорошее качество классификации всего за одну эпоху?\n","3. подумайте, в чем может быть причина различий в дообучении одной и той же модели на разных датасетах\n","    - Внимательно изучите датасет с русскими твитами. В чем его особенности? Нет ли явных паттернов или ключевых слов, которые однозначно определяют сентимент твита?\n","    - Попробуйте удалить пунктуацию из датасета с русскими твитами и перезапустите дообучение модели. Изменилось ли итоговое качество работы модели? Почему?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8ez3I0KDuEOI"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"task9_bert_sentiment_analysis_GPU.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"}},"nbformat":4,"nbformat_minor":0}
