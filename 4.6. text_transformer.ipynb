{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer, Self-Attention и моделирование языка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T18:27:04.225361Z",
     "start_time": "2019-11-05T18:27:04.223470Z"
    }
   },
   "outputs": [],
   "source": [
    "# Если Вы запускаете ноутбук на colab или kaggle,\n",
    "# выполните следующие строчки, чтобы подгрузить библиотеку dlnlputils:\n",
    "\n",
    "# !git clone https://github.com/Samsung-IT-Academy/stepik-dl-nlp.git && pip install -r stepik-dl-nlp/requirements.txt\n",
    "# import sys; sys.path.append('./stepik-dl-nlp')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "import youtokentome as yttm\n",
    "\n",
    "import dlnlputils\n",
    "from dlnlputils.data import tokenize_corpus, build_vocabulary, \\\n",
    "    save_texts_to_file, LanguageModelDataset, load_war_and_piece_chunks, \\\n",
    "    GreedyGenerator, BeamGenerator\n",
    "from dlnlputils.pipeline import train_eval_loop, init_random_seed\n",
    "from dlnlputils.base import get_params_number\n",
    "\n",
    "init_random_seed()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка текстов и разбиение на обучающую и тестовую подвыборки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим темы моделирования языка, механизмов внимания и рассмотрим архитектуру \"трансформер\". Проверять работоспособность методов будем с помощью известного произведения Льва Николаевича Толстого \"Война и мир\". В нашем случае, обучающая выборка — это просто большой текстовый файл без всякой разметки. При загрузке текста мы читаем весь его в память, а потом нарезаем на кусочки размером в 200 символов. Таким образом мы получим набор небольших фрагментов текста, но, при этом, длина каждого фрагмента будет больше, чем длина отдельного предложения. Современные языковые модели работают с более длинными последовательностями, поэтому общепринятая схема — это \"не выполнять разбиение текста на отдельные предложения перед подачей их в языковую модель\". Всего у нас получилось около 8 тысяч фрагментов. На экране один такой фрагмент. Он содержит фрагменты двух предложений. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T18:27:55.233798Z",
     "start_time": "2019-11-05T18:27:55.197616Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7976\n",
      "у нее был грипп, как она говорила (грипп был тогда новое\n",
      "слово, употреблявшееся только редкими). В записочках, разосланных утром с\n",
      "красным лакеем, было написано без различия во всех:\n",
      "  \"Si vous n'avez\n"
     ]
    }
   ],
   "source": [
    "# Если Вы запускаете ноутбук на colab или kaggle, добавьте в начало пути ./stepik-dl-nlp\n",
    "all_chunks = load_war_and_piece_chunks('./datasets/war_and_peace.txt')\n",
    "print(len(all_chunks))\n",
    "print(all_chunks[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как обычно, разобьём все наши данные на обучающую и тестовую выборку в соотношении 70% в обучающую выборку, 30% в тестовую. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T18:27:55.954154Z",
     "start_time": "2019-11-05T18:27:55.919185Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер обучающей выборки 5583\n",
      "Размер валидационной выборки 2393\n"
     ]
    }
   ],
   "source": [
    "np.random.shuffle(all_chunks)\n",
    "\n",
    "TRAIN_SPLIT = int(len(all_chunks) * 0.7)\n",
    "train_texts = all_chunks[:TRAIN_SPLIT]\n",
    "test_texts = all_chunks[TRAIN_SPLIT:]\n",
    "\n",
    "print('Размер обучающей выборки', len(train_texts))\n",
    "print('Размер валидационной выборки', len(test_texts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Токенизация корпуса с помощью BPE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Современные языковые модели работают, как правило, не с целыми токенами. Они работают с фрагментами слов, или, так называемыми \"sub-word units\" (по сути, это N-граммы символов). Поэтому для токенизации мы используем не классический токенизатор с помощью регулярных выражений или каких-то других правил (например, как те которые мы использовали в предыдущих семинарах). Здесь мы используем алгоритм \"byte pair encoding\" (BPE). Напомню, в двух словах, как он работает, в чём его основной принцип. Допустим, у нас есть последовательность символов: \"ABCABE\", например. Тогда, сначала, этот алгоритм будет искать наиболее частотную биграмму (в данном случае это \"AB\"), и он заменит её в тексте на какой-то новый символ, который в тексте ранее не встречался. Например, мы получим \"XCXE\". Такая же операция поиска наиболее частотной биграммы и замены её на новый символ будет повторяться в цикле. Например, на следующем шаге мы заменим биграмму \"XC\" на какой-нибудь символ \"Y\" и получим новую последовательность, и так далее. Таким образом мы последовательно сжимаем текст и, в процессе сжатия текста, запоминаем те замены, которые мы сделали. Например, мы можем запомнить, что \"AB\" было заменено на \"X\", а \"XC\" заменено было на \"Y\". Такой алгоритм позволяет получить нечто среднее между алгоритмами, работающими на уровне отдельных токенов, и на уровне отдельных символов. Когда мы работаем с отдельными символами, у нас алфавит маленький, то есть решать задачу классификации нам попроще, но длина последовательностей растёт и поэтому нам нужно строить модели, которые умеют запоминать далёкие зависимости. Это достаточно сложно. Наоборот, если мы работаем с отдельными токенами, то последовательности у нас гораздо короче. Но, с другой стороны, словарь у нас разрастается очень быстро (нам нужно уметь предсказывать каждый отдельный токен, а токенов очень много — гораздо больше, чем символов). И поэтому, с одной стороны, нам нужно помнить более короткие зависимости, но, зато, задача классификации становится сложной, потому что классов очень много. Алгоритмы, такие как byte pair encoding, позволяют найти золотую середину между этими двумя крайностями. В этом семинаре мы будем использовать реализацию byte pair encoding из библиотеки \"YouTokenToMe\". Эта библиотека была разработана \"ВКонтакте\"[1] и, на сегодняшний день, является самой быстрой реализацией byte pair encoding. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T18:27:56.412237Z",
     "start_time": "2019-11-05T18:27:56.386089Z"
    }
   },
   "outputs": [],
   "source": [
    "# Если Вы запускаете ноутбук на colab или kaggle, добавьте в начало пути ./stepik-dl-nlp\n",
    "BPE_MODEL_FILENAME = './models/4.6.war_and_peace_bpe.yttm'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Основной модуль библиотеки реализован не на python, и поэтому наиболее удобный и быстрый способ скармливания данных в эту библиотеку — это через текстовый файл. Поэтому мы, сначала, сохраняем все наши тексты в этот файлик, а затем вызываем функцию обучения. И функция обучения читает данные из текстового файла и складывает обученную модель (то есть, словарь замен) в другой файлик, который мы указали. Самый важный параметр здесь — это размер словаря. Он и позволяет нам выбрать, что мы хотим — более длинные последовательности, но меньший словарь, или более короткие последовательности, но более крупный словарь, и, чем больше наш словарь, тем больше будет редких классов — это будет создавать нам некоторые сложности при обучении."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T18:27:56.928780Z",
     "start_time": "2019-11-05T18:27:56.696400Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training parameters\n",
      "  input: ./datasets/war_and_peace_bpe_train.txt\n",
      "  model: ./models/war_and_peace_bpe.yttm\n",
      "  vocab_size: 1000\n",
      "  n_threads: 8\n",
      "  character_coverage: 1\n",
      "  pad: 0\n",
      "  unk: 1\n",
      "  bos: 2\n",
      "  eos: 3\n",
      "\n",
      "reading file...\n",
      "learning bpe...\n",
      "number of unique characters in the training data: 142\n",
      "number of deleted characters: 0\n",
      "number of unique characters left: 142\n",
      "model saved to: ./models/war_and_peace_bpe.yttm\n"
     ]
    }
   ],
   "source": [
    "# Если Вы запускаете ноутбук на colab или kaggle, добавьте в начало пути ./stepik-dl-nlp\n",
    "TRAIN_TEXTS_FILENAME = './datasets/war_and_peace_bpe_train.txt'\n",
    "save_texts_to_file(train_texts, TRAIN_TEXTS_FILENAME)\n",
    "yttm.BPE.train(data=TRAIN_TEXTS_FILENAME, vocab_size=1000, model=BPE_MODEL_FILENAME);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Когда модель обучена, мы создаём экземпляр класса \"bpe\" и передаём туда путь к файлу с обученной моделью. Давайте посмотрим на словарь, который наша модель выучила. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T18:27:57.767294Z",
     "start_time": "2019-11-05T18:27:57.731252Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PAD> <UNK> <BOS> <EOS> ▁ о а е и н т с л р в к , д м у п я г ь ы з б . ч й - ж ш e х ю s ц a n r i u o t щ э П l Н ф А В m d c О ? ! К Д Б p М v Р \" ) С ( ' ; И Т ё 1 h : Я 2 q f Г ъ b g Ч Э 0 3 Е 5 ] [ j 4 I z Л З 6 8 M A 9 7 У Ж V L x X Ф Ш y C Х J B P D E N S k Ц R Q O T ` w Ю H U F G K Ь W Й * & # Щ Z / ▁с ▁п ▁в ▁н то ▁о ▁и ▁к го ал ра ст но ▁- ▁по ен ▁д ер ел ▁б ро ▁не ко во ка ▁ч ▁м ри ▁на ло ть на ли ла ▁з ▁е ▁у ▁т ре ва ни ся сь ак ▁что ру ет ▁ко ▁бы ми ны ня да ▁то ди хо ▁за ▁го ем ▁г ▁он ол ени ▁от ки ви ну каз е, ▁э та ▁П ти ши ▁при ▁вы ▁ра му ▁Н ▁ж ов ▁вс ле ▁А до ▁В ▁про ▁мо ля ▁как мо ▁во казал ры ▁его ма ▁об сто ▁это ль й, ▁сказал ере не ▁а ▁до ▁О ▁я ▁К ▁кото ▁сво ▁кня ▁Д м, у, ше ▁Б али по чи ▁но сти ▁ни си ча ста ель ▁из ве лу ала де ▁Ан вори ▁М ▁под ▁ка ▁d .. ша ... за ска жи ще es я, лся ▁со че лы зь сть ско ou ▁ли ▁хо ▁ви ▁ст ень ▁ру ря енно ▁Пь ▁так ме ты ▁p ▁Р ги га дел лю сно re же ▁раз ▁( со те ду ку ▁се ски ▁c ▁С ▁ва вши ▁все тель бе en вал ▁l ▁дру ▁было ▁И on ▁говори ▁пос гда ту ▁сто ели щи ать лько ▁бу вы ▁Пьер ▁пере ▁Ро дре ▁ему ▁Т дно ▁пре ▁Андре ▁a вер ю, би ство ез ▁са ▁ф вая ▁Росто ▁Он ▁зна ар сп ▁она ▁которы а, ▁сп ▁m ▁был ▁же ▁всё ▁гла чал сь, бо ды ▁ми ▁те ву й. ▁ду er жени ▁голо х, ▁ве ▁(сно ▁князь ▁(сноска шел фи ба ▁лю ▁ста мот бы ▁лиц ▁бол ▁вз ▁На е. жа кой ▁Бо ть, ело ▁та енны ▁de ▁Я в, et го, нц ми, ▁s -то елов ai ▁си ало ▁да ▁гра ▁только т, ела гля ▁свое ▁ш ▁1 ▁оп м. ться ходи ▁буд qu са ха ▁которо жно ▁v гу ▁\" лов ▁ты шь ous ера ▁улы тельно ▁Кня ▁ее ▁еще ▁рас ▁n рем ▁ро вно ▁ме ▁Г к, пи ный нно ▁ре ▁пол ▁обра ▁им ▁qu ▁свои я. дь елове ▁и, жал фиц ясь ным ерь ▁челове ▁глаза оло ▁оста ▁Дени сов дя an ▁По ▁себ ▁слу па ▁ле ▁жи ▁боль су ▁для ▁ц ▁чу ка, ▁сказала ять ался аль e, ет, вля ▁Не рел ▁ло на, нул ▁Ч ▁ма лась бу ▁Э ▁t ман ей ▁была роси ▁него ск нцу ▁после гра ▁были ▁Ростов мы ▁эти ▁мне ▁сол ▁Андрей ▁офиц ▁врем ща ех ▁княз ▁х ▁бо ▁пер ▁говорил и, ri ▁он, нима ств ▁Е ▁мог ранцу ▁ком те, сту вать ▁дол н, le ят лись ▁бе ▁граф ▁Князь чень ▁вер ▁Доло ные шо ▁мы ▁сло ▁лицо ▁исп ▁[ ▁Долохо ва, чно ему ▁улыб ▁сдел ▁му ▁ча вор ▁пред ▁одно te ▁f зи перь ▁моло ▁2 ▁солда ▁мен руг ▁комна ▁смот нулся ца eu жет ения ▁et вет нов ражени ▁когда oi чего ▁стра ▁чтобы ▁Денисов ▁Ни ю. казы ▁хот ▁pa ки, зы ▁уже ▁кра ▁они ▁ба ▁хоро ались ком ного ▁Ва ▁пи вше дин ав се вст ▁друго ▁очень спо ▁францу ков лен ▁будто ▁вас ▁су ал, ▁княж ▁Ми ▁Но зна х. ▁который om ▁ту ▁перед ▁отве том нт ▁пра об ne ▁Ку est ▁од ▁пу ▁Она ▁Анна нови ▁теперь ▁опять ▁сов ная говори ▁Л ▁этого ▁де ▁Ната ▁vous ▁поло ▁стоя арь зов ▁гу ▁que ▁j ющи вой ▁воз ▁себя ной вство ных ение ▁дел ▁жен ем, нь ▁Что ▁мину стви ▁спроси ▁З дет ▁офицер ent ский ▁этот ку, ▁то, ▁кри ▁Марь лыш ▁ар ▁вп ▁ожи ▁ку зо ния ▁Во дол ми. ▁la ▁ch ▁le ▁Нико ▁поч ную ▁двер ▁подо ▁обе ▁коман сили ▁или ке л, ▁Это me ▁неп жели ▁вой у. ▁чем сте му, ние ют мал ▁ла ▁нес ▁разго ▁Мо вали is ▁Вы енер ▁Миха ▁взгля ▁которые ▁зак ▁сы il дар ▁меня он стро ▁M ую кры ее ▁продол ▁мал сы ▁пла вший кон ▁ничего друг ва. ▁Ба ▁Михай ▁сле ром жен ▁огля ▁види ▁дело ▁Бори ▁ша стоя ров ▁быть но, ся, ▁зам воль ▁Со our ▁себе пра ского ▁Никола ▁Куту кая ▁без казать ▁время ными вала in ▁друг на. ▁обрати ▁Как ▁что-то ▁Ну, ▁чи кий лаго ▁князя вл ▁их ▁Пав ▁сер ▁своего ▁вес ▁вот ▁Михайлов соб рая ▁бра ▁че ▁всех ниц ▁нас ▁жиз ais ▁свою ехал ▁Ко ▁каз ▁само кра ▁он. д, про ▁тем ▁молодо сколько ▁u ▁b ▁A ere дер ▁пе ▁команди вшись ▁останови ▁лоша сты ▁взя ▁генер ра, стно да, ▁доро us жд ▁может ▁Да ▁сидел ▁сторо ▁надо юще ▁тре ть. чь ▁ну ▁чувство ▁госу ▁Пьера ▁мол ▁малень ▁Наташа кое им ▁вдруг it ▁l' ли, мер ▁Багра вого ▁л ним ▁непри ▁други ▁спросил ▁будет ▁пото и. ▁своей ▁княги кого ez ▁Баграти ▁доб ▁па ▁люб жала ▁Ж пу ▁расс ▁арми ▁рука лось ▁Павлов ▁Васили ▁ок ▁видел ▁У оль дом ▁впере ▁начал ▁особ ▁где кто тер ▁вст шь, ▁сча ▁бле дал ▁mon жду ▁сме ▁прои ливо ▁вам ерез 'est вя ▁мой ▁Ту ▁рус ▁день ▁ши ▁ди ственно ▁g дро ▁улыба ▁дума ку. ▁лу ▁3 ▁кре ▁его. ете виц каза стя шая ▁отвечал ▁всегда цо ▁com ch ▁Пьер, ▁ско res шла жу ▁более ▁выражени ▁есть ны, ской ▁благо гла тя ▁сам ▁того, ▁вели ▁спо елы та, ▁сла ы,\n"
     ]
    }
   ],
   "source": [
    "tokenizer = yttm.BPE(BPE_MODEL_FILENAME)\n",
    "\n",
    "print(' '.join(tokenizer.vocab()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы сказали алгоритму выделить тысячу наиболее характерных N-грамм через byte pair encoding. Вот какие N-граммы нашлись. Во-первых, словарь содержит несколько служебных токенов — это токен \"padding\", то есть токен, предназначенный для выравнивания длин последовательностей, чтобы их подавать в нейросеть; это токен \"unknown\" — это когда алгоритм встретил в тексте какую-то N-грамму, которую не видел при обучении; и два токена \"beginning of sequence\" и \"end of sequence\". Мы сказали алгоритму: \"Пожалуйста, выдели нам тысячу наиболее характерных N-грамм через byte pair encoding\". Вот какие N-граммы нашлись. Во-первых, словарь содержит несколько служебных токенов — это токен \"padding\", то есть токен, предназначенный для выравнивания длин последовательностей, чтобы их подавать в нейросеть; это токен \"unknown\" — это когда алгоритм встретил в тексте какую-то N-грамму, которую не видел при обучении; и два токена \"beginning of sequence\" и \"end of sequence\". Далее идёт набор юниграмм, то есть, по сути — это все уникальные символы, которые встретились в обучающей выборке. А вот дальше уже идут более сложные конструкции, причём здесь идут вперемешку как биграммы и так и более длинные последовательности. Мы можем видеть здесь как фрагменты слов (какие-то устойчивые подслова, то есть основы слова) можем видеть имена людей без окончания (как, например, \"Андрей\", \"Ростов\", и так далее). Также здесь есть и явно слишком специфические последовательности (например, \" Пьер,\"). Скорее всего, это сигнал к тому, что можно сделать словарь поменьше для нашей модели. Но это не так очевидно, нужно смотреть на метрики на отложенной выборке, чтобы выбрать правильный размер словаря. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Токенизатор из библиотеки \"YouTokenToMe\" принимает на вход не отдельный текст, а сразу список текстов (список строк) и на выходе возвращает список списков, каждый вложенный список содержит числа — это номера токенов (номера N-грамм) в словаре. В принципе, как обычно. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T18:27:58.100551Z",
     "start_time": "2019-11-05T18:27:58.075268Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[210, 238, 244, 13, 317, 16, 147, 200, 12, 265, 35, 161, 337, 490, 203, 269, 447, 4, 111, 111, 96, 27, 415, 148, 176, 551, 201, 726, 199, 161, 848, 889, 772, 23, 16, 690, 179, 585, 18, 154, 412, 19, 382, 157, 186, 635, 10, 518, 774, 363, 670, 157, 793, 37, 7, 426, 791, 186, 635, 10, 518, 774, 650, 25, 988, 206, 186, 13, 201, 8, 149, 474, 17, 275, 31, 23, 8, 34, 444]]\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.encode(train_texts[:1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T18:27:59.729717Z",
     "start_time": "2019-11-05T18:27:59.551045Z"
    }
   },
   "outputs": [],
   "source": [
    "train_token_ids = tokenizer.encode(train_texts, bos=True, eos=True)\n",
    "test_token_ids = tokenizer.encode(test_texts, bos=True, eos=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим — а какой длины последовательности после токенизации у нас получились. Когда мы загружали датасет, мы нарезали исходный текст на кусочки длиной 200 символов. В результате токенизации, большая часть фрагментов получила длину от 60 до 140, примерно. Причём наиболее распространённая длина последовательности — мода — около 80, то есть получилось сжать среднюю длину текста чуть более, чем в два раза. Таким образом, с точки зрения длины последовательности, задача уже проще, чем моделирование языка на уровне отдельных символов. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T18:28:00.401753Z",
     "start_time": "2019-11-05T18:27:59.731680Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist([len(sent) for sent in train_token_ids], bins=30)\n",
    "plt.title('Распределение длин фрагментов в токенах')\n",
    "plt.yscale('log');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если мы построим гистограмму частот встречаемости токенов, то найдём распределение Ципфа: у нас очень мало частотных N-грамм (то есть тех N-грамм, которые встретились больше 2000 раз — их, наверное, меньше 20 суммарно), и основное количество N-грамм встретилось порядка нескольких сотен раз. Надо сказать, что очень редких N-грамм (то есть, вот этот — самый левый столбик) — их небольшое количество (около 100, всего лишь), то есть большая часть словаря у нас не является редкими классами. Это хорошая новость — всегда проще решать задачу классификации, когда классы сбалансированы. Когда мы обучали наш токенизатор, мы использовали только обучающую подвыборку всех данных, то есть только 70% текстов. Логично, что в остальных 30% могут встретиться токены, которые не встречались в обучающей выборке. Но мы используем здесь BPE, и поэтому в тестовой выборке, на самом деле, не оказалось токенов, которые бы мы не увидели в том или ином виде в обучающей выборке. То есть — да, может быть, какие-то длинные N-граммы мы там не нашли, но зато мы смогли эти длинные N-граммы разбить на более мелкие, и, всё равно, все символы у нас так или иначе нашлись в словаре. Таким образом, когда у нас в новом тексте встречаются только неизвестные слова, то BPE просто деградирует до character-level, то есть наша модель просто становится моделью на уровне отдельных символов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T18:28:01.153867Z",
     "start_time": "2019-11-05T18:28:00.404320Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "token_counts = np.bincount([token_id for text in train_token_ids for token_id in text])\n",
    "plt.hist(token_counts, bins=100)\n",
    "plt.title('Распределение количества упоминаний токенов')\n",
    "plt.yscale('log');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T18:28:01.204527Z",
     "start_time": "2019-11-05T18:28:01.156884Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество случаев с неизвестными n-граммами символов в валидационной выборке 0\n"
     ]
    }
   ],
   "source": [
    "unknown_subwords_in_test = sum(1 for text in test_token_ids for token_id in text if token_id == 1)\n",
    "print('Количество случаев с неизвестными n-граммами символов в валидационной выборке',\n",
    "      unknown_subwords_in_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка датасетов для PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как обычно, давайте создадим специальную структуру данных — Dataset, который будет готовить обучающие примеры для того, чтобы подавать их в pytorch для обучения. Для этой цели мы написали специальный класс \"LanguageModelDataset\", который принимает на вход список токенизированных предложений, в которых токены заменены на их номера. А также он принимает длину фрагмента которую нужно подавать в модель за раз. То есть, это наибольшее количество токенов, которые модель будет видеть за раз. Давайте посмотрим, как этот Dataset работает. Как обычно, наш Dataset реализует два основных метода — это получение длины датасета (то есть, количества примеров) и \"get_item\" — это получение одного конкретного примера по его порядковому номеру. Когда мы готовим очередной пример для модели, мы выбираем по индексу фрагмент текста, затем из всего текста мы выбираем какой-то случайный подфрагмент, непрерывный. И делаем из этого фрагмента ещё два кусочка — первый кусочек (здесь это переменная \"seed part\") — это весь текст, кроме последнего символа. А \"target_part\" — это весь текст, кроме первого символа. Таким образом, мы получаем, как бы, два текста — \"seed_part\" у нас выполняет роль входа в модель, а \"target_part\" — это то, что мы ожидаем на выходе модели. Таким образом, если у нас есть, например, текст \"ABCD\", тогда \"seed-part\" — это \"ABC\", а \"target_part\" — это \"BCD\". Физический смысл у этих последовательностей — следующий. На очередной позиции в \"target\" стоит токен, который модель должна предсказать, прочитав столько же токенов из входной последовательности. Таким образом, токен \"B\" она должна уметь предсказать только лишь по токену \"A\", токен \"C\" модель должна уметь предсказывать из \"AB\", а токен \"D\" она должна уметь предсказывать из всей входной последовательности, то есть \"ABC\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T18:28:02.980335Z",
     "start_time": "2019-11-05T18:28:02.938616Z"
    }
   },
   "outputs": [],
   "source": [
    "CHUNK_LENGTH = 80\n",
    "\n",
    "train_dataset = LanguageModelDataset(train_token_ids,\n",
    "                                     chunk_length=CHUNK_LENGTH)\n",
    "test_dataset = LanguageModelDataset(test_token_ids,\n",
    "                                    chunk_length=CHUNK_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На экране один пример, сгенерированный нашим Dataset. Мы видим что здесь токены, как бы, смещены на одну позицию влево всегда, и на очередной позиции вектора \"target\" у нас стоит токен, который нужно уметь предсказывать после прочтения всех предыдущих токенов. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T18:28:03.085890Z",
     "start_time": "2019-11-05T18:28:03.061652Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  2, 210, 238, 244,  13, 317,  16, 147, 200,  12, 265,  35, 161,\n",
       "        337, 490, 203, 269, 447,   4, 111, 111,  96,  27, 415, 148, 176,\n",
       "        551, 201, 726, 199, 161, 848, 889, 772,  23,  16, 690, 179, 585,\n",
       "         18, 154, 412,  19, 382, 157, 186, 635,  10, 518, 774, 363, 670,\n",
       "        157, 793,  37,   7, 426, 791, 186, 635,  10, 518, 774, 650,  25,\n",
       "        988, 206, 186,  13, 201,   8, 149, 474,  17, 275,  31,  23,   8,\n",
       "         34, 444]),\n",
       " array([210, 238, 244,  13, 317,  16, 147, 200,  12, 265,  35, 161, 337,\n",
       "        490, 203, 269, 447,   4, 111, 111,  96,  27, 415, 148, 176, 551,\n",
       "        201, 726, 199, 161, 848, 889, 772,  23,  16, 690, 179, 585,  18,\n",
       "        154, 412,  19, 382, 157, 186, 635,  10, 518, 774, 363, 670, 157,\n",
       "        793,  37,   7, 426, 791, 186, 635,  10, 518, 774, 650,  25, 988,\n",
       "        206, 186,  13, 201,   8, 149, 474,  17, 275,  31,  23,   8,  34,\n",
       "        444,   3]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Токенайзер из библиотеки \"YouTokenToMe\" умеет и декодировать тексты. То есть, обратно преобразовывать их в текст (то есть в строку). На экране вы видите пример детокенизации, то есть мы взяли тот же самый обучающий пример и прогнали его через детокенизатор. Мы видим, что две последовательности, входная и выходная, сдвинуты относительно друг друга на один токен, на одну N-грамму. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T18:28:03.260915Z",
     "start_time": "2019-11-05T18:28:03.219571Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<BOS> от восторга, с толпою побежал за ним. XXI. На площади куда поехал государь, стояли лицом к лицу справа батальон преображенцев, слева батальон французской гвардии в медвежьих ш',\n",
       " 'от восторга, с толпою побежал за ним. XXI. На площади куда поехал государь, стояли лицом к лицу справа батальон преображенцев, слева батальон французской гвардии в медвежьих ш<EOS>']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(list(train_dataset[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Общие классы и функции"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Маска зависимостей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если мы будем просто в лоб подавать текст и на выходе просить его же — действительно, модель ничего не выучит. Нам нужно усложнить ей задачу, нам нужно сделать так, чтобы при предсказании i-го токена она принципиально не могла учитывать токены, стоящие справа от этой позиции. Для этого мы будем использовать специальную маску. На экране вы видите функцию, которая генерирует такую маску и, собственно, пример этой маски — давайте разберём, какой физический смысл у этой маски. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T18:28:04.302365Z",
     "start_time": "2019-11-05T18:28:04.244547Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def make_target_dependency_mask(length):\n",
    "    full_mask = torch.ones(length, length)\n",
    "    ignore_mask = torch.tril(full_mask) < 1\n",
    "    full_mask.masked_fill_(ignore_mask, float('-inf'))\n",
    "    full_mask.masked_fill_(~ignore_mask, 0)\n",
    "    return full_mask\n",
    "\n",
    "make_target_dependency_mask(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Это так называемая \"маска зависимости позиций\". Для примера мы сгенерировали эту маску для достаточно короткой последовательности длины 10. Маска имеет размер 10 на 10, это квадратная матрица, строка соответствует номеру позиции в выходной последовательности, а столбцы соответствуют номерам позиций во входной последовательности, и на пересечении столбца и строки стоит 0, если при предсказании токена на позиции \"i\" можно учитывать токен на позиции \"j\". То есть, если учитывать можно — тогда стоит 0, а если учитывать нельзя — тогда стоит -∞. Таким образом, мы \"запрещаем\" модели смотреть на все токены справа. И, например, для самого первого токена (это первая строчка) мы можем использовать только самый первый входной токен. Для второго токена в выходной последовательности мы можем использовать уже два токена, а для последнего выходного токена мы можем использовать всю входную последовательность. Если в двух словах — то эти маски подаются в механизм внимания для того, чтобы занулить веса определённых элементов, чтобы мы не учитывали определённые входные позиции при расчёте выходных позиции. Она используется именно в механизмах внимания. Как именно она там используется, мы рассмотрим чуть позже."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Кодирование позиции"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Следующий вспомогательный элемент, который нам нужен — это позиционное кодирование. Механизм self-attention — он, в некотором смысле, похож на механизм свёрток, тем, что он инвариантен к позиции элемента в последовательности. Мы можем за одну операцию сравнить каждый элемент последователи с любым другим элементом последовательности. Но кажется, что, когда мы работаем с текстами, особенно с текстами с фиксированным порядком слов, нам важно учитывать позиции токенов. Даже если порядок слов и не фиксированный, то относительные позиции токенов уж точно полезны. Потому что всё-таки это достаточно редкий случай — когда связь между словами идёт через пол-текста. Даже для человека такие связи были бы очень сложными. Нам нужно учитывать относительные позиции токенов. Для того, чтобы закодировать позиции токенов, к эмбеддингу токена, который мы берём из таблички, будем прибавлять эмбеддинг позиции, то есть вектор такой же длины, что и эмбеддинг токена, который имеет разное значение для разных позиций. И самый, наверное, интуитивный способ закодировать позицию — это использовать какой-то периодический сигнал. Авторы трансформера предлагают использовать набор синусоид и косинусоид разной частоты. На экране вы видите график, который изображает сразу несколько таких векторов. Один срез графика (вертикальный) описывает нам эмбеддинг одной позиции. Вы можете видеть, что здесь есть как высокочастотные сигналы (как, например, вот этот), так и низкочастотные (как вот эта горизонтальная прямая, или вот этот голубой график). Таким образом, по изменению сигнала на определённых позициях мы можем определить, как далеко друг от друга два токена находятся. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T18:28:05.590059Z",
     "start_time": "2019-11-05T18:28:05.567602Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_positional_encoding(max_length, embedding_size):\n",
    "    time = np.pi * torch.arange(0, max_length).float()\n",
    "    freq_dividers = torch.arange(1, embedding_size // 2 + 1).float()\n",
    "    inputs = time[:, None] / freq_dividers[None, :]\n",
    "    \n",
    "    result = torch.zeros(max_length, embedding_size)\n",
    "    result[:, 0::2] = torch.sin(inputs)\n",
    "    result[:, 1::2] = torch.cos(inputs)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T18:28:06.060293Z",
     "start_time": "2019-11-05T18:28:05.708626Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_pos_codes = make_positional_encoding(30, 30)\n",
    "plt.plot(sample_pos_codes[:, ::3].numpy());\n",
    "plt.gcf().set_size_inches((15, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Основной класс - языковая модель"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Начнём строить какие-нибудь модельки. Для удобства, определим общий класс — \"языковая модель\". Этот класс будет выполнять некоторые базовые операции вне зависимости от архитектуры нейросети, которая языковую модель будет реализовывать. К таким операциям относится хранение векторов слов, получение кодов позиций, а также предсказание токенов для каждой позиции. Посмотрим на метод \"forward\" и разберём основные шаги. На вход к нам приходит прямоугольная матрица, в ней количество строк соответствует количеству примеров в батче, а количество столбцов — наибольшей длине последовательности. Зная длину последовательности мы можем сгенерировать маску зависимостей, то есть вот эту вот треугольную матрицу из нулей и минус бесконечности. А также мы можем сгенерировать ещё одну маску, которая нам помечает токены за границей последовательности. То есть, если последовательность короче, чем \"max in_len\" (то есть — чем наибольшая длина входной последовательности), то она будет \"добиваться\" нулями до конца, до наибольшей длины, и нам нужно исключить эти нули из рассмотрения, из предсказаний. Для этого мы используем \"padding mask\". Теперь нам нужно получить начальное представление токенов для того, чтобы их подать уже в нейросеть. Вектора токенов у нас будут складываться из двух компонент, а именно: эмбеддинг самого токена и эмбеддинг позиции. Эмбеддинги токенов мы берём просто из таблички, для этого мы используем стандартный модуль из pytorch — nn.embedding. Как обычно, мы помечаем, что нулевой токен — это фиктивный токен, то есть \"padding\". Этот модуль, по сути, осуществляет всего лишь выборку строк из матрицы по индексам. И он позволяет обучать эмбеддинги, что называется, \"end to end\". То есть эмбеддинги будут получать обновления на каждом градиентном шаге. На выходе из эмбеддинг слоя мы уже имеем не двухмерную матрицу, прямоугольную, а трёхмерный тензор. У нас добавилось ещё одно измерение, соответствующее количеству элементов в эмбеддинге. Для того, чтобы получить эмбеддинги позиций, мы используем функцию, которую рассмотрели чуть ранее. Она возвращает нам прямоугольную матрицу размерности [\"длина последовательности\" на \"размер эмбеддинга\"]. То есть, в ней нет измерения, соответствующего количеству примеров в батче. Чтобы иметь возможность сложить два тензора эмбеддингов — то есть, эмбеддинги токенов и эмбеддинги позиции, мы добавляем некоторое фиктивное измерение (добавляем единичку). После этой операции тензоры \"seed_embs\" и \"pos_codes\" будут оба трёхмерными, их можно будет сложить — что мы, собственно, и делаем. Далее к полученным эмбеддингам мы применяем dropout. На самом деле, dropout здесь очень драматично влияет на возможности модели переобучаться. Я предлагаю вам ответить на вопрос — какой dropout важнее: этот, или те dropout, которые находятся в основной нейросети (которая собственно, предсказывает токены). Далее мы подаём признаки токенов в некоторую нейросеть, которая здесь у нас лежит в переменной \"backbone\". Какая это нейросеть — здесь пока здесь не определено, это определяется при создании экземпляра класса \"LanguageModel\". Кроме эмбеддингов мы передаём туда две маски — маску зависимости и маску padding. Нейросеть \"backbone\" возвращает нам, также, трёхмерный тензор такой же размерности, что и была на входе, то есть [\"количество элементов в батче\", \"максимальная длина последовательности\" и \"размер вектора представления\"], (то есть рабочая размерность). Размерность модели, то есть величина последнего измерения тензора, не соответствует размеру словаря — это вполне нормально, мы не хотим растить ширину модели линейно с ростом количества токенов в словаре (это слишком дорого). Поэтому нам нужен дополнительный слой, который преобразует какой-то вектор в распределение вероятностей токенов в словаре. Для этого мы используем простой линейный слой. Когда вы подаёте на вход линейному слою какой-то многомерный тензор, то линейная проекция применяется к последнему измерению. Выходной тензор у нас представляет логиты (то есть он представляет не сами вероятности, распределения вероятностей, а логиты). Чтобы получить распределение вероятностей из логитов, нам нужно применить к этому тензору softmax по последнему измерению. Но мы не будем это делать, потому что мы знаем, что после логитов сразу пойдёт кросс-энтропия, а если у нас софтмакс и кросс энтропия, то можно софтмакс не брать полностью, можно лишние экспоненты и логарифмы сократить, и получить большую вычислительную стабильность. Не будем считать софтмакс на выходе модели. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T18:28:07.079279Z",
     "start_time": "2019-11-05T18:28:07.031056Z"
    }
   },
   "outputs": [],
   "source": [
    "class LanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_size, backbone, emb_dropout=0.0):\n",
    "        super().__init__()\n",
    "        self.embedding_size = embedding_size\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_size, padding_idx=0)\n",
    "        self.emb_dropout = nn.Dropout(emb_dropout)\n",
    "        self.backbone = backbone\n",
    "        self.out = nn.Linear(embedding_size, vocab_size)\n",
    "    \n",
    "    def forward(self, seed_token_ids):\n",
    "        \"\"\"\n",
    "            seed_token_ids - BatchSize x MaxInLen\n",
    "        \"\"\"\n",
    "        batch_size, max_in_length = seed_token_ids.shape\n",
    "\n",
    "        seed_padding_mask = seed_token_ids == 0\n",
    "        dependency_mask = make_target_dependency_mask(max_in_length) \\\n",
    "            .to(seed_token_ids.device)\n",
    "        \n",
    "        seed_embs = self.embeddings(seed_token_ids)  # BatchSize x MaxInLen x EmbSize\n",
    "        pos_codes = make_positional_encoding(max_in_length,\n",
    "                                             self.embedding_size).unsqueeze(0).to(seed_embs.device)\n",
    "        seed_embs = seed_embs + pos_codes\n",
    "        seed_embs = self.emb_dropout(seed_embs)\n",
    "\n",
    "        # BatchSize x TargetLen x EmbSize\n",
    "        target_features = seed_embs\n",
    "        target_features = self.backbone(seed_embs,\n",
    "                                        mask=dependency_mask,\n",
    "                                        src_key_padding_mask=seed_padding_mask)\n",
    "        logits = self.out(target_features)  # BatchSize x TargetLen x VocabSize\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Утилиты для обучения - функция потерь и расписание изменения длины градиентного шага"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определим парочку стандартных вспомогательных компонент. Во-первых, нам нужна функция потерь. В качестве функции потерь мы будем использовать кросс-энтропию, но, перед тем, как подавать данные в функцию расчёта кросс-энтропии, мы просто их вытянем в линию. То есть мы, как бы, забудем, что у нас были отдельно — примеры в батче, и отдельно — токены в предложениях. Мы смешаем все предложения в кучу. Для оценки кросс-энтропии это совершенно не важно. А ещё мы скажем что нужно игнорировать padding. Это сделает фактическое распределение классов сильно менее скошенным и улучшит сходимости. Хотя вы можете выключить это и посмотреть, как это повлияет. А также, другая стандартная утилитка — это расписание изменения длины градиентного шага. Мы говорим, тем самым, что, если в течение двадцати эпох значение функции потерь на валидации не уменьшилось существенно, тогда — уменьшить длину градиентного шага в два раза. Использование такого \"расписания\" позволяет исключить ошибки, когда вы устанавливаете слишком большой \"learning rate\" при обучении, то есть если вы поставите слишком большой \"learning rate\", то модель просто не будет учиться и, в результате, \"learning rate\" автоматически уменьшится. Да, он уменьшится не сразу (а спустя вот такое вот количество эпох), но, тем не менее, если вы запустили эксперимент на ночь и ушли, то, скорее всего, утром вы получите обученную модель. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T18:28:07.797230Z",
     "start_time": "2019-11-05T18:28:07.774142Z"
    }
   },
   "outputs": [],
   "source": [
    "def lm_cross_entropy(pred, target):\n",
    "    \"\"\"\n",
    "    pred - BatchSize x TargetLen x VocabSize\n",
    "    target - BatchSize x TargetLen\n",
    "    \"\"\"\n",
    "    pred_flat = pred.view(-1, pred.shape[-1])  # BatchSize*TargetLen x VocabSize\n",
    "    target_flat = target.view(-1)  # BatchSize*TargetLen\n",
    "    return F.cross_entropy(pred_flat, target_flat, ignore_index=0)\n",
    "\n",
    "\n",
    "def lr_scheduler(optimizer):\n",
    "    return torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,\n",
    "                                                      patience=20,\n",
    "                                                      factor=0.5,\n",
    "                                                      verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Реализация Transformer из PyTorch 1.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предпримем первую попытку обучить языковую модель, используя реализацию трансформера из библиотеки pytorch. Мы будем использовать не весь трансформер, а только его первую часть — трансформер \"encoder\". Этот вспомогательный класс нам нужен для двух задач. По какой-то причине, стандартная реализация трансформера умеет работать с тензорами, в которых первое измерение соответствует не размеру батча, а длине последовательности, а \"batch_size\" стоит на втором месте. Таким образом, этот класс делает, по сути, всего лишь две вещи. Во-первых, он транспонирует тензор перед подачей в трансформер, транспонирует результаты работы трансформера обратно, и возвращает результат не изменённым. И — вторая важная деталь — это инициализация параметров. По умолчанию, в трансформере используется равномерный шум с амплитудой, подбираемой исходя из количества входных признаков. Эта схема инициализации реализовывается в pytorch функцией \"xavier_uniform\". Таким способом, мы инициализируем все веса, кроме bias, то есть все \"матричные\" веса. ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T18:28:09.401017Z",
     "start_time": "2019-11-05T18:28:09.365637Z"
    }
   },
   "outputs": [],
   "source": [
    "class BatchFirstTransformerEncoder(nn.Module):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__()\n",
    "        self.impl = nn.TransformerEncoder(*args, **kwargs)\n",
    "        self.initialize_weights()\n",
    "    \n",
    "    def forward(self, src, *args, **kwargs):\n",
    "        src = src.transpose(0, 1).contiguous()  # MaxInLen  x BatchSize x EmbSize\n",
    "        result = self.impl(src, *args, **kwargs)  # TargetLen x BatchSize x EmbSize\n",
    "        result = result.transpose(0, 1).contiguous()  # BatchSize x TargetLen x EmbSize\n",
    "        return result\n",
    "    \n",
    "    def initialize_weights(self):\n",
    "        for param in self.impl.parameters():\n",
    "            if param.dim() > 1:\n",
    "                nn.init.xavier_uniform_(param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наша модель реализуется базовым классом \"LanguageModel\". Мы передаём размер словаря (это 1000, в данном случае), размер эмбеддинга (256 элементов) и он же — это размер модели. А также передаём туда экземпляр backbone нейросети, то есть — это та нейросеть, которая будет производить агрегацию контекстов, будет сравнивать слова с соседними словами и, таким образом, на вход она будет получать эмбеддинги отдельных токенов, а на выходе у неё уже будут эмбеддинги фраз, предложений. То есть — более крупных конструкций. Мы будем использовать три слоя self-attention и будем использовать не очень большой dropout. Как мы видим, модель содержит примерно 2 миллиона параметров. Это не очень большая модель (по современным меркам). Попробуем обучить модель. Для этого мы будем использовать нашу стандартную функцию, которую мы использовали весь курс до этого. На что здесь нужно обратить внимание — это то, что мы передаём сюда функцию потерь, \"lm cross entropy\", то есть — это та функция, которую мы определили, это не просто функция кросс-энтропии из pytorch. А также здесь стоит большой batch_size. А ещё я поставил большое количество эпох здесь. То есть, я ожидаю, что модель будет сходиться не очень быстро. В самом деле, на каждой эпохе мы делаем всего лишь 11 итераций, потому что у нас небольшой датасет (как мы помним, в нём примерно 6000 обучающих фрагментов и 3000 тестовых), и при таком большом размере батча мы делаем маленькое количество обновлений, поэтому нам нужно побольше эпох. Зато каждая эпоха проходит очень быстро. В моём случае, потребовалось примерно 800 эпох, то есть чуть больше чем 8000 градиентных шагов, чтобы модель более-менее сошлась. Сходимость модели мы проверяем по среднему значению функции потерь на отложенной выборке. То есть, спустя примерно 800 тысяч шагов, функция потерь на валидации перестала улучшаться, поэтому мы досрочно остановили обучение. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T18:28:10.550078Z",
     "start_time": "2019-11-05T18:28:10.425261Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество параметров 2094312\n"
     ]
    }
   ],
   "source": [
    "torch_transf_model = LanguageModel(tokenizer.vocab_size(),\n",
    "                                   256,\n",
    "                                   BatchFirstTransformerEncoder(\n",
    "                                       nn.TransformerEncoderLayer(\n",
    "                                           d_model=256,\n",
    "                                           nhead=16,\n",
    "                                           dim_feedforward=512,\n",
    "                                           dropout=0.1),\n",
    "                                       num_layers=3),\n",
    "                                   emb_dropout=0.1)\n",
    "print('Количество параметров', get_params_number(torch_transf_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T18:28:58.797642Z",
     "start_time": "2019-11-05T18:28:34.626744Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (best_val_loss,\n",
    "#  best_torch_transf_model) = train_eval_loop(torch_transf_model,\n",
    "#                                             train_dataset,\n",
    "#                                             test_dataset,\n",
    "#                                             lm_cross_entropy,\n",
    "#                                             lr=2e-3,\n",
    "#                                             epoch_n=2000,\n",
    "#                                             batch_size=512,\n",
    "#                                             # device='cuda',\n",
    "#                                             early_stopping_patience=50,\n",
    "#                                             max_batches_per_epoch_train=1000,\n",
    "#                                             max_batches_per_epoch_val=1000,\n",
    "#                                             lr_scheduler_ctor=lr_scheduler)\n",
    "\n",
    "# Хорошая практика — сохранять модели на промежуточных итерациях для того чтобы если, например, \n",
    "# вам придётся досрочно остановить обучение или вы захотите усреднить модели (веса моделей с \n",
    "# разных итераций) между собой (это, кстати, хорошая практика, она позволяет немного улучшить качество). \n",
    "# В данном случае мы сохраняем только последнюю лучшую модель и тут же её загружаем, чтобы поиграться немножко. \n",
    "\n",
    "# Если Вы запускаете ноутбук на colab или kaggle, добавьте в начало пути ./stepik-dl-nlp\n",
    "# torch.save(best_torch_transf_model.state_dict(), './models/4.6.war_and_peace_torch_transf_best.pth')\n",
    "\n",
    "# Если Вы запускаете ноутбук на colab или kaggle, добавьте в начало пути ./stepik-dl-nlp\n",
    "torch_transf_model.load_state_dict(torch.load('./models/4.6.war_and_peace_torch_transf_best.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Генерация текста с помощью языковой модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Жадная генерация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как вы помните из лекции, существует два основных подхода к декодированию текста из языковой модели. Это полностью жадный алгоритм декодирования — то есть, когда мы на каждом шаге берём наиболее вероятный токен. И, при этом, наиболее вероятный токен мы выбираем без учёта совместного распределения токенов (то есть — вот на этом шаге модель сказала, что токен \"А\" самый лучший — мы его и берём вне зависимости от того, какой следующий токен может быть, или предыдущий). Этот алгоритм мы реализовали в нашей библиотеке в классе \"GreedyGenerator\". Он получает на вход обученную модель и \"tokenizer\". А затем он будет получать на вход текст и выдавать новый текст. Собственно, алгоритм предельно простой — сначала мы токенизируем наше предложение. Затем мы делаем некоторое количество шагов, но не более заданного числа шагов. И, на каждом шаге, мы полностью перевычисляем модель, то есть мы берём все входные токены, которые накопили к данному шагу, заворачиваем их в тензор, копируем на видеокарту и прогоняем через модель, а потом выбираем наиболее вероятный последний токен. Здесь \"batch_size\" равен 1, то есть мы берём в этом \"indexer\" первый элемент батча (он соответствует нашему предложению) и последний элемент в последовательности. Таким образом, после взятия этих индексов у нас на выходе будет вектор размерности, соответствующей размеру словаря. И мы просто берём токен с наибольшим весом из этого вектора. Как вы помните, наша модель возвращает не распределение вероятностей, а логиты, то есть это какие-то ненормированное числа. Чтобы получить распределение вероятностей, в этом случае, нам нужно ещё софтмакс применить к этим векторам. Но если мы хотим делать только \"arg max\", то нам не нужен \"softmax\", потому что он сглаживает величины, приводит их в диапазон от нуля до единицы, но он их не переупорядочивает, а значит точка максимума не изменится. Вот мы выбираем лучший токен, используя всего лишь предсказание модели именно для этой позиции. Если на очередном шаге мы предсказали конец последовательности, то мы прекращаем генерировать дальше. А если это ещё не конец последовательности, то мы добавляем текущий токен к нашему списку токенов и снова засовываем это всё в модель на следующей итерации. Затем, когда мы сделали достаточное количество шагов, мы просто декодируем список номеров токенов в строку (всё просто). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T18:29:02.366423Z",
     "start_time": "2019-11-05T18:29:02.329495Z"
    }
   },
   "outputs": [],
   "source": [
    "greedy_generator = GreedyGenerator(torch_transf_model, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, что же наша модель может генерировать. На вход модели мы подаём какой-то небольшой фрагмент текста. Хочу обратить ваше внимание, что мы подаём не только фрагменты текстов, но даже фрагменты слова. То есть — мы не полностью подали последнее слово, и модель сгенерировала на выходе вот такой фрагмент. То есть она, во-первых, закончила слово, а потом продолжила относительно связным текстом. У неё даже получилось смешать французский и русский язык. Обратите внимание, что данная реализация — она не очень эффективная, потому что она полностью перевычисляет всю модель, хотя, казалось бы, мы можем часть активаций сохранить, потому что когда мы в цикле в \"greedy_generator\" выбираем следующий лучший токен, мы всё равно берём все предыдущие токены, прогоняем их через модель, и, активации на большом количестве слоёв — они будут те же самые. То есть, казалось бы, их можно закэшировать и не прогонять одни и те же токены через модель повторно. Просто закэшировав активации. Но реализация этого не очень очевидная, более того, она достаточно сложная, и поэтому в семинаре мы не стали её делать. Также на экране вы видите парочку других примеров, которые были сгенерированы моделью из практически того же текста, но с небольшими изменениями. Мы видим что, несмотря на то, что изменения в исходном тексте небольшие, результирующий текст кардинально меняется"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T18:29:03.175509Z",
     "start_time": "2019-11-05T18:29:02.921960Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "сказала княжна, оглядывая Бона неприятноей, сидевшего груди, которая была на своем рнена, 2 рными подле него. - Позвольте мне прине\n",
      "смеялась княжна, оглядывая Наполеона со всейного и красной ртерьвой адъютанта, Борис, видимо с трудом приделихитектор.\n",
      "сказала княжна, оглядывая Кутуз, как будто удивляют, наблуку, счится на может, - сказал штабно по-остотостью, которую получили\n",
      "сказал Кутузов, оглядывая Наполеона продаживалась повторядка и, видимо, счившим свой новую ребенком, как будто везде укало, до и\n"
     ]
    }
   ],
   "source": [
    "print(greedy_generator('сказала княжна, оглядывая Бона'))\n",
    "print(greedy_generator('смеялась княжна, оглядывая Наполе'))\n",
    "print(greedy_generator('сказала княжна, оглядывая Кутуз'))\n",
    "print(greedy_generator('сказал Кутузов, оглядывая Наполеона'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Только что для генерации текста мы использовали алгоритм жадного поиска. Какими свойствами, по вашему мнению, он обладает?\n",
    "+ +При жадном поиске мы можем сгенерировать токен конца предложения слишком рано, никак это исправить уже не получится\n",
    "+ +Жадный поиск не гарантирует обнаружения оптимального решения: возможно, выбрав менее вероятную букву сейчас, на следующем шаге мы сможем сделать выбор так, что результирующая вероятность нежадного варианта будет выше\n",
    "- -Жадный поиск позволяет одновременно оценивать вероятности для нескольких вариантов, сохраняя древовидную структуру возможных токенов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Генерация с помощью лучевого поиска - Beam Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Более практичный способ декодирования текста (он даёт более хорошие результаты, более качественные тексты) — это использование лучевого поиска. Упрощённый вариант лучевого поиска мы реализовали в классе \"BeamGenerator\". У него точно такой же интерфейс, как и у \"GreedyGenerator\". Давайте посмотрим, как он работает. На экране вы видите код лучевого поиска. На вход функция принимает исходный текст, а также параметры лучевого поиска. Наибольшее количество шагов — это, по сути, наибольшее количество токенов, которые мы можем добавить к исходной последовательности, это количество лучших гипотез, лучших вариантов декодирования, которое нам нужно вернуть из этой функции. Ширина луча — это количество наилучших промежуточных вариантов, которое мы будем хранить в процессе декодирования. Как и в прошлый раз, начинаем мы с того, что преобразовываем текст в последовательность токенов. Две самые важные переменные, которые мы будем обновлять в процессе генерации: первая — это список промежуточных гипотез (или частичных гипотез). Этот список будет содержать пары (то есть кортежи из двух элементов). На первом месте кортежа будет стоять вес, то есть какая-то оценка правдоподобности этой гипотезы, а на втором месте — собственно, сама гипотеза (в виде списка токенов). На самом деле, эта переменная — это не просто список. Мы будем поддерживать эту переменную в виде очереди с приоритетами, то есть мы будем её пересортировывать после добавления нового элемента каждый раз, чтобы на первом месте стояла гипотеза с наилучшим score (с наилучшей оценкой правдоподобности). Второй важный список — это список готовых гипотез, то есть, когда мы уже либо сделали наибольшее количество шагов, либо мы дошли до конца последовательности, то мы прекращаем генерировать из данной гипотезы и мы перемещаем её в список готовых гипотез. Это список, из которого будет формироваться результат работы этой функции. Для того, чтобы было удобно реализовывать очереди с приоритетами, в python есть пакет \"heap queue\", то есть это \"очередь куча\". В нём есть базовые операции для работы с кучей и, соответственно, с очередью с приоритетами. Если вы не знаете, что такое \"куча\" и \"очередь с приоритетами\", то мы оставим ссылку на материалы, которые вы можете почитать и освежить свои знания в этой области. Функция \"heap pop\" возвращает нам элемент с головы кучи, то есть это элемент с наименьшим текущем скором. То есть библиотека \"heap queue\" реализовывает кучу на минимум. То есть, на вершине кучи лежит наименьший элемент. Эта функция возвращает нам элемент списка \"partial hypothesis\". Как мы помним, этот список содержит кортежи. На первом месте кортежа стоит score, на втором месте кортежа стоит гипотеза в виде списка токенов. Следующим шагом мы кладём нашу текущую гипотезу в модель и получаем новое предсказание для последнего токена. Здесь мы не можем работать с исходными логитами, нам нужно как-то нормировать. Но сами вероятности от нуля до единицы нам не очень удобны, потому что правдоподобность целой гипотезы будет считаться как произведение вероятностей. P(A)*P(B)*P(C)... и, таким образом, если у нас хотя бы одна из этих вероятностей достаточно маленькая, то всё произведение устремится к нулю. Это очень неудобно — мы очень быстро выйдем за пределы точности вычислений и эта оценка правдоподобия станет бесполезной. Вместо этого мы будем использовать log-вероятность. Напомню, что, если мы работаем с логарифмированными вероятностями, то у нас произведение заменяется на сумму. Да, эти логарифмы — это большие по модулю отрицательные числа, но, с помощью операции сложения, нам гораздо сложнее выйти за пределы точности, и поэтому, на практике, используют часто именно логарифмированные вероятности. Чтобы получить логарифмированные вероятности мы применяем не \"softmax\", а \"log softmax\". А затем выбираем k токенов с наибольшей log-вероятностью из этого списка. Далее мы итерируемся по списку k лучших вариантов и добавляем новые гипотезы в нашу очередь. Как мы это делаем? Во-первых, мы преобразовываем тензоры в числа — так, чтобы не тащить за собой объекты pytorch. Это нам экономит память, если бы мы этого не делали, то у нас бы утекала память. Затем нам нужно посчитать новую оценку правдоподобности гипотезы. Оценку правдоподобности гипотезы мы считаем как log-вероятность этой гипотезы, делённую на корень из длины этой гипотезы в токенах. Такую дополнительную нормализацию, то есть деление на корень из длины, обычно используют для того, чтобы в процессе поиска мы не предпочитали слишком короткие гипотезы, потому что понятно — когда мы перемножаем много вероятностей или складываем много отрицательных чисел — score, в принципе, сильно падает, и поэтому более короткие гипотезы априорно оказываются более вероятными. Но мы этого не хотим, поэтому мы делим score на корень из длины. Далее мы обновляем нашу гипотезу, то есть дописываем в неё токены, и кладём эту гипотезу либо в список финальных гипотез (если эта гипотеза уже достаточно длинная или мы на этом шаге вы выбрали токен конца последовательности), либо мы кладём её в нашу очередь, когда мы говорим, что — \"ага, начиная с этой гипотезы мы можем продолжить наш поиск\". Далее мы обрезаем нашу очередь. То есть мы оставляем в нашей очереди только заданное количество наилучших гипотез. Если бы мы этого не делали, то наш поиск, в принципе, бы выродился в полный перебор и нам бы не хватило никакой памяти для этого. Если \"beam_size\" равен единице, то, по сути, \"beam search\" откатывается, деградируя до \"полностью жадного\"[1] алгоритма. Поэтому мы должны регулировать значением параметра \"beam_size\" то, насколько мы хотим перебирать разные варианты. Чем больше \"beam_size\", тем больше времени мы потратим, тем больше памяти мы потратим. Но, скорее всего, мы получим более правдоподобный текст (хотя — не факт, если наша модель переобучилась, то необязательно мы получим более правдоподобный текст). Такие итерации мы повторяем до тех пор, пока наша очередь не пуста. А именно — она пополняется тогда, когда мы кладём в неё частичные гипотезы, не очень длинные — не законченные фрагменты текста. Она перестаёт пополняться тогда, когда у нас уже накапливаются очень длинные гипотезы или когда мы постепенно выбираем в качестве продолжения токен конца последовательности. Итак, пара операций, которые нам нужно сделать уже после цикла. Мы накопили какой-то список финальных гипотез, нам нужно декорировать их в тексты и выбрать заданное количество наилучших гипотез — всё это возвращается назад. То есть, эта функция возвращает нам список пар (вот она возвращает нам список пар). Первый элемент пары — это score, то есть оценка правдоподобности текста, и второй элемент — это, собственно, сам текст. Необходимо обратить внимание на вот это место (old_denorm_score-token_score) — у нас token_score — это отрицательное число, это логарифм вероятности, и чем это число меньше (то есть, чем оно больше по модулю), тем менее вероятен этот токен. А мы помним, что модуль \"heap queue\" в python реализует кучу на минимум. Поэтому нам нужно, как бы, накапливать score со знаком \"минус\" — так, чтобы минимальный score был у самой правдоподобной гипотезы. Поэтому мы здесь используем минус — мы вычитаем из накопленного score, score текущего токена.\n",
    "[1] Тема жадного декодирования и лучевого поиска также будет рассматриваться в лекции про seq2seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T18:29:08.328662Z",
     "start_time": "2019-11-05T18:29:08.294006Z"
    }
   },
   "outputs": [],
   "source": [
    "beam_generator = BeamGenerator(torch_transf_model, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь обратимся к тому, что же он нагенерировал. Первое, что мы видим — это то, что beam search работает дольше. Раньше нам требовалось полторы секунды, чтобы сгенерировать одно предложение, теперь, чтобы сгенерировать 5 вариантов, нам нужно 8 секунд. Пока что, разница небольшая. Надо заметить, что эта реализация \"beam search\" тоже не самая эффективная, по той же причине — мы никак не используем кэширование. На экране 5 лучших вариантов, которые получилось сгенерировать, вы видите score, отсортированные по возрастанию (напомню, что самый лучший score — это самый маленький score, потому, что это \"минус сумма log-вероятностией\"). Как вы видите, все тексты содержат большой общий фрагмент, отличается только концовка. Наиболее вероятная причина этого — это чрезмерная уверенность модели. Таким образом, если мы отклоняемся от единственного, наиболее вероятного варианта декодирования, хотя бы чуть-чуть, то score уже очень сильно ухудшается и у других вариантов нету шансов удержаться внутри луча. В качестве домашнего задания я предлагаю вам побороться с этой чрезмерной уверенностью и повысить разнообразие вариантов генерации. Один из возможных способов борьбы с чрезмерной уверенностью — это сглаживание меток, то есть можно перевесить метки так, чтобы они стали менее контрастными, чтобы кросс-энтропия не давала очень сильный штраф. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T18:29:10.573399Z",
     "start_time": "2019-11-05T18:29:09.653198Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****\n",
      "3.8039367890591738\n",
      "сказала княжна, оглядывая Наполеоном прыгнулась и солдатс выросшее обнял его дававшим до положения полкового командира. Раздра\n",
      "\n",
      "****\n",
      "4.122018043246527\n",
      "сказала княжна, оглядывая Наполеоном прыгнулась и солдатс выросшее обнял его дававшим до положения полкового командира. Раздры\n",
      "\n",
      "****\n",
      "4.126380466417055\n",
      "сказала княжна, оглядывая Наполеоном прыгнулась и солдатс выросшее обнял его дававшим до положения полкового командира и лошадей, веро\n",
      "\n",
      "****\n",
      "4.167284298026888\n",
      "сказала княжна, оглядывая Наполеоном прыгнулась и солдатс выросшее обнял его дававшим до положения полкового командира. Раздали\n",
      "\n",
      "****\n",
      "4.18815717071838\n",
      "сказала княжна, оглядывая Наполеоном прыгнулась и солдатс выросшее обнял его дававшим до положения полкового командира. Раздался\n",
      "\n"
     ]
    }
   ],
   "source": [
    "beam_gen_variants = beam_generator('сказала княжна, оглядывая Наполе',\n",
    "                                   beamsize=5,\n",
    "                                   return_hypotheses_n=5)\n",
    "\n",
    "for score, pred_txt in beam_gen_variants:\n",
    "    print('****')\n",
    "    print(score)\n",
    "    print(pred_txt)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте посмотрим, как будут меняться списки сгенерированных предложений в зависимости от настроек лучевого поиска. В первом случае мы использовали ширину луча \"5\". Если использовать ширину луча \"20\", то разнообразие чуть-чуть подрастает. Видим, что первые \"много\" примеров по-прежнему содержат большой общий фрагмент. То есть, они были сгенерированы, на самом деле, из одной гипотезы и отличаются только последней парой шагов. Но дальше мы видим, что, уже какое-то изменение идёт, хотя оно, конечно, тоже не очень большое. По сути, отличие только в том, что здесь дефис добавляется иногда. Другими словами, с такой моделью пока что не получается разнообразия предложить. Другая простая техника для повышения разнообразия предсказаний — это добавление шума в предсказания модели. Как это делать? Мы берём вектор логитов для очередного токена и добавляем туда, например гауссовский шум или, более правильно — шум из распределения Гумбеля. Но эта техника немного не информированная, то есть силу этого шума нужно подбирать руками и мы рискуем получить ерунду. Кроме того, процесс декодирования может стать слишком стохастическим и это приведёт к тому, что запуская его его несколько раз, мы будем получать абсолютно не пересекающееся множество вариантов декодирования. Это сделает нашу модель банально непредсказуемой, её нельзя будет вообще никак использовать на практике. Так что с этим способом повышения разнообразия нужно быть аккуратней, хотя, на этапе обучения, его вполне можно использовать посмелее. Обратите внимание, что с шириной луча \"20\" та же самая работа заняла уже не 8 секунд, а почти 31 секунду. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T18:27:05.050342Z",
     "start_time": "2019-11-05T18:27:05.005Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****\n",
      "2.382470321274086\n",
      "сказала княжна, оглядывая Наполеона. - Ну, полно, Вася, ваше сиятельство, - с тоюда, mon prince, - сказал дежурный штаб-ротмист\n",
      "\n",
      "****\n",
      "2.4674322565790145\n",
      "сказала княжна, оглядывая Наполеона. - Ну, полно, Вася, ваше сиятельство, - с тоюда, mon prince, - сказал дежурный штаб-офицер,\n",
      "\n",
      "****\n",
      "2.605359436769898\n",
      "сказала княжна, оглядывая Наполеона. - Ну, полно, Вася, ваше сиятельство, - с тоюда, mon prince, - сказал дежурный штаб-ротмистро\n",
      "\n",
      "****\n",
      "2.654231978213724\n",
      "сказала княжна, оглядывая Наполеона. - Ну, полно, Вася, ваше сиятельство, - с тоюда, mon prince, - сказал дежурный штаб-ротми и\n",
      "\n",
      "****\n",
      "2.6601492861628477\n",
      "сказала княжна, оглядывая Наполеона. - Ну, полно, Вася, ваше сиятельство, - с тоюда, mon prince, - сказал дежурный штаб-ротко и\n",
      "\n",
      "****\n",
      "2.6715561789836664\n",
      "сказала княжна, оглядывая Наполеона. - Ну, полно, Вася, ваше сиятельство, - с тоюда, mon prince, - сказал дежурный штаб-роткола\n",
      "\n",
      "****\n",
      "2.6930503362617157\n",
      "сказала княжна, оглядывая Наполеона. - Ну, полно, Вася, ваше сиятельство, - с тоюда, mon prince, - сказал дежурный штаб-офицер.\n",
      "\n",
      "****\n",
      "2.7283582622238107\n",
      "сказала княжна, оглядывая Наполеона. - Ну, полно, Вася, ваше сиятельство, - с тоюда, mon prince, - сказал дежурный штаб-роткой,\n",
      "\n",
      "****\n",
      "2.743533420476292\n",
      "сказала княжна, оглядывая Наполеона. - Ну, полно, Вася, ваше сиятельство, - с тоюда, mon prince, - сказал дежурный штаб-роткот\n",
      "\n",
      "****\n",
      "2.807331610829414\n",
      "сказала княжна, оглядывая Наполеона. - Ну, полно, Вася, ваше сиятельство, - с тоюда, mon prince, - сказал дежурный штаб-роткоб\n",
      "\n",
      "****\n",
      "2.8095323928181073\n",
      "сказала княжна, оглядывая Наполеона. - Ну, полно, Вася, ваше сиятельство, - с тоюда, mon prince, - сказал дежурный штаб-ротми на\n",
      "\n",
      "****\n",
      "2.809903554824834\n",
      "сказала княжна, оглядывая Наполеона. - Ну, полно, Вася, ваше сиятельство, - с тоюда, mon prince, - сказал дежурный штаб-ротми по\n",
      "\n",
      "****\n",
      "2.8105425937713258\n",
      "сказала княжна, оглядывая Наполеона. - Ну, полно, Вася, ваше сиятельство, - с тоюда, mon prince, - сказал дежурный штаб-ротколи\n",
      "\n",
      "****\n",
      "2.8141109567005005\n",
      "сказала княжна, оглядывая Наполеона. - Ну, полно, Вася, ваше сиятельство, - с тоюда, mon prince, - сказал дежурный штаб-ротми князь\n",
      "\n",
      "****\n",
      "2.86132057737759\n",
      "сказала княжна, оглядывая Наполеона. - Ну, полно, Вася, ваше сиятельство, - с тоюда, mon prince, - сказал дежурный штаб-ротко,\n",
      "\n",
      "****\n",
      "2.876768712338506\n",
      "сказала княжна, оглядывая Наполеона. - Ну, полно, Вася, ваше сиятельство, - с тоюда, mon prince, - сказал дежурный штаб-роткол\n",
      "\n",
      "****\n",
      "2.8829663895532938\n",
      "сказала княжна, оглядывая Наполеона. - Ну, полно, Вася, ваше сиятельство, - с тоюда, mon prince, - сказал дежурный штаб-ротково\n",
      "\n",
      "****\n",
      "2.8986026680459624\n",
      "сказала княжна, оглядывая Наполеона. - Ну, полно, Вася, ваше сиятельство, - с тоюда, mon prince, - сказал дежурный штаб-ротко.\n",
      "\n",
      "****\n",
      "2.909038902086836\n",
      "сказала княжна, оглядывая Наполеона. - Ну, полно, Вася, ваше сиятельство, - с тоюда, mon prince, - сказал дежурный штаб-ротко улыба\n",
      "\n",
      "****\n",
      "2.909895705370214\n",
      "сказала княжна, оглядывая Наполеона. - Ну, полно, Вася, ваше сиятельство, - с тоюда, mon prince, - сказал дежурный штаб-ротми -\n",
      "\n"
     ]
    }
   ],
   "source": [
    "beam_gen_variants = beam_generator('сказала княжна, оглядывая Наполе',\n",
    "                                   beamsize=20,\n",
    "                                   return_hypotheses_n=20)\n",
    "\n",
    "for score, pred_txt in beam_gen_variants:\n",
    "    print('****')\n",
    "    print(score)\n",
    "    print(pred_txt)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы можем пойти ещё дальше и выбрать ширину луча \"100\". Я предлагаю вам самостоятельно поэкспериментировать с этими параметрами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T18:27:05.051378Z",
     "start_time": "2019-11-05T18:27:05.008Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****\n",
      "2.1899334814827975\n",
      "сказала княжна, оглядывая Наполеон<EOS>\n",
      "\n",
      "****\n",
      "2.6998181540848165\n",
      "сказала княжна, оглядывая Наполеон-прительно покакровился на р храбрости, удерживая друг на друга. Полковник молчал, приятно\n",
      "\n",
      "****\n",
      "2.7443088971934664\n",
      "сказала княжна, оглядывая Наполеон ум вопросительно посмотрел на Анну Михайловну.<EOS>\n",
      "\n",
      "****\n",
      "2.7506848157140187\n",
      "сказала княжна, оглядывая Наполеон-прительно покакровился на р храбрости, удерживая друг на друга. Полковник молчал. - А то\n",
      "\n",
      "****\n",
      "2.800065689334612\n",
      "сказала княжна, оглядывая Наполеон ум вопросительно посмотрел на Анну Михайловну. - Mon charmanteMase, - говорил князь Андрей, оглядывшему на\n",
      "\n",
      "****\n",
      "2.805451713484964\n",
      "сказала княжна, оглядывая Наполеон ум вопросительно посмотрел на Анну Михайловну. - Ma chere, - сказал вдруг, обращаясь к князю Андрею, - перебила его ч\n",
      "\n",
      "****\n",
      "2.8534349211560364\n",
      "сказала княжна, оглядывая Наполеон-прительно покакровился на р храбрости, удерживая друг на друга. Полковник молчал. - А!\n",
      "\n",
      "****\n",
      "2.865310822497766\n",
      "сказала княжна, оглядывая Наполеон ум вопросительно посмотрел на Анну Михайловну. - Ma chere, - сказал вдруг, обращаясь к князю Андрею, - незаконным сы\n",
      "\n",
      "****\n",
      "2.8690326871056544\n",
      "сказала княжна, оглядывая Наполеон ум вопросительно посмотрел на Анну Михайловну. - Ma chere, - сказал вдруг, обращаясь к Анне Павловне, - заговорила она\n",
      "\n",
      "****\n",
      "2.897367313396686\n",
      "сказала княжна, оглядывая Наполеон ум вопросительно посмотрел на Анну Михайловну. - Mon charmanteMages, 116 - сказал он. Болконский\n",
      "\n",
      "****\n",
      "2.992818800481488\n",
      "сказала княжна, оглядывая Наполеон ум вопросительно посмотрел на Анну Михайловну. - Mon charmanteMage d'agon d'Autri\n",
      "\n",
      "****\n",
      "2.995579486114585\n",
      "сказала княжна, оглядывая Наполеон ум<EOS>\n",
      "\n",
      "****\n",
      "3.0160276306415605\n",
      "сказала княжна, оглядывая Наполеон ум вопросительно посмотрел на Анну Михайловну. - Mon charmanteMage d'agon d'Ausuis\n",
      "\n",
      "****\n",
      "3.0262129903081934\n",
      "сказала княжна, оглядывая Наполеон ум вопросительно посмотрел на Анну Михайловну. - Mon charmanteMase, - говорил он, - особенно тогда как будто не\n",
      "\n",
      "****\n",
      "3.037891474099283\n",
      "сказала княжна, оглядывая Наполеон ум вопросительно посмотрел на Анну Михайловну. - Ma chere, - сказал вдруг, обращаясь к австрийскому. - G\n",
      "\n",
      "****\n",
      "3.042640427049892\n",
      "сказала княжна, оглядывая Наполеон как будто<EOS>\n",
      "\n",
      "****\n",
      "3.044456046606813\n",
      "сказала княжна, оглядывая Наполеон ум вопросительно посмотрел на Анну Михайловну. - Mon charme de pret, - сказала княжна Марья. - Ah! je\n",
      "\n",
      "****\n",
      "3.0587938513257598\n",
      "сказала княжна, оглядывая Наполеон ум вопросительно посмотрел на Анну Михайловну. - Mon charmanteMase, - говорил он, - особенно тогда улыбаясь.\n",
      "\n",
      "****\n",
      "3.0612109060233332\n",
      "сказала княжна, оглядывая Наполеон-прительно покакровился на него, ожидаял ее строже и взглянула. Княжна Марья сначала удерживала\n",
      "\n",
      "****\n",
      "3.06630576706719\n",
      "сказала княжна, оглядывая Наполеон ум вопросительно посмотрел на Анну Михайловну. - Ma chere, - сказал вдруг, обращаясь к австрийский генералу нац\n",
      "\n"
     ]
    }
   ],
   "source": [
    "beam_gen_variants = beam_generator('сказала княжна, оглядывая Наполе',\n",
    "                                   beamsize=100,\n",
    "                                   return_hypotheses_n=20)\n",
    "\n",
    "for score, pred_txt in beam_gen_variants:\n",
    "    print('****')\n",
    "    print(score)\n",
    "    print(pred_txt)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Только что для генерации текста мы использовали алгоритм BEAM.  \n",
    "Выберите верные, по вашему мнению, утверждения об этом алгоритме.\n",
    "- +BEAM без нормализации чаще отдает предпочтение коротким последовательностям.\n",
    "- +BEAM является компромиссом между скоростью работы и количеством найденных вариантов.\n",
    "- -BEAM работает быстрее жадного поиска."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Собственная реализация MultiHeadAttention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы загрузили датасет, мы обучили токенизатор, собственно токенизировали датасет, мы реализовали несколько базовых классов и утилит для того, чтобы выполнить обучение. То есть, это класс LanguageModel, это обёртка для трансформера, которая транспонирует тензоры и инициализирует веса, это функция потерь, это расписание для изменения длины градиентного шага. Затем мы обучили модель, используя, в качестве backbone (то есть в качестве основной нейросети) реализацию трансформера из библиотеки pytorch. Затем мы взяли два алгоритма декодирования — это \"полностью жадный\" и \"beam search\", то есть умеренно жадный алгоритм, и проверили, что, в целом, модель как-то учится и что-то генерирует. И это, в принципе, выглядит как какой-то более-менее связный текст.  \n",
    "Теперь пойдём дальше и заменим реализацию трансформера из библиотеки pytorch на нашу реализацию. Будем строить реализацию трансформера. Самый базовый элемент — это \"механизм внимания с несколькими головами\" (или \"multi-head attention\"). Это достаточно универсальная реализация механизма внимания, хотя и несколько упрощённая относительно той реализации, которая входит в библиотеку pytorch. На вход механизму внимания подаётся три главных последовательности. Это последовательность запросов, последовательность ключей и последовательность значений. Каждая из этих последовательностей представляется четырёхмерным тензором. Физический смысл измерений этого тензора следующий: первое — это размер батча (как обычно), второе измерение — это длина последовательности, третье измерение — это количество \"голов\", то есть, по сути это количество независимых механизмов внимания. \"Multihead attention\" можно реализовать с помощью нескольких \"single head attention\", то есть, с помощью нескольких простых механизмов внимания, в которых все вычисления производятся независимо и последовательно. Данная реализация \"multihead attention\" — она более эффективная, потому что все \"головы\", то есть другими словами, несколько механизмов внимания, вычисляются параллельно. Третье измерение — это количество \"голов\", и четвёртое измерение — это размер вектора. Если мы говорим про последовательность запросов и последовательность ключей, то у них последнее измерение должно быть одинаковое, потому что эти две группы векторов мы будем сравнивать с помощью скалярного произведения. Отдельно есть ещё тензор значений, он тоже четырёхмерный, но у него допускается другое количество элементов в последнем измерении. Кроме этих трёх основных последовательностей, в механизм внимания передаётся две маски. Первая маска — это \"маска паддингов\". Это прямоугольный тензор, в котором количество строк соответствует количеству примеров в батче, а количество столбцов соответствует максимальной длине примера. Этот тензор состоит из ноликов и единичек, и единичками помечаются те элементы, которые выходят за границы последовательности (то есть это \"паддинги\") — это те элементы, которые не нужно учитывать. Вторая маска — это маска зависимости позиций. Она одинакова для всех примеров в батче. Эта маска представляется прямоугольной матрицей. В общем случае — прямоугольной, но в нашем семинаре эту функцию мы будем использовать для реализации механизма \"self-attention\", то есть \"внутреннее внимание\", а там длина последовательности запросов и последовательности ключей одинакова (потому что они вычислены из одной и той же исходной последовательности). Поэтому, в нашем случае, это будет всегда квадратная матрица. Маска зависимости выглядит примерно вот так, как вы видите на экране. Напомню, что строки соответствуют выходным позициям, столбцы — входным позициям, нолик обозначает, что для вычисления вектора признаков для данной выходной позиции можно использовать данную входную позицию. Если в ячейке стоит −infinite — это значит, что нельзя использовать данную входную позицию для данной выходной."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кроме этого, мы хотим иметь возможность включать dropout в механизме внимания. Авторы трансформера рекомендуют делать так. Для этого мы передаём ещё два аргумента. Первый аргумент — это флаг, которые принимает значение \"true\", когда мы находимся в режиме обучения — это значит, что dropout нужно включить. Если мы не в режиме обучения, то dropout выключается. И второй параметр — это число от нуля до единицы, это сила dropout. Если эта переменная равна 0, то, по сути, dropout выключен. Если — равно 1, то dropout зануляет практически все элементы входной последовательности. Эта функция возвращает кортеж из двух элементов. То есть, эта функция возвращает сразу два тензора. Первый тензор — это основной результат работы механизма внимания. То есть, для каждого запроса и для каждой \"головы\" найден новый вектор признаков. Второй тензор возвращать не обязательно, но мы это будем делать для целей визуализации. Это тоже четырёхмерный тензор, который показывает нам оценки значимости или релевантности каждой позиции из последовательности ключей для каждой позиции из последовательности запросов.  \n",
    "\n",
    "1. **\\# BatchSize x ValuesLen x KeysLen x HeadN**  \n",
    "**relevances = torch.einsum('bvhs,bkhs->bvkh', (queries, keys))**  \n",
    "Самый первый шаг в механизме внимания — это сравнение. Здесь мы берём последовательность запросов, последовательность ключей, берём все возможные пары выходной позиции и входной позиции и находим сходство посредством скалярного произведения. Для того, чтобы красиво записать вычисления всех нужных нам оценок сходства, мы используем так называемую \"эйнштейновскую запись\" (мы приложим ссылку для того, чтобы вы могли поизучать, что это такое). Частое это достаточно удобный способ для описания сложных тензорных произведений. Если в двух словах, то — для того, чтобы описать тензорное произведение в эйнштейновской записи мы задаём обозначения для всех измерений входных тензоров. То есть, \"b\" — это \"batch size\", \"v\" — это \"количество запросов\" (то есть длина последовательности запросов), \"h\" — это \"количество голов\", \"s\" — это размерность вектора признаков для каждой позиции, для каждой головы. То же самое для второго тензора — это тензор ключей, здесь всё то же самое, кроме второго измерения, потому что, теоретически, количество запросов и количество ключей могут отличаться, хотя в данном семинаре это не так. И, затем, после знака \"стрелочки\" мы описываем измерения результирующего тензора. Те буквы, которые были слева от стрелочки, но их нету справа от стрелочки, соответствуют измерениям, по которым будет производиться скалярное произведение. Конкретно в этой ситуации у нас уходит буковка \"s\" — это значит, что мы производим скалярное произведение по последнему измерению и немного переворачиваем результирующий тензор — так, чтобы у нас первое измерение соответствовало количеству примеров в батче, второе — количеству запросов (то есть, длине последовательность запросов), третье — количеству ключей и четвёртое количеству \"голов\". Получаем такой вот четырёхмерный тензор. Надо сказать, что запросы и ключи мы сравниваем только внутри одной \"головы\" и только внутри одного примера в батче.  \n",
    "_  \n",
    "2. **\\# замаскировать элементы, выходящие за длины последовательностей ключей**  \n",
    "**padding_mask_expanded = keys_padding_mask[:, None, :, None].expand_as(relevances)**  \n",
    "**relevances.masked_fill_(padding_mask_expanded, float('-inf'))**  \n",
    "Затем мы применяем наши маски. Во-первых, мы применяем маску паддингов. Напомню, что эта маска содержит нолики для значимых токенов и единички для токенов выравнивания (паддингов). Применение этой маски заключается в том, что мы записываем  -infinite во все позиции тензора сходства, соответствующие сравнениям какого-либо запроса с ключами, соответствующими паддингу. Напомню, что, когда мы будем применять софтмакс для того, чтобы получить нормированные оценки сходства, позиции, на которых стояло -infinite получат значение \"0\".  \n",
    "_  \n",
    "3. **\\# замаскировать пары <выходная позиция, входная позиция>**  \n",
    "**relevances = relevances + dependency_mask[None, :, :, None].expand_as(relevances)**  \n",
    "**normed_rels = F.softmax(relevances, dim=2)**  \n",
    "**normed_rels = F.dropout(normed_rels, weights_dropout, is_training)**  \n",
    "Далее, аналогичным образом, мы применяем маску зависимостей. Как мы помним, в маске зависимостей тоже есть \"нолики\", есть -infinite. Когда мы к какому-то конечному числу добавляем -infinite, то результат становится равным -infinite. Обратите внимание на вот эту странную запись — мы ставим квадратные скобки, как будто хотим выбрать из тензора какие-то строки или столбцы (то есть, проиндексировать тензор), а потом передаём туда None. Что это за ерунда? Такую запись можно использовать для того, чтобы добавить измерения в тензор. Это примерно то же самое, что вызвать несколько раз метод \"unsqueeze\" из pytorch. Двоеточие соответствует взятию всех элементов по соответствующему измерению. Таким образом в выделенной строчке мы добавляем два измерения на первую позицию (то есть, как бы, добавляем измерения для размера батча), и на последнюю позицию (то есть, добавляем измерения для количества голов). Далее мы применяем софтмакс по третьему измерению. То есть по измерению, соответствующему количеству ключей (напомню, что измерения нумеруются с нуля). Таким образом, сумма весов в тензоре \"normed rels\" для каждой выходной позиции, для каждого элемента батча и для каждой \"головы\" будет равна 1. Далее мы применяем dropout, причём применяем его не на матрицу признаков, как это обычно делается, а мы применяем его поверх нормированных оценок сходства. Таким образом, мы исключаем зависимости каких-то выходных позиций от входных. Это достаточно хороший способ регуляризации в данном случае.  \n",
    "_  \n",
    "4. **# BatchSize x ValuesLen x KeysLen x HeadN x 1**  \n",
    "**normed_rels_expanded = normed_rels.unsqueeze(-1)**  \n",
    "**# BatchSize x 1 x KeysLen x HeadN x ValueSize**  \n",
    "**values_expanded = values.unsqueeze(1)**  \n",
    "**# BatchSize x ValuesLen x KeysLen x HeadN x ValueSize**  \n",
    "**weighted_values = normed_rels_expanded * values_expanded**  \n",
    "**result = weighted_values.sum(2)  # BatchSize x ValuesLen x HeadN x ValueSize**  \n",
    "Далее нам нужно взять тензор весов (то есть тензор \"normed rels\") и тензор значений (\"values\") и перемножить их и сложить так, чтобы получить новый вектор признаков для каждой выходной позиций. Здесь мы сначала добавляем измерение в исходные тензоры, так, чтобы у них были одинаковые количества измерений, а затем применяем операцию поэлементного перемножения. И в numpy, и в pytorch есть так называемый механизм \"broadcasting\" — это когда у нас формы тензоров не совпадают, а мы к ним как применяем операцию перемножения или сложения. Рytorch и numpy каким-то образом дополняют размерности этих тензоров, так, чтобы они совпали и операцию можно было выполнить. Одно из базовых правил broadcasting — это когда размерность тензора по какому-то измерению равна единице, мы можем по этому измерению его просто клонировать нужное количество раз. Конечно клонирование, фактически, не выполняется — память дополнительно не выделяется, но, как будто бы, мы клонируем. Таким образом, в результате broadcasting, например, вот это измерение — последнее измерение тензора \"normed rels expanded\" станет равно \"value_size\", то есть количеству признаков для каждого значения. В результате процедуры broadcasting и перемножения мы получаем пятимерный тензор — обратите внимание, что единички (вот эти) были автоматически расширены до соответствующей размерности второго тензора. И, наконец, мы сворачиваем полученный тензор по размерности, соответствующей количеству ключей KeysLen. Таким образом, получаем четырёхмерный тензор, который для каждого примера в батче, для каждой выходной позиции и для каждой головы содержит некоторый вектор признаков, ну, и возвращаем всё."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T18:29:13.586871Z",
     "start_time": "2019-11-05T18:29:13.544216Z"
    }
   },
   "outputs": [],
   "source": [
    "def my_multihead_attention(queries, keys, values,\n",
    "                           keys_padding_mask, dependency_mask,\n",
    "                           is_training,\n",
    "                           weights_dropout):\n",
    "    \"\"\"\n",
    "    queries - BatchSize x ValuesLen x HeadN x KeySize\n",
    "    keys - BatchSize x KeysLen x HeadN x KeySize\n",
    "    values - BatchSize x KeysLen x HeadN x ValueSize\n",
    "    keys_padding_mask - BatchSize x KeysLen\n",
    "    dependency_mask - ValuesLen x KeysLen\n",
    "    is_training - bool\n",
    "    weights_dropout - float\n",
    "    \n",
    "    result - tuple of two:\n",
    "        - BatchSize x ValuesLen x HeadN x ValueSize - resulting features\n",
    "        - BatchSize x ValuesLen x KeysLen x HeadN - attention map\n",
    "    \"\"\"\n",
    "\n",
    "    # BatchSize x ValuesLen x KeysLen x HeadN\n",
    "    relevances = torch.einsum('bvhs,bkhs->bvkh', (queries, keys))\n",
    "    \n",
    "    # замаскировать элементы, выходящие за длины последовательностей ключей\n",
    "    padding_mask_expanded = keys_padding_mask[:, None, :, None].expand_as(relevances)\n",
    "    relevances.masked_fill_(padding_mask_expanded, float('-inf'))\n",
    "    \n",
    "    # замаскировать пары <выходная позиция, входная позиция>\n",
    "    relevances = relevances + dependency_mask[None, :, :, None].expand_as(relevances)\n",
    "    \n",
    "    normed_rels = F.softmax(relevances, dim=2)    \n",
    "    normed_rels = F.dropout(normed_rels, weights_dropout, is_training)\n",
    "    \n",
    "    # BatchSize x ValuesLen x KeysLen x HeadN x 1\n",
    "    normed_rels_expanded = normed_rels.unsqueeze(-1)\n",
    "    \n",
    "    # BatchSize x 1 x KeysLen x HeadN x ValueSize\n",
    "    values_expanded = values.unsqueeze(1)\n",
    "    \n",
    "    # BatchSize x ValuesLen x KeysLen x HeadN x ValueSize\n",
    "    weighted_values = normed_rels_expanded * values_expanded\n",
    "    result = weighted_values.sum(2)  # BatchSize x ValuesLen x HeadN x ValueSize\n",
    "    \n",
    "    return result, normed_rels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self-Attention - это Attention, в котором ключи, значения и запросы вычисляются из элементов одной и той же последовательности"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Это была реализация механизма внимания с несколькими головами и с раздельными последовательностями запросов, ключей и значений. Теперь нам нужно сделать небольшой шажок сторону \"self attention\". Это уже кирпичик, имеющий непосредственное отношение к трансформеру. По сути, \"self-attention\" — это обычный механизм внимания. Самая главная его особенность заключается в том, что ключи, запросы и значения вычисляются из одной и той же последовательности. Посмотрим, как это всё работает. Метод \"forward\" — на вход нам дают одну последовательность. Эта последовательность представляет батч текстов, то есть у нас есть какое-то количество примеров в батче, наибольшая длина текста и последнее измерение соответствует вектору признаков, то есть рабочему размеру модели. Дальше мы берём три простых линейных слоя. По сути, каждый линейный слой параметризуется квадратной матрицей. В принципе, не обязательно брать именно линейный слой — можно навернуть сюда более сложную архитектуру, но не нужно, чаще всего. Итак, мы берём три этих линейных слоя и применяем их к исходной последовательности (queries_flat, keys_flat, values_flat). Таким образом, мы преобразовываем вектор признаков каждого входного элемента независимо от других элементов. Затем мы немного меняем форму, то есть мы последнее измерение (оно обозначается \"model size\") разбиваем на два измерения — это количество голов (то есть, по сути, это количество независимых механизмов внимания) и новое количество признаков. Это новое количество признаков равняется, по сути, \"model size\" делить на количество голов. Как вы видите, запросы, ключи и значения получаются абсолютно одинаково. Отличие заключается только в том, что веса (queries_proj, keys_proj, values_proj) преобразований независимы и они сходятся к разным значениям в ходе обучения. Далее мы берём эти три тензора, берём маски, которые нам передали свыше на вход, и передаём в функцию, которую мы только что рассмотрели — функцию \"my multihead attention\". Также мы передаём туда флаг \"self train\" — этот флаг есть у каждого экземпляра класса \"torch.nn.module\". Он автоматически обновляется, в зависимости от того, находится ли вся модель в режиме обучения, или в режиме предсказания. Как мы помним, функция multihead attention возвращает нам четырёхмерный тензор, мы схлопываем последнее измерение обратно в model size для того, чтобы слои self-attention можно было комбинировать с любыми другими слоями. То есть это удобно — когда форма тензора не меняется после преобразования. А также мы сохраняем карту активации — это позволит нам потом эти карты активации нарисовать и, возможно, получить какие-то знания о том, как работает модель (но — не факт). Важный момент здесь — это вызывать метод \"detach\". Если мы не будем его вызывать, то у нас будет попросту утекать память, потому что каждый тензор хранит ссылки на тензоры, из которых он был получен, и, таким образом, мы будем хранить ссылки на предыдущие батчи, даже. Поэтому, если мы не хотим дальше использовать какой-то тензор в обучении, не хотим прокидывать через него производную, то всегда лучше сделать \"detach\". Итак, это был блок \"self attention\". Вернёмся немножко назад — к конструктору нашего класса \"self attention\", посмотрим, что же нам нужно, чтобы создать экземпляр этого класса. Нам нужен размер модели (суммарное количество признаков по всем головам, model_size), нам нужно количество голов и нам нужен коэффициент dropout. Важно, чтобы размер модели (\"model_size\") делился нацело на количество голов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T18:29:14.090216Z",
     "start_time": "2019-11-05T18:29:14.064361Z"
    }
   },
   "outputs": [],
   "source": [
    "class MyMultiheadSelfAttention(nn.Module):\n",
    "    def __init__(self, model_size, n_heads, dropout=0):\n",
    "        super().__init__()\n",
    "        assert model_size % n_heads == 0, 'Размерность модели должна делиться нацело на количество голов'\n",
    "        self.n_heads = n_heads\n",
    "\n",
    "        self.queries_proj = nn.Linear(model_size, model_size)\n",
    "        self.keys_proj = nn.Linear(model_size, model_size)\n",
    "        self.values_proj = nn.Linear(model_size, model_size)\n",
    "        \n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.last_attention_map = None\n",
    "    \n",
    "    def forward(self, sequence, padding_mask, dependency_mask):\n",
    "        \"\"\"\n",
    "        sequence - BatchSize x Len x ModelSize\n",
    "        padding_mask - BatchSize x Len\n",
    "        dependency_mask - Len x Len\n",
    "        \n",
    "        result - BatchSize x Len x ModelSize\n",
    "        \"\"\"\n",
    "        batch_size, max_len, model_size = sequence.shape\n",
    "        \n",
    "        queries_flat = self.queries_proj(sequence)  # BatchSize x Len x ModelSize\n",
    "        queries = queries_flat.view(batch_size, max_len, self.n_heads, -1)\n",
    "        \n",
    "        keys_flat = self.keys_proj(sequence)  # BatchSize x Len x ModelSize\n",
    "        keys = keys_flat.view(batch_size, max_len, self.n_heads, -1)\n",
    "        \n",
    "        values_flat = self.values_proj(sequence)  # BatchSize x Len x ModelSize\n",
    "        values = values_flat.view(batch_size, max_len, self.n_heads, -1)\n",
    "        \n",
    "        # BatchSize x Len x HeadsN x ValueSize\n",
    "        result, att_map = my_multihead_attention(queries, keys, values,\n",
    "                                                 padding_mask, dependency_mask,\n",
    "                                                 self.training, self.dropout)\n",
    "        result_flat = result.view(batch_size, max_len, model_size)\n",
    "        \n",
    "        self.last_attention_map = att_map.detach()\n",
    "\n",
    "        return result_flat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Один слой трансформера - Self-Attention, Feed-Forward, skip-connections, LayerNorm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Два базовых кирпичика у нас уже есть — это механизм внимания с несколькими головами и механизм \"self-attention\" (то есть, механизм внутреннего внимания). Теперь мы можем собрать слой \"трансформер\". Давайте сразу перейдём к методу forward. Интерфейс у метода forward — такой же, как и у self attention, то есть он принимает на вход входную последовательность — это трёхмерный тензор (батч на длину на размер модели), это маска паддингов (прямоугольная матрица) и маска зависимости позиции (это квадратная матрица). Первым делом мы здесь выполняем агрегацию контекста. То есть мы хотим понять смысл каждого токена в контексте всей входной последовательности. Для этого мы вызываем механизм \"self attention\". Затем, к признакам, которые мы получили из механизма внимания, мы применяем dropout и складываем с исходными признаками последовательности. То есть мы здесь получаем, как бы, \"skip connection\", или это вам может напоминать блок ResNet. Skip connection очень хорошо помогают учить глубокие нейросети. \"Skip connection\" или \"вычисления без нелинейностей\" можно применять в абсолютно любых архитектурах, в реккурентках, свёрточных нейросетях, в трансформере они тоже применяются. И затем к полученным признакам мы применяем \"Layer norm\". Вообще, в обработке последовательностей, такие способы нормализации как \"Batch norm\" не очень удобно применять, потому что они накапливают статистики и непонятно, как вообще статистики считать, когда у нас количество элементов последовательности вообще отличается — может меняться от батча к батчу. Наиболее часто используемый способ нормализации в обработке текстов — это \"Layer norm\", его используют и в рекуррентках, и в трансформере. Хорошо, теперь переменная \"sequence\" у нас содержит признаки с учётом контекста. Механизм внимания хорошо учитывает контекст, но, как нелинейность, он не очень мощный, поэтому давайте применим некоторую нейросеть (независимо) к признакам каждого токена. В классическом трансформере для этого используется двухслойный перцептрон (с двумя линейными слоями, функцией активации ReLU и с dropout). Применять эту нелинейность мы также будем через ResNet-блок, то есть мы суммируем вход нелинейности и выход нелинейности. И, также, второй раз применяем \"Layer norm\". Таким образом, один слой трансформера состоит из двух residual слоёв (то есть двух блоков со skip connection) и первый блок содержит self attention (то есть, агрегирует контекст), а второй блок преобразовывает признаки каждого элемента последовательности независимо от других элементов последовательности. То есть, больше играет роль нелинейности и обогащает модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T18:29:15.069352Z",
     "start_time": "2019-11-05T18:29:15.028453Z"
    }
   },
   "outputs": [],
   "source": [
    "class MyTransformerEncoderLayer(nn.Module):\n",
    "    def __init__(self, model_size, n_heads, dim_feedforward, dropout):\n",
    "        super().__init__()\n",
    "        self.self_attention = MyMultiheadSelfAttention(model_size,\n",
    "                                                       n_heads,\n",
    "                                                       dropout=dropout)\n",
    "        self.first_dropout = nn.Dropout(dropout)\n",
    "        self.first_norm = nn.LayerNorm(model_size)\n",
    "        \n",
    "        self.feedforward = nn.Sequential(\n",
    "            nn.Linear(model_size, dim_feedforward),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(dim_feedforward, model_size),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "        self.second_norm = nn.LayerNorm(model_size)\n",
    "    \n",
    "    def forward(self, sequence, padding_mask, dependency_mask):\n",
    "        att_features = self.self_attention(sequence, padding_mask, dependency_mask)\n",
    "\n",
    "        sequence = sequence + self.first_dropout(att_features)\n",
    "        sequence = self.first_norm(sequence)\n",
    "        \n",
    "        sequence = sequence + self.feedforward(sequence)\n",
    "        sequence = self.second_norm(sequence)\n",
    "        return sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Энкодер Трансформера - стопка из нескольких слоёв"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Мы сделали уже три базовых кирпичика — это механизм внимания с несколькими головами, это self attention и это один слой трансформера. Теперь нам нужно собрать \"encoder трансформер\". По сути, это просто стопка из нескольких слоёв трансформера, который мы только что описали. Для того чтобы создать энкодер для трансформера, мы должны взять несколько экземпляров класса \"my transformer encoding layer\" (это класс, который мы только что описали) и слепить из них последовательность. Кроме того, мы должны здесь проинициализировать веса всех этих слоёв. Эти слои применяются последовательно, каждый принимает на вход результат работы предыдущего. Кроме того, мы передаём в каждый слой одни и те же маски — это маска паддингов и маска зависимостей. Названия переменных здесь выбраны так, чтобы они соответствовали названиям параметров в реализации pytorch, для того, чтобы мы могли просто взять экземпляр этого класса и подставить его вместо стандартного трансформера. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T18:29:15.728916Z",
     "start_time": "2019-11-05T18:29:15.680640Z"
    }
   },
   "outputs": [],
   "source": [
    "class MyTransformerEncoder(nn.Module):\n",
    "    def __init__(self, n_layers, **layer_kwargs):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([\n",
    "            MyTransformerEncoderLayer(**layer_kwargs)\n",
    "            for _ in range(n_layers)\n",
    "        ])\n",
    "        self.initialize_weights()\n",
    "\n",
    "    def forward(self, sequence, mask, src_key_padding_mask):\n",
    "        for layer in self.layers:\n",
    "            sequence = layer(sequence, src_key_padding_mask, mask)\n",
    "        return sequence\n",
    "\n",
    "    def initialize_weights(self):\n",
    "        for param in self.parameters():\n",
    "            if param.dim() > 1:\n",
    "                nn.init.xavier_uniform_(param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Попробуем обучить языковую модель с нашим Трансформером"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаём экземпляр языковой модели уже с нашей реализацией трансформера, передаём туда примерно те же самые параметры. Здесь можно видеть, что количество параметров в нашей реализации немножко меньше, чем в стандартной. В этом семинаре мы сделали более простую реализацию, отказавшись от некоторой гибкости, в угоду понятности и простоте. Обучаем нашу модель. Вы можете заметить, что наша реализация медленнее, стандартная реализация проходит эпоху за 2 с копейками секунды, а здесь требуется 6. Наиболее вероятная причина замедления — это то, что мы использовали перемножение тензоров с помощью энштейновского суммирования, то есть помощью функции \"torch einsum\". Эта функция очень удобная, она гибкая, но она помедленнее. Ничего удивительного в этом нет — бесплатных завтраков не бывает[1]. Мы бы тоже могли обойтись без этой функции, но нам бы пришлось сделать несколько дополнительных транспонирований, в результате мы бы получили гораздо менее читаемый код. Нашей модели также требуется порядка 8-9 тысяч градиентных шагов для того, чтобы сойтись. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T18:29:18.531896Z",
     "start_time": "2019-11-05T18:29:18.460196Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество параметров 1896936\n"
     ]
    }
   ],
   "source": [
    "my_transf_model = LanguageModel(tokenizer.vocab_size(),\n",
    "                                256,\n",
    "                                MyTransformerEncoder(\n",
    "                                    n_layers=3,\n",
    "                                    model_size=256,\n",
    "                                    n_heads=16,\n",
    "                                    dim_feedforward=512,\n",
    "                                    dropout=0.1),\n",
    "                                emb_dropout=0.1)\n",
    "print('Количество параметров', get_params_number(my_transf_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T18:29:30.000482Z",
     "start_time": "2019-11-05T18:29:24.291741Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 0\n",
      "Эпоха: 22 итераций, 5.24 сек\n",
      "Среднее значение функции потерь на обучении 6.338748585094105\n",
      "Среднее значение функции потерь на валидации 6.243571376800537\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 1\n",
      "Эпоха: 22 итераций, 5.24 сек\n",
      "Среднее значение функции потерь на обучении 6.2414961511438545\n",
      "Среднее значение функции потерь на валидации 6.221575546264648\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 2\n",
      "Эпоха: 22 итераций, 5.25 сек\n",
      "Среднее значение функции потерь на обучении 6.192097100344571\n",
      "Среднее значение функции потерь на валидации 6.060164260864258\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 3\n",
      "Эпоха: 22 итераций, 5.26 сек\n",
      "Среднее значение функции потерь на обучении 5.924730149182406\n",
      "Среднее значение функции потерь на валидации 5.757946586608886\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 4\n",
      "Эпоха: 22 итераций, 5.26 сек\n",
      "Среднее значение функции потерь на обучении 5.633466612208974\n",
      "Среднее значение функции потерь на валидации 5.340909671783447\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 5\n",
      "Эпоха: 22 итераций, 5.26 сек\n",
      "Среднее значение функции потерь на обучении 5.255439498207786\n",
      "Среднее значение функции потерь на валидации 4.927377367019654\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 6\n",
      "Эпоха: 22 итераций, 5.26 сек\n",
      "Среднее значение функции потерь на обучении 4.894216147336093\n",
      "Среднее значение функции потерь на валидации 4.630330991744995\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 7\n",
      "Эпоха: 22 итераций, 5.27 сек\n",
      "Среднее значение функции потерь на обучении 4.628094716505571\n",
      "Среднее значение функции потерь на валидации 4.447854328155517\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 8\n",
      "Эпоха: 22 итераций, 5.27 сек\n",
      "Среднее значение функции потерь на обучении 4.448662887920033\n",
      "Среднее значение функции потерь на валидации 4.3259929656982425\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 9\n",
      "Эпоха: 22 итераций, 5.27 сек\n",
      "Среднее значение функции потерь на обучении 4.330244931307706\n",
      "Среднее значение функции потерь на валидации 4.236042642593384\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 10\n",
      "Эпоха: 22 итераций, 5.27 сек\n",
      "Среднее значение функции потерь на обучении 4.235548214478926\n",
      "Среднее значение функции потерь на валидации 4.163877773284912\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 11\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 4.158548008311879\n",
      "Среднее значение функции потерь на валидации 4.104539060592652\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 12\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 4.088256120681763\n",
      "Среднее значение функции потерь на валидации 4.050945234298706\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 13\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 4.023118766871366\n",
      "Среднее значение функции потерь на валидации 3.988761329650879\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 14\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 3.9596124345606025\n",
      "Среднее значение функции потерь на валидации 3.938153791427612\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 15\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 3.900452136993408\n",
      "Среднее значение функции потерь на валидации 3.8781686067581176\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 16\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 3.8434641469608652\n",
      "Среднее значение функции потерь на валидации 3.832400894165039\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 17\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 3.7856700962240044\n",
      "Среднее значение функции потерь на валидации 3.7884600877761843\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 18\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 3.732034683227539\n",
      "Среднее значение функции потерь на валидации 3.747918701171875\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 19\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 3.6819838285446167\n",
      "Среднее значение функции потерь на валидации 3.6979090929031373\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 20\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 3.6325026100332085\n",
      "Среднее значение функции потерь на валидации 3.668026661872864\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 21\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 3.58522583137859\n",
      "Среднее значение функции потерь на валидации 3.634350228309631\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 22\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 3.5420785600488838\n",
      "Среднее значение функции потерь на валидации 3.6032072067260743\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 23\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 3.501683538610285\n",
      "Среднее значение функции потерь на валидации 3.580146908760071\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 24\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 3.4585412415591152\n",
      "Среднее значение функции потерь на валидации 3.5518645286560058\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 25\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 3.4239091222936455\n",
      "Среднее значение функции потерь на валидации 3.5292680501937865\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 26\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 3.384797844019803\n",
      "Среднее значение функции потерь на валидации 3.499595022201538\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 27\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 3.3485042832114478\n",
      "Среднее значение функции потерь на валидации 3.485230231285095\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 28\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 3.3214005015113135\n",
      "Среднее значение функции потерь на валидации 3.4638524055480957\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 29\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 3.2876720428466797\n",
      "Среднее значение функции потерь на валидации 3.4478300333023073\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 30\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 3.2577544234015723\n",
      "Среднее значение функции потерь на валидации 3.4383982181549073\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 31\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 3.2286038507114756\n",
      "Среднее значение функции потерь на валидации 3.422059440612793\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 32\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 3.1989180499857124\n",
      "Среднее значение функции потерь на валидации 3.401842498779297\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 33\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 3.1739241643385454\n",
      "Среднее значение функции потерь на валидации 3.3904772758483888\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 34\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 3.1490213979374277\n",
      "Среднее значение функции потерь на валидации 3.379375696182251\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 35\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 3.127904252572493\n",
      "Среднее значение функции потерь на валидации 3.3659068822860716\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 36\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 3.1006995981389824\n",
      "Среднее значение функции потерь на валидации 3.356380271911621\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 37\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 3.081947510892695\n",
      "Среднее значение функции потерь на валидации 3.344441771507263\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 38\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 3.06184382872148\n",
      "Среднее значение функции потерь на валидации 3.333724093437195\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 39\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 3.038699410178445\n",
      "Среднее значение функции потерь на валидации 3.3274476766586303\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 40\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 3.0234956524588843\n",
      "Среднее значение функции потерь на валидации 3.311714744567871\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 41\n",
      "Эпоха: 22 итераций, 5.30 сек\n",
      "Среднее значение функции потерь на обучении 3.002603379162875\n",
      "Среднее значение функции потерь на валидации 3.303416919708252\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 42\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.98279653895985\n",
      "Среднее значение функции потерь на валидации 3.2996415376663206\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 43\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.963869745081121\n",
      "Среднее значение функции потерь на валидации 3.2938360452651976\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 44\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.945658553730358\n",
      "Среднее значение функции потерь на валидации 3.280404734611511\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 45\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.9287920648401435\n",
      "Среднее значение функции потерь на валидации 3.274797821044922\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 46\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.912965026768771\n",
      "Среднее значение функции потерь на валидации 3.268150520324707\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 47\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.898729833689603\n",
      "Среднее значение функции потерь на валидации 3.262428569793701\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 48\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.883137280290777\n",
      "Среднее значение функции потерь на валидации 3.25565447807312\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 49\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.867734052918174\n",
      "Среднее значение функции потерь на валидации 3.2464915037155153\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 50\n",
      "Эпоха: 22 итераций, 5.30 сек\n",
      "Среднее значение функции потерь на обучении 2.8536473621021616\n",
      "Среднее значение функции потерь на валидации 3.2408969163894654\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 51\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.8432633118195967\n",
      "Среднее значение функции потерь на валидации 3.2389361381530763\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 52\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.8286361369219692\n",
      "Среднее значение функции потерь на валидации 3.22564902305603\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 53\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.8145184733650903\n",
      "Среднее значение функции потерь на валидации 3.227388286590576\n",
      "\n",
      "Эпоха 54\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.798992698842829\n",
      "Среднее значение функции потерь на валидации 3.2190465211868284\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 55\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.786642974073237\n",
      "Среднее значение функции потерь на валидации 3.2163143396377563\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 56\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.7733322273601186\n",
      "Среднее значение функции потерь на валидации 3.2087764501571656\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 57\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.7636104930530894\n",
      "Среднее значение функции потерь на валидации 3.20199875831604\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 58\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.7550533576445146\n",
      "Среднее значение функции потерь на валидации 3.198385500907898\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 59\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.7415396842089566\n",
      "Среднее значение функции потерь на валидации 3.1974868535995484\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 60\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.7265811291607944\n",
      "Среднее значение функции потерь на валидации 3.191457748413086\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 61\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.721801508556713\n",
      "Среднее значение функции потерь на валидации 3.1841748476028444\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 62\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.7110261050137607\n",
      "Среднее значение функции потерь на валидации 3.1819473028182985\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 63\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.7014008326963945\n",
      "Среднее значение функции потерь на валидации 3.1794090032577516\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 64\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.6927710338072344\n",
      "Среднее значение функции потерь на валидации 3.174659824371338\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 65\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.6820594180714\n",
      "Среднее значение функции потерь на валидации 3.167201542854309\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 66\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.674110174179077\n",
      "Среднее значение функции потерь на валидации 3.165957236289978\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 67\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.6665452285246416\n",
      "Среднее значение функции потерь на валидации 3.1568078994750977\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 68\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.6580538641322744\n",
      "Среднее значение функции потерь на валидации 3.1568065643310548\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 69\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.647472294894132\n",
      "Среднее значение функции потерь на валидации 3.1522052764892576\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 70\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.640269311991605\n",
      "Среднее значение функции потерь на валидации 3.152323055267334\n",
      "\n",
      "Эпоха 71\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.629128770394759\n",
      "Среднее значение функции потерь на валидации 3.148580026626587\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 72\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.6251028017564253\n",
      "Среднее значение функции потерь на валидации 3.145537281036377\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 73\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.612328616055575\n",
      "Среднее значение функции потерь на валидации 3.146006202697754\n",
      "\n",
      "Эпоха 74\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.6077844446355645\n",
      "Среднее значение функции потерь на валидации 3.140416383743286\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 75\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.5964638103138316\n",
      "Среднее значение функции потерь на валидации 3.1390445470809936\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 76\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.5894310907884077\n",
      "Среднее значение функции потерь на валидации 3.133563780784607\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 77\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.585996833714572\n",
      "Среднее значение функции потерь на валидации 3.1290180921554565\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 78\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.5742753852497446\n",
      "Среднее значение функции потерь на валидации 3.130484175682068\n",
      "\n",
      "Эпоха 79\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.5721390572461216\n",
      "Среднее значение функции потерь на валидации 3.1225613355636597\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 80\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.562686096538197\n",
      "Среднее значение функции потерь на валидации 3.119015622138977\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 81\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.5491483970121904\n",
      "Среднее значение функции потерь на валидации 3.1153767824172975\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 82\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.54870144887404\n",
      "Среднее значение функции потерь на валидации 3.1117902755737306\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 83\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.546159787611528\n",
      "Среднее значение функции потерь на валидации 3.115907001495361\n",
      "\n",
      "Эпоха 84\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.5369423736225474\n",
      "Среднее значение функции потерь на валидации 3.11179723739624\n",
      "\n",
      "Эпоха 85\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.5285551331259986\n",
      "Среднее значение функции потерь на валидации 3.1083447694778443\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 86\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.5235565358942207\n",
      "Среднее значение функции потерь на валидации 3.1067482471466064\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 87\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.518781640312888\n",
      "Среднее значение функции потерь на валидации 3.1007715463638306\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 88\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.511854973706332\n",
      "Среднее значение функции потерь на валидации 3.1031702518463136\n",
      "\n",
      "Эпоха 89\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.506767598065463\n",
      "Среднее значение функции потерь на валидации 3.0936121225357054\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 90\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.498609358614141\n",
      "Среднее значение функции потерь на валидации 3.090886092185974\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 91\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.4939833771098745\n",
      "Среднее значение функции потерь на валидации 3.0933447599411013\n",
      "\n",
      "Эпоха 92\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.488601337779652\n",
      "Среднее значение функции потерь на валидации 3.0875205516815187\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 93\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.482289357618852\n",
      "Среднее значение функции потерь на валидации 3.0899373054504395\n",
      "\n",
      "Эпоха 94\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.478586500341242\n",
      "Среднее значение функции потерь на валидации 3.0824047565460204\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 95\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.4719644243066963\n",
      "Среднее значение функции потерь на валидации 3.085134482383728\n",
      "\n",
      "Эпоха 96\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.4659370834177192\n",
      "Среднее значение функции потерь на валидации 3.0844040870666505\n",
      "\n",
      "Эпоха 97\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.457945801995017\n",
      "Среднее значение функции потерь на валидации 3.0794963121414183\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 98\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.4559910514137964\n",
      "Среднее значение функции потерь на валидации 3.0823094129562376\n",
      "\n",
      "Эпоха 99\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.4490608085285532\n",
      "Среднее значение функции потерь на валидации 3.0829049348831177\n",
      "\n",
      "Эпоха 100\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.4513353542848066\n",
      "Среднее значение функции потерь на валидации 3.078102684020996\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 101\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.4407875537872314\n",
      "Среднее значение функции потерь на валидации 3.069453310966492\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 102\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.434352408755909\n",
      "Среднее значение функции потерь на валидации 3.07189679145813\n",
      "\n",
      "Эпоха 103\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.4315851710059424\n",
      "Среднее значение функции потерь на валидации 3.069591999053955\n",
      "\n",
      "Эпоха 104\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.427636677568609\n",
      "Среднее значение функции потерь на валидации 3.069409155845642\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 105\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.425816048275341\n",
      "Среднее значение функции потерь на валидации 3.065142297744751\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 106\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.4231905828822744\n",
      "Среднее значение функции потерь на валидации 3.06699001789093\n",
      "\n",
      "Эпоха 107\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.413393183188005\n",
      "Среднее значение функции потерь на валидации 3.064677023887634\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 108\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.409714948047291\n",
      "Среднее значение функции потерь на валидации 3.0617169380187987\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 109\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.4043977802450005\n",
      "Среднее значение функции потерь на валидации 3.054845595359802\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 110\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.399715033444491\n",
      "Среднее значение функции потерь на валидации 3.0529491186141966\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 111\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.3979682705619116\n",
      "Среднее значение функции потерь на валидации 3.0512721300125123\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 112\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.3963694138960405\n",
      "Среднее значение функции потерь на валидации 3.0496166944503784\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 113\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.389708323912187\n",
      "Среднее значение функции потерь на валидации 3.0523020744323732\n",
      "\n",
      "Эпоха 114\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.387502919543873\n",
      "Среднее значение функции потерь на валидации 3.04552321434021\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 115\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.3804107037457554\n",
      "Среднее значение функции потерь на валидации 3.042544436454773\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 116\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.375792915170843\n",
      "Среднее значение функции потерь на валидации 3.0462297916412355\n",
      "\n",
      "Эпоха 117\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.3740283142436636\n",
      "Среднее значение функции потерь на валидации 3.0398414373397826\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 118\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.369676254012368\n",
      "Среднее значение функции потерь на валидации 3.036826157569885\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 119\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.3709056702527134\n",
      "Среднее значение функции потерь на валидации 3.036379671096802\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 120\n",
      "Эпоха: 22 итераций, 5.30 сек\n",
      "Среднее значение функции потерь на обучении 2.3634677800265225\n",
      "Среднее значение функции потерь на валидации 3.0341281652450562\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 121\n",
      "Эпоха: 22 итераций, 5.44 сек\n",
      "Среднее значение функции потерь на обучении 2.3579965179616753\n",
      "Среднее значение функции потерь на валидации 3.031922960281372\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 122\n",
      "Эпоха: 22 итераций, 5.31 сек\n",
      "Среднее значение функции потерь на обучении 2.3557404604825107\n",
      "Среднее значение функции потерь на валидации 3.0284278869628904\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 123\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.351215189153498\n",
      "Среднее значение функции потерь на валидации 3.0296621322631836\n",
      "\n",
      "Эпоха 124\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.3491787802089346\n",
      "Среднее значение функции потерь на валидации 3.033039593696594\n",
      "\n",
      "Эпоха 125\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.344729033383456\n",
      "Среднее значение функции потерь на валидации 3.0278172731399535\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 126\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.341653661294417\n",
      "Среднее значение функции потерь на валидации 3.031773018836975\n",
      "\n",
      "Эпоха 127\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.3400018323551524\n",
      "Среднее значение функции потерь на валидации 3.0266629219055177\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 128\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.3343750671906904\n",
      "Среднее значение функции потерь на валидации 3.024848699569702\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 129\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.3322619741613213\n",
      "Среднее значение функции потерь на валидации 3.0248453855514525\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 130\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.3285340504212813\n",
      "Среднее значение функции потерь на валидации 3.019368076324463\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 131\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.3241107680580835\n",
      "Среднее значение функции потерь на валидации 3.0295388221740724\n",
      "\n",
      "Эпоха 132\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.323184457692233\n",
      "Среднее значение функции потерь на валидации 3.0195735692977905\n",
      "\n",
      "Эпоха 133\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.319203561002558\n",
      "Среднее значение функции потерь на валидации 3.016486883163452\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 134\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.3148391355167734\n",
      "Среднее значение функции потерь на валидации 3.017574119567871\n",
      "\n",
      "Эпоха 135\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.3085855570706455\n",
      "Среднее значение функции потерь на валидации 3.020142340660095\n",
      "\n",
      "Эпоха 136\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.3105103861201894\n",
      "Среднее значение функции потерь на валидации 3.0145050287246704\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 137\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.308447339318015\n",
      "Среднее значение функции потерь на валидации 3.014540410041809\n",
      "\n",
      "Эпоха 138\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.3051545294848355\n",
      "Среднее значение функции потерь на валидации 3.0049920320510863\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 139\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.301375692540949\n",
      "Среднее значение функции потерь на валидации 3.015064167976379\n",
      "\n",
      "Эпоха 140\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.2977467233484443\n",
      "Среднее значение функции потерь на валидации 3.008411693572998\n",
      "\n",
      "Эпоха 141\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.2917601845481177\n",
      "Среднее значение функции потерь на валидации 3.013724613189697\n",
      "\n",
      "Эпоха 142\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.2919167171825063\n",
      "Среднее значение функции потерь на валидации 3.012575793266296\n",
      "\n",
      "Эпоха 143\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.2918571450493554\n",
      "Среднее значение функции потерь на валидации 3.002276659011841\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 144\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.2833974144675513\n",
      "Среднее значение функции потерь на валидации 3.0053001165390016\n",
      "\n",
      "Эпоха 145\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.2864333391189575\n",
      "Среднее значение функции потерь на валидации 3.0070913553237917\n",
      "\n",
      "Эпоха 146\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.2772683013569224\n",
      "Среднее значение функции потерь на валидации 3.001578688621521\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 147\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.279001897031611\n",
      "Среднее значение функции потерь на валидации 2.9996694326400757\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 148\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.2740394202145664\n",
      "Среднее значение функции потерь на валидации 3.0050825595855715\n",
      "\n",
      "Эпоха 149\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.2739530476656826\n",
      "Среднее значение функции потерь на валидации 3.0006059885025023\n",
      "\n",
      "Эпоха 150\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 2.2759206728501753\n",
      "Среднее значение функции потерь на валидации 2.999058175086975\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 151\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.268231435255571\n",
      "Среднее значение функции потерь на валидации 3.0006059646606444\n",
      "\n",
      "Эпоха 152\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.2651404684240166\n",
      "Среднее значение функции потерь на валидации 2.9921202421188355\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 153\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.2650714895941992\n",
      "Среднее значение функции потерь на валидации 2.988923192024231\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 154\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.261248241771351\n",
      "Среднее значение функции потерь на валидации 2.995785880088806\n",
      "\n",
      "Эпоха 155\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.2587375099008735\n",
      "Среднее значение функции потерь на валидации 2.9874973058700562\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 156\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.255192691629583\n",
      "Среднее значение функции потерь на валидации 2.9954191923141478\n",
      "\n",
      "Эпоха 157\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.2558423714204268\n",
      "Среднее значение функции потерь на валидации 2.9967900991439818\n",
      "\n",
      "Эпоха 158\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.25230826031078\n",
      "Среднее значение функции потерь на валидации 2.9943843364715574\n",
      "\n",
      "Эпоха 159\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.247156945141879\n",
      "Среднее значение функции потерь на валидации 2.979126453399658\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 160\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.242583534934304\n",
      "Среднее значение функции потерь на валидации 2.9925338506698607\n",
      "\n",
      "Эпоха 161\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.2429536039179023\n",
      "Среднее значение функции потерь на валидации 2.989495062828064\n",
      "\n",
      "Эпоха 162\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.2408382892608643\n",
      "Среднее значение функции потерь на валидации 2.973493480682373\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 163\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.241685921495611\n",
      "Среднее значение функции потерь на валидации 2.9830610036849974\n",
      "\n",
      "Эпоха 164\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.2377229061993686\n",
      "Среднее значение функции потерь на валидации 2.979693150520325\n",
      "\n",
      "Эпоха 165\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.2340376593849878\n",
      "Среднее значение функции потерь на валидации 2.9859268426895142\n",
      "\n",
      "Эпоха 166\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.2362912568179043\n",
      "Среднее значение функции потерь на валидации 2.9847951889038087\n",
      "\n",
      "Эпоха 167\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.2277000925757666\n",
      "Среднее значение функции потерь на валидации 2.982423424720764\n",
      "\n",
      "Эпоха 168\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.2300879196687178\n",
      "Среднее значение функции потерь на валидации 2.982215166091919\n",
      "\n",
      "Эпоха 169\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 2.224950996312228\n",
      "Среднее значение функции потерь на валидации 2.9759080171585084\n",
      "\n",
      "Эпоха 170\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.2271773598410864\n",
      "Среднее значение функции потерь на валидации 2.979192018508911\n",
      "\n",
      "Эпоха 171\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.2256892160935835\n",
      "Среднее значение функции потерь на валидации 2.9780746698379517\n",
      "\n",
      "Эпоха 172\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.2191665064204824\n",
      "Среднее значение функции потерь на валидации 2.977046847343445\n",
      "\n",
      "Эпоха 173\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.219747467474504\n",
      "Среднее значение функции потерь на валидации 2.970818591117859\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 174\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.214979572729631\n",
      "Среднее значение функции потерь на валидации 2.9690762042999266\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 175\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.2137732289054175\n",
      "Среднее значение функции потерь на валидации 2.979784893989563\n",
      "\n",
      "Эпоха 176\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.210480635816401\n",
      "Среднее значение функции потерь на валидации 2.971200776100159\n",
      "\n",
      "Эпоха 177\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.2090061686255713\n",
      "Среднее значение функции потерь на валидации 2.968485164642334\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 178\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.2069014635953037\n",
      "Среднее значение функции потерь на валидации 2.9724866151809692\n",
      "\n",
      "Эпоха 179\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.2045070474798028\n",
      "Среднее значение функции потерь на валидации 2.9697627782821656\n",
      "\n",
      "Эпоха 180\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.206035949967124\n",
      "Среднее значение функции потерь на валидации 2.96784451007843\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 181\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.2021214203401045\n",
      "Среднее значение функции потерь на валидации 2.9729549169540403\n",
      "\n",
      "Эпоха 182\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.1994766105305064\n",
      "Среднее значение функции потерь на валидации 2.9631059646606444\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 183\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.19706975330006\n",
      "Среднее значение функции потерь на валидации 2.9664999723434446\n",
      "\n",
      "Эпоха 184\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.1948677843267266\n",
      "Среднее значение функции потерь на валидации 2.971052646636963\n",
      "\n",
      "Эпоха 185\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.193077715960416\n",
      "Среднее значение функции потерь на валидации 2.9675312757492067\n",
      "\n",
      "Эпоха 186\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 2.192914193326777\n",
      "Среднее значение функции потерь на валидации 2.9654815912246706\n",
      "\n",
      "Эпоха 187\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.19245923649181\n",
      "Среднее значение функции потерь на валидации 2.97316575050354\n",
      "\n",
      "Эпоха 188\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 2.1866573095321655\n",
      "Среднее значение функции потерь на валидации 2.959982490539551\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 189\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.186438723043962\n",
      "Среднее значение функции потерь на валидации 2.964471626281738\n",
      "\n",
      "Эпоха 190\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.1842996857383032\n",
      "Среднее значение функции потерь на валидации 2.967226195335388\n",
      "\n",
      "Эпоха 191\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.186647068370472\n",
      "Среднее значение функции потерь на валидации 2.961155581474304\n",
      "\n",
      "Эпоха 192\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.182660937309265\n",
      "Среднее значение функции потерь на валидации 2.957075524330139\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 193\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.1789569312875923\n",
      "Среднее значение функции потерь на валидации 2.958760666847229\n",
      "\n",
      "Эпоха 194\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.1785178509625522\n",
      "Среднее значение функции потерь на валидации 2.9596455097198486\n",
      "\n",
      "Эпоха 195\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.1758827079426157\n",
      "Среднее значение функции потерь на валидации 2.9596754789352415\n",
      "\n",
      "Эпоха 196\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.1714969114823774\n",
      "Среднее значение функции потерь на валидации 2.9539923906326293\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 197\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.1690173907713457\n",
      "Среднее значение функции потерь на валидации 2.9536529541015626\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 198\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 2.16805916482752\n",
      "Среднее значение функции потерь на валидации 2.958730363845825\n",
      "\n",
      "Эпоха 199\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.1688542799516157\n",
      "Среднее значение функции потерь на валидации 2.9579129457473754\n",
      "\n",
      "Эпоха 200\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 2.169289989904924\n",
      "Среднее значение функции потерь на валидации 2.95593683719635\n",
      "\n",
      "Эпоха 201\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.1618553291667593\n",
      "Среднее значение функции потерь на валидации 2.953817534446716\n",
      "\n",
      "Эпоха 202\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.1657988266511397\n",
      "Среднее значение функции потерь на валидации 2.954206919670105\n",
      "\n",
      "Эпоха 203\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.159230503168973\n",
      "Среднее значение функции потерь на валидации 2.9578133106231688\n",
      "\n",
      "Эпоха 204\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.1572612632404673\n",
      "Среднее значение функции потерь на валидации 2.950288724899292\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 205\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.1617394143884834\n",
      "Среднее значение функции потерь на валидации 2.9574294567108153\n",
      "\n",
      "Эпоха 206\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.1562843322753906\n",
      "Среднее значение функции потерь на валидации 2.951277995109558\n",
      "\n",
      "Эпоха 207\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 2.1614115021445532\n",
      "Среднее значение функции потерь на валидации 2.9545446634292603\n",
      "\n",
      "Эпоха 208\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.15347881750627\n",
      "Среднее значение функции потерь на валидации 2.952787089347839\n",
      "\n",
      "Эпоха 209\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.154537656090476\n",
      "Среднее значение функции потерь на валидации 2.9483954429626467\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 210\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.14652220769362\n",
      "Среднее значение функции потерь на валидации 2.949895477294922\n",
      "\n",
      "Эпоха 211\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.151750456203114\n",
      "Среднее значение функции потерь на валидации 2.947731852531433\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 212\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.145597956397317\n",
      "Среднее значение функции потерь на валидации 2.9490036249160765\n",
      "\n",
      "Эпоха 213\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.146918686953458\n",
      "Среднее значение функции потерь на валидации 2.937525773048401\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 214\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.1429307135668667\n",
      "Среднее значение функции потерь на валидации 2.943588972091675\n",
      "\n",
      "Эпоха 215\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.1453673622824927\n",
      "Среднее значение функции потерь на валидации 2.946385979652405\n",
      "\n",
      "Эпоха 216\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 2.143195770003579\n",
      "Среднее значение функции потерь на валидации 2.941659760475159\n",
      "\n",
      "Эпоха 217\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.141147407618436\n",
      "Среднее значение функции потерь на валидации 2.9413727521896362\n",
      "\n",
      "Эпоха 218\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 2.1385034756226973\n",
      "Среднее значение функции потерь на валидации 2.9401446104049684\n",
      "\n",
      "Эпоха 219\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.1397238102826206\n",
      "Среднее значение функции потерь на валидации 2.9384107112884523\n",
      "\n",
      "Эпоха 220\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.137728962031278\n",
      "Среднее значение функции потерь на валидации 2.9367414236068727\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 221\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.134739182212136\n",
      "Среднее значение функции потерь на валидации 2.9368364334106447\n",
      "\n",
      "Эпоха 222\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.134487975727428\n",
      "Среднее значение функции потерь на валидации 2.943578577041626\n",
      "\n",
      "Эпоха 223\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 2.127843141555786\n",
      "Среднее значение функции потерь на валидации 2.943848395347595\n",
      "\n",
      "Эпоха 224\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.1341493129730225\n",
      "Среднее значение функции потерь на валидации 2.9409133434295653\n",
      "\n",
      "Эпоха 225\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.130935170433738\n",
      "Среднее значение функции потерь на валидации 2.934470844268799\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 226\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.1270011338320645\n",
      "Среднее значение функции потерь на валидации 2.9311041831970215\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 227\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.1258642240004106\n",
      "Среднее значение функции потерь на валидации 2.9384519338607786\n",
      "\n",
      "Эпоха 228\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.1293597004630347\n",
      "Среднее значение функции потерь на валидации 2.9393929481506347\n",
      "\n",
      "Эпоха 229\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.1226307478818027\n",
      "Среднее значение функции потерь на валидации 2.9239051580429076\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 230\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.1213845664804634\n",
      "Среднее значение функции потерь на валидации 2.9347321033477782\n",
      "\n",
      "Эпоха 231\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 2.116689508611506\n",
      "Среднее значение функции потерь на валидации 2.932906699180603\n",
      "\n",
      "Эпоха 232\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 2.1180128942836416\n",
      "Среднее значение функции потерь на валидации 2.937695360183716\n",
      "\n",
      "Эпоха 233\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 2.1161633946678857\n",
      "Среднее значение функции потерь на валидации 2.9335893630981444\n",
      "\n",
      "Эпоха 234\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 2.1168633591045034\n",
      "Среднее значение функции потерь на валидации 2.92324583530426\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 235\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 2.113521695137024\n",
      "Среднее значение функции потерь на валидации 2.9275443315505982\n",
      "\n",
      "Эпоха 236\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.1122561259703203\n",
      "Среднее значение функции потерь на валидации 2.9272281646728517\n",
      "\n",
      "Эпоха 237\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.1126532446254385\n",
      "Среднее значение функции потерь на валидации 2.932177948951721\n",
      "\n",
      "Эпоха 238\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 2.109494924545288\n",
      "Среднее значение функции потерь на валидации 2.937912678718567\n",
      "\n",
      "Эпоха 239\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.1111720258539375\n",
      "Среднее значение функции потерь на валидации 2.9299150705337524\n",
      "\n",
      "Эпоха 240\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 2.110972046852112\n",
      "Среднее значение функции потерь на валидации 2.936556172370911\n",
      "\n",
      "Эпоха 241\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 2.105506571856412\n",
      "Среднее значение функции потерь на валидации 2.9298787355422973\n",
      "\n",
      "Эпоха 242\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 2.1060006618499756\n",
      "Среднее значение функции потерь на валидации 2.9292332887649537\n",
      "\n",
      "Эпоха 243\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 2.1037287495353003\n",
      "Среднее значение функции потерь на валидации 2.9204522371292114\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 244\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 2.1017451719804243\n",
      "Среднее значение функции потерь на валидации 2.923009157180786\n",
      "\n",
      "Эпоха 245\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 2.0992109883915293\n",
      "Среднее значение функции потерь на валидации 2.9297910928726196\n",
      "\n",
      "Эпоха 246\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 2.1012965007261797\n",
      "Среднее значение функции потерь на валидации 2.924626898765564\n",
      "\n",
      "Эпоха 247\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.098863114010204\n",
      "Среднее значение функции потерь на валидации 2.91905734539032\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 248\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 2.097072796388106\n",
      "Среднее значение функции потерь на валидации 2.92666277885437\n",
      "\n",
      "Эпоха 249\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.0950846021825615\n",
      "Среднее значение функции потерь на валидации 2.922020196914673\n",
      "\n",
      "Эпоха 250\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.0939096970991655\n",
      "Среднее значение функции потерь на валидации 2.9166871070861817\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 251\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 2.0979910005222666\n",
      "Среднее значение функции потерь на валидации 2.915040612220764\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 252\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 2.093852010640231\n",
      "Среднее значение функции потерь на валидации 2.918334412574768\n",
      "\n",
      "Эпоха 253\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 2.0936235297809946\n",
      "Среднее значение функции потерь на валидации 2.912666749954224\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 254\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 2.089289275082675\n",
      "Среднее значение функции потерь на валидации 2.929068350791931\n",
      "\n",
      "Эпоха 255\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.092119173570113\n",
      "Среднее значение функции потерь на валидации 2.928582692146301\n",
      "\n",
      "Эпоха 256\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 2.089419635859403\n",
      "Среднее значение функции потерь на валидации 2.909702515602112\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 257\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 2.0889044241471724\n",
      "Среднее значение функции потерь на валидации 2.9120678424835207\n",
      "\n",
      "Эпоха 258\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 2.084323146126487\n",
      "Среднее значение функции потерь на валидации 2.9190557956695558\n",
      "\n",
      "Эпоха 259\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 2.083072218027982\n",
      "Среднее значение функции потерь на валидации 2.9127762794494627\n",
      "\n",
      "Эпоха 260\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 2.0857829505747016\n",
      "Среднее значение функции потерь на валидации 2.9126710414886476\n",
      "\n",
      "Эпоха 261\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 2.084372574632818\n",
      "Среднее значение функции потерь на валидации 2.919492077827454\n",
      "\n",
      "Эпоха 262\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 2.0833250934427436\n",
      "Среднее значение функции потерь на валидации 2.9167087078094482\n",
      "\n",
      "Эпоха 263\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.0853903510353784\n",
      "Среднее значение функции потерь на валидации 2.918462872505188\n",
      "\n",
      "Эпоха 264\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 2.079249544577165\n",
      "Среднее значение функции потерь на валидации 2.910137438774109\n",
      "\n",
      "Эпоха 265\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 2.0745902278206567\n",
      "Среднее значение функции потерь на валидации 2.917562246322632\n",
      "\n",
      "Эпоха 266\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 2.0779998194087637\n",
      "Среднее значение функции потерь на валидации 2.9020688056945803\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 267\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.078146154230291\n",
      "Среднее значение функции потерь на валидации 2.914679479598999\n",
      "\n",
      "Эпоха 268\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 2.0743726058439775\n",
      "Среднее значение функции потерь на валидации 2.91536066532135\n",
      "\n",
      "Эпоха 269\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 2.0699676925485786\n",
      "Среднее значение функции потерь на валидации 2.9041110038757325\n",
      "\n",
      "Эпоха 270\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 2.0679424946958367\n",
      "Среднее значение функции потерь на валидации 2.9121315240859986\n",
      "\n",
      "Эпоха 271\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 2.0712540474804966\n",
      "Среднее значение функции потерь на валидации 2.9072081565856935\n",
      "\n",
      "Эпоха 272\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 2.075481880794872\n",
      "Среднее значение функции потерь на валидации 2.9135924100875856\n",
      "\n",
      "Эпоха 273\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 2.0715976628390225\n",
      "Среднее значение функции потерь на валидации 2.9114551305770875\n",
      "\n",
      "Эпоха 274\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 2.066853707486933\n",
      "Среднее значение функции потерь на валидации 2.9099393129348754\n",
      "\n",
      "Эпоха 275\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 2.072254814884879\n",
      "Среднее значение функции потерь на валидации 2.9025086164474487\n",
      "\n",
      "Эпоха 276\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 2.069396571679549\n",
      "Среднее значение функции потерь на валидации 2.8974085807800294\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 277\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 2.0648276751691643\n",
      "Среднее значение функции потерь на валидации 2.9003756761550905\n",
      "\n",
      "Эпоха 278\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 2.063449453223835\n",
      "Среднее значение функции потерь на валидации 2.9043614864349365\n",
      "\n",
      "Эпоха 279\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 2.06207182190635\n",
      "Среднее значение функции потерь на валидации 2.9158546924591064\n",
      "\n",
      "Эпоха 280\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 2.064759677106684\n",
      "Среднее значение функции потерь на валидации 2.9070155382156373\n",
      "\n",
      "Эпоха 281\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 2.0629607113924893\n",
      "Среднее значение функции потерь на валидации 2.907208967208862\n",
      "\n",
      "Эпоха 282\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 2.0630720637061377\n",
      "Среднее значение функции потерь на валидации 2.9028858184814452\n",
      "\n",
      "Эпоха 283\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 2.059567256407304\n",
      "Среднее значение функции потерь на валидации 2.914399433135986\n",
      "\n",
      "Эпоха 284\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.0580479285933753\n",
      "Среднее значение функции потерь на валидации 2.900440716743469\n",
      "\n",
      "Эпоха 285\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 2.0601032267917287\n",
      "Среднее значение функции потерь на валидации 2.904581570625305\n",
      "\n",
      "Эпоха 286\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 2.058135682886297\n",
      "Среднее значение функции потерь на валидации 2.9039307594299317\n",
      "\n",
      "Эпоха 287\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 2.0620334256779063\n",
      "Среднее значение функции потерь на валидации 2.9030889511108398\n",
      "\n",
      "Эпоха 288\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.0559992519291965\n",
      "Среднее значение функции потерь на валидации 2.9003077268600466\n",
      "\n",
      "Эпоха 289\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 2.0561970418149773\n",
      "Среднее значение функции потерь на валидации 2.902375602722168\n",
      "\n",
      "Эпоха 290\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 2.0499679175290195\n",
      "Среднее значение функции потерь на валидации 2.8972779512405396\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 291\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 2.0550232963128523\n",
      "Среднее значение функции потерь на валидации 2.904589533805847\n",
      "\n",
      "Эпоха 292\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 2.048070566220717\n",
      "Среднее значение функции потерь на валидации 2.8916447877883913\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 293\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.048884489319541\n",
      "Среднее значение функции потерь на валидации 2.9026071786880494\n",
      "\n",
      "Эпоха 294\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 2.052302295511419\n",
      "Среднее значение функции потерь на валидации 2.8976049423217773\n",
      "\n",
      "Эпоха 295\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.0497057112780483\n",
      "Среднее значение функции потерь на валидации 2.9013115406036376\n",
      "\n",
      "Эпоха 296\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 2.047476838935505\n",
      "Среднее значение функции потерь на валидации 2.9010843515396116\n",
      "\n",
      "Эпоха 297\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 2.0457197590307756\n",
      "Среднее значение функции потерь на валидации 2.899407720565796\n",
      "\n",
      "Эпоха 298\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 2.0457625822587446\n",
      "Среднее значение функции потерь на валидации 2.9045047044754027\n",
      "\n",
      "Эпоха 299\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 2.0451622388579627\n",
      "Среднее значение функции потерь на валидации 2.8979465484619142\n",
      "\n",
      "Эпоха 300\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 2.0409722924232483\n",
      "Среднее значение функции потерь на валидации 2.8971473455429075\n",
      "\n",
      "Эпоха 301\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 2.0397160703485664\n",
      "Среднее значение функции потерь на валидации 2.891371464729309\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 302\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 2.041060604832389\n",
      "Среднее значение функции потерь на валидации 2.910814142227173\n",
      "\n",
      "Эпоха 303\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 2.041062051599676\n",
      "Среднее значение функции потерь на валидации 2.896935057640076\n",
      "\n",
      "Эпоха 304\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 2.0377443432807922\n",
      "Среднее значение функции потерь на валидации 2.889911484718323\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 305\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 2.040344395420768\n",
      "Среднее значение функции потерь на валидации 2.8920031070709227\n",
      "\n",
      "Эпоха 306\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 2.0359037843617527\n",
      "Среднее значение функции потерь на валидации 2.8923144340515137\n",
      "\n",
      "Эпоха 307\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 2.0380724451758643\n",
      "Среднее значение функции потерь на валидации 2.8928256034851074\n",
      "\n",
      "Эпоха 308\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 2.03562025048516\n",
      "Среднее значение функции потерь на валидации 2.8950937747955323\n",
      "\n",
      "Эпоха 309\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 2.035360861908306\n",
      "Среднее значение функции потерь на валидации 2.901850962638855\n",
      "\n",
      "Эпоха 310\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 2.03361559456045\n",
      "Среднее значение функции потерь на валидации 2.886648941040039\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 311\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 2.0322679714723066\n",
      "Среднее значение функции потерь на валидации 2.893967056274414\n",
      "\n",
      "Эпоха 312\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 2.0302531719207764\n",
      "Среднее значение функции потерь на валидации 2.89532470703125\n",
      "\n",
      "Эпоха 313\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 2.032820636575872\n",
      "Среднее значение функции потерь на валидации 2.890862822532654\n",
      "\n",
      "Эпоха 314\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 2.028422464023937\n",
      "Среднее значение функции потерь на валидации 2.887527322769165\n",
      "\n",
      "Эпоха 315\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 2.0275111957029863\n",
      "Среднее значение функции потерь на валидации 2.9000669002532957\n",
      "\n",
      "Эпоха 316\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 2.028590050610629\n",
      "Среднее значение функции потерь на валидации 2.8946566581726074\n",
      "\n",
      "Эпоха 317\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 2.026809112592177\n",
      "Среднее значение функции потерь на валидации 2.882775354385376\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 318\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 2.028175077655099\n",
      "Среднее значение функции потерь на валидации 2.893309164047241\n",
      "\n",
      "Эпоха 319\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 2.022545733235099\n",
      "Среднее значение функции потерь на валидации 2.890572500228882\n",
      "\n",
      "Эпоха 320\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 2.024410058151592\n",
      "Среднее значение функции потерь на валидации 2.896237516403198\n",
      "\n",
      "Эпоха 321\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 2.027872616594488\n",
      "Среднее значение функции потерь на валидации 2.8796332359313963\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 322\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 2.0222072438760237\n",
      "Среднее значение функции потерь на валидации 2.8841470956802366\n",
      "\n",
      "Эпоха 323\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 2.0234599601138723\n",
      "Среднее значение функции потерь на валидации 2.8812008142471313\n",
      "\n",
      "Эпоха 324\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 2.0205982381647285\n",
      "Среднее значение функции потерь на валидации 2.8865174531936644\n",
      "\n",
      "Эпоха 325\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 2.0199873826720496\n",
      "Среднее значение функции потерь на валидации 2.8821456670761108\n",
      "\n",
      "Эпоха 326\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 2.018999224359339\n",
      "Среднее значение функции потерь на валидации 2.8834822177886963\n",
      "\n",
      "Эпоха 327\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 2.0182707743211226\n",
      "Среднее значение функции потерь на валидации 2.8835946798324583\n",
      "\n",
      "Эпоха 328\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 2.0180501612749966\n",
      "Среднее значение функции потерь на валидации 2.8842277050018312\n",
      "\n",
      "Эпоха 329\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 2.0183088887821543\n",
      "Среднее значение функции потерь на валидации 2.882935905456543\n",
      "\n",
      "Эпоха 330\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 2.0191527279940518\n",
      "Среднее значение функции потерь на валидации 2.8807444334030152\n",
      "\n",
      "Эпоха 331\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 2.0167414871129123\n",
      "Среднее значение функции потерь на валидации 2.8913053035736085\n",
      "\n",
      "Эпоха 332\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 2.0169916369698266\n",
      "Среднее значение функции потерь на валидации 2.8846222400665282\n",
      "\n",
      "Эпоха 333\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 2.0156835696913977\n",
      "Среднее значение функции потерь на валидации 2.8889771938323974\n",
      "\n",
      "Эпоха 334\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 2.0147760727188806\n",
      "Среднее значение функции потерь на валидации 2.8786790132522584\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 335\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 2.011400943452662\n",
      "Среднее значение функции потерь на валидации 2.884262943267822\n",
      "\n",
      "Эпоха 336\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 2.014093691652471\n",
      "Среднее значение функции потерь на валидации 2.8845667123794554\n",
      "\n",
      "Эпоха 337\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 2.0119241313500837\n",
      "Среднее значение функции потерь на валидации 2.870716595649719\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 338\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 2.010418664325367\n",
      "Среднее значение функции потерь на валидации 2.884493899345398\n",
      "\n",
      "Эпоха 339\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 2.008740045807578\n",
      "Среднее значение функции потерь на валидации 2.883756637573242\n",
      "\n",
      "Эпоха 340\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 2.0114682641896335\n",
      "Среднее значение функции потерь на валидации 2.882669520378113\n",
      "\n",
      "Эпоха 341\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 2.0120026740160855\n",
      "Среднее значение функции потерь на валидации 2.8736637353897097\n",
      "\n",
      "Эпоха 342\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 2.0064234029163015\n",
      "Среднее значение функции потерь на валидации 2.878750276565552\n",
      "\n",
      "Эпоха 343\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 2.001737659627741\n",
      "Среднее значение функции потерь на валидации 2.8887596130371094\n",
      "\n",
      "Эпоха 344\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 2.00438794222745\n",
      "Среднее значение функции потерь на валидации 2.8756613969802856\n",
      "\n",
      "Эпоха 345\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 2.0076434287157925\n",
      "Среднее значение функции потерь на валидации 2.8774123907089235\n",
      "\n",
      "Эпоха 346\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 2.001828843897039\n",
      "Среднее значение функции потерь на валидации 2.879491853713989\n",
      "\n",
      "Эпоха 347\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 2.0014483007517727\n",
      "Среднее значение функции потерь на валидации 2.8813427686691284\n",
      "\n",
      "Эпоха 348\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 2.0013474280183967\n",
      "Среднее значение функции потерь на валидации 2.884123659133911\n",
      "\n",
      "Эпоха 349\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 2.000915749506517\n",
      "Среднее значение функции потерь на валидации 2.870983290672302\n",
      "\n",
      "Эпоха 350\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.9979476820338855\n",
      "Среднее значение функции потерь на валидации 2.8757296562194825\n",
      "\n",
      "Эпоха 351\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.9986869476058267\n",
      "Среднее значение функции потерь на валидации 2.8804617166519164\n",
      "\n",
      "Эпоха 352\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 2.0040336684747175\n",
      "Среднее значение функции потерь на валидации 2.8803727626800537\n",
      "\n",
      "Эпоха 353\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.9982698451388965\n",
      "Среднее значение функции потерь на валидации 2.8866261720657347\n",
      "\n",
      "Эпоха 354\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 2.0023243589834734\n",
      "Среднее значение функции потерь на валидации 2.876334857940674\n",
      "\n",
      "Эпоха 355\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.9999807206067173\n",
      "Среднее значение функции потерь на валидации 2.8864840507507323\n",
      "\n",
      "Эпоха 356\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.9944918534972451\n",
      "Среднее значение функции потерь на валидации 2.870467495918274\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 357\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.997062162919478\n",
      "Среднее значение функции потерь на валидации 2.8656548738479612\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 358\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.9944571690125898\n",
      "Среднее значение функции потерь на валидации 2.8808988332748413\n",
      "\n",
      "Эпоха 359\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.9930405887690457\n",
      "Среднее значение функции потерь на валидации 2.8708895206451417\n",
      "\n",
      "Эпоха 360\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.993513903834603\n",
      "Среднее значение функции потерь на валидации 2.8734118938446045\n",
      "\n",
      "Эпоха 361\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.9955268881537698\n",
      "Среднее значение функции потерь на валидации 2.876417398452759\n",
      "\n",
      "Эпоха 362\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.9925950928167864\n",
      "Среднее значение функции потерь на валидации 2.8748114824295046\n",
      "\n",
      "Эпоха 363\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.9932832555337385\n",
      "Среднее значение функции потерь на валидации 2.874094319343567\n",
      "\n",
      "Эпоха 364\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.9956750707192854\n",
      "Среднее значение функции потерь на валидации 2.8697872877120973\n",
      "\n",
      "Эпоха 365\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.9881746606393293\n",
      "Среднее значение функции потерь на валидации 2.879120969772339\n",
      "\n",
      "Эпоха 366\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.9898530895059758\n",
      "Среднее значение функции потерь на валидации 2.8744680881500244\n",
      "\n",
      "Эпоха 367\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.9911058328368447\n",
      "Среднее значение функции потерь на валидации 2.8671171188354494\n",
      "\n",
      "Эпоха 368\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.9885104569521816\n",
      "Среднее значение функции потерь на валидации 2.878681206703186\n",
      "\n",
      "Эпоха 369\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.984774562445554\n",
      "Среднее значение функции потерь на валидации 2.8751956939697267\n",
      "\n",
      "Эпоха 370\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.9884181727062573\n",
      "Среднее значение функции потерь на валидации 2.8675210952758787\n",
      "\n",
      "Эпоха 371\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.985023108395663\n",
      "Среднее значение функции потерь на валидации 2.8714115142822267\n",
      "\n",
      "Эпоха 372\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.9853919798677617\n",
      "Среднее значение функции потерь на валидации 2.866557765007019\n",
      "\n",
      "Эпоха 373\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.9773405681956897\n",
      "Среднее значение функции потерь на валидации 2.8712112665176392\n",
      "\n",
      "Эпоха 374\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.9886239658702503\n",
      "Среднее значение функции потерь на валидации 2.8718728542327883\n",
      "\n",
      "Эпоха 375\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.9836077094078064\n",
      "Среднее значение функции потерь на валидации 2.864374041557312\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 376\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.9822005792097612\n",
      "Среднее значение функции потерь на валидации 2.86590838432312\n",
      "\n",
      "Эпоха 377\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.9843644933267073\n",
      "Среднее значение функции потерь на валидации 2.8730183601379395\n",
      "\n",
      "Эпоха 378\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.979232213713906\n",
      "Среднее значение функции потерь на валидации 2.8665549039840696\n",
      "\n",
      "Эпоха 379\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.9809076244180852\n",
      "Среднее значение функции потерь на валидации 2.8648738622665406\n",
      "\n",
      "Эпоха 380\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.9780202453786677\n",
      "Среднее значение функции потерь на валидации 2.872130823135376\n",
      "\n",
      "Эпоха 381\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.9867265224456787\n",
      "Среднее значение функции потерь на валидации 2.867780017852783\n",
      "\n",
      "Эпоха 382\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.9767420400272717\n",
      "Среднее значение функции потерь на валидации 2.8631861209869385\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 383\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.9772174575112083\n",
      "Среднее значение функции потерь на валидации 2.8570372104644775\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 384\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.9789492379535327\n",
      "Среднее значение функции потерь на валидации 2.8588404178619387\n",
      "\n",
      "Эпоха 385\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.978588949550282\n",
      "Среднее значение функции потерь на валидации 2.8683667898178102\n",
      "\n",
      "Эпоха 386\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.974432961507277\n",
      "Среднее значение функции потерь на валидации 2.861793351173401\n",
      "\n",
      "Эпоха 387\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.9766196771101519\n",
      "Среднее значение функции потерь на валидации 2.860007572174072\n",
      "\n",
      "Эпоха 388\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.974773639982397\n",
      "Среднее значение функции потерь на валидации 2.8618792057037354\n",
      "\n",
      "Эпоха 389\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.9747192859649658\n",
      "Среднее значение функции потерь на валидации 2.86572904586792\n",
      "\n",
      "Эпоха 390\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.972748344594782\n",
      "Среднее значение функции потерь на валидации 2.862598490715027\n",
      "\n",
      "Эпоха 391\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.9718977971510454\n",
      "Среднее значение функции потерь на валидации 2.8685355186462402\n",
      "\n",
      "Эпоха 392\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.9729928374290466\n",
      "Среднее значение функции потерь на валидации 2.861452603340149\n",
      "\n",
      "Эпоха 393\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.967774672941728\n",
      "Среднее значение функции потерь на валидации 2.8635202646255493\n",
      "\n",
      "Эпоха 394\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.9741135293787175\n",
      "Среднее значение функции потерь на валидации 2.856959676742554\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 395\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.9721816290508618\n",
      "Среднее значение функции потерь на валидации 2.861831521987915\n",
      "\n",
      "Эпоха 396\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.9709194248372859\n",
      "Среднее значение функции потерь на валидации 2.868029975891113\n",
      "\n",
      "Эпоха 397\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.9720181280916387\n",
      "Среднее значение функции потерь на валидации 2.8620256900787355\n",
      "\n",
      "Эпоха 398\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.96794162013314\n",
      "Среднее значение функции потерь на валидации 2.854043483734131\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 399\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.9634028402241794\n",
      "Среднее значение функции потерь на валидации 2.873183512687683\n",
      "\n",
      "Эпоха 400\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.967473642392592\n",
      "Среднее значение функции потерь на валидации 2.862605667114258\n",
      "\n",
      "Эпоха 401\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.9667078906839544\n",
      "Среднее значение функции потерь на валидации 2.8638792991638184\n",
      "\n",
      "Эпоха 402\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.967592103914781\n",
      "Среднее значение функции потерь на валидации 2.8600228786468507\n",
      "\n",
      "Эпоха 403\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.971676924011924\n",
      "Среднее значение функции потерь на валидации 2.8553889751434327\n",
      "\n",
      "Эпоха 404\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.9632171880115161\n",
      "Среднее значение функции потерь на валидации 2.863573408126831\n",
      "\n",
      "Эпоха 405\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.9619552384723316\n",
      "Среднее значение функции потерь на валидации 2.8606509447097777\n",
      "\n",
      "Эпоха 406\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.9633461995558306\n",
      "Среднее значение функции потерь на валидации 2.8651540756225584\n",
      "\n",
      "Эпоха 407\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.9661324566060847\n",
      "Среднее значение функции потерь на валидации 2.863434314727783\n",
      "\n",
      "Эпоха 408\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.9683085138147527\n",
      "Среднее значение функции потерь на валидации 2.858359718322754\n",
      "\n",
      "Эпоха 409\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.9610597166148098\n",
      "Среднее значение функции потерь на валидации 2.8646224975585937\n",
      "\n",
      "Эпоха 410\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.9604534019123425\n",
      "Среднее значение функции потерь на валидации 2.8567231416702272\n",
      "\n",
      "Эпоха 411\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.9654150171713396\n",
      "Среднее значение функции потерь на валидации 2.8635104417800905\n",
      "\n",
      "Эпоха 412\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.961580840024081\n",
      "Среднее значение функции потерь на валидации 2.857209658622742\n",
      "\n",
      "Эпоха 413\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.9572245424444026\n",
      "Среднее значение функции потерь на валидации 2.8603409051895143\n",
      "\n",
      "Эпоха 414\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.9598238359798084\n",
      "Среднее значение функции потерь на валидации 2.8582191944122313\n",
      "\n",
      "Эпоха 415\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.9580285874280063\n",
      "Среднее значение функции потерь на валидации 2.8530941724777223\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 416\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.952967649156397\n",
      "Среднее значение функции потерь на валидации 2.8567246913909914\n",
      "\n",
      "Эпоха 417\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.9594007947228171\n",
      "Среднее значение функции потерь на валидации 2.854776692390442\n",
      "\n",
      "Эпоха 418\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.9570698033679614\n",
      "Среднее значение функции потерь на валидации 2.8560378313064576\n",
      "\n",
      "Эпоха 419\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.9560783234509556\n",
      "Среднее значение функции потерь на валидации 2.854071283340454\n",
      "\n",
      "Эпоха 420\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.9566618908535351\n",
      "Среднее значение функции потерь на валидации 2.854919505119324\n",
      "\n",
      "Эпоха 421\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.9563481211662292\n",
      "Среднее значение функции потерь на валидации 2.8634873390197755\n",
      "\n",
      "Эпоха 422\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.9566770087588916\n",
      "Среднее значение функции потерь на валидации 2.8563825368881224\n",
      "\n",
      "Эпоха 423\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.9588940956375815\n",
      "Среднее значение функции потерь на валидации 2.861460733413696\n",
      "\n",
      "Эпоха 424\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.9539773139086636\n",
      "Среднее значение функции потерь на валидации 2.8537312507629395\n",
      "\n",
      "Эпоха 425\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.9535511190241033\n",
      "Среднее значение функции потерь на валидации 2.859690451622009\n",
      "\n",
      "Эпоха 426\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.956048932942477\n",
      "Среднее значение функции потерь на валидации 2.859433722496033\n",
      "\n",
      "Эпоха 427\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.954258534041318\n",
      "Среднее значение функции потерь на валидации 2.8493863582611083\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 428\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.9465816346081821\n",
      "Среднее значение функции потерь на валидации 2.8412668704986572\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 429\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.9507605975324458\n",
      "Среднее значение функции потерь на валидации 2.8468167304992678\n",
      "\n",
      "Эпоха 430\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.9500355503775857\n",
      "Среднее значение функции потерь на валидации 2.844847297668457\n",
      "\n",
      "Эпоха 431\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.9416351860219783\n",
      "Среднее значение функции потерь на валидации 2.8549458026885985\n",
      "\n",
      "Эпоха 432\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.9508993246338584\n",
      "Среднее значение функции потерь на валидации 2.854024577140808\n",
      "\n",
      "Эпоха 433\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.9456617886369878\n",
      "Среднее значение функции потерь на валидации 2.855453872680664\n",
      "\n",
      "Эпоха 434\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.9486158056692644\n",
      "Среднее значение функции потерь на валидации 2.853342819213867\n",
      "\n",
      "Эпоха 435\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.9469065937128933\n",
      "Среднее значение функции потерь на валидации 2.854360485076904\n",
      "\n",
      "Эпоха 436\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.9499136101115833\n",
      "Среднее значение функции потерь на валидации 2.847757339477539\n",
      "\n",
      "Эпоха 437\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.9449803178960627\n",
      "Среднее значение функции потерь на валидации 2.8503466129302977\n",
      "\n",
      "Эпоха 438\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.9438095797191968\n",
      "Среднее значение функции потерь на валидации 2.850337100028992\n",
      "\n",
      "Эпоха 439\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.9431128339333967\n",
      "Среднее значение функции потерь на валидации 2.861759352684021\n",
      "\n",
      "Эпоха 440\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.9440705288540234\n",
      "Среднее значение функции потерь на валидации 2.852765345573425\n",
      "\n",
      "Эпоха 441\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.9407561421394348\n",
      "Среднее значение функции потерь на валидации 2.855220580101013\n",
      "\n",
      "Эпоха 442\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.9445972496812993\n",
      "Среднее значение функции потерь на валидации 2.8528109312057497\n",
      "\n",
      "Эпоха 443\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.942794680595398\n",
      "Среднее значение функции потерь на валидации 2.853572392463684\n",
      "\n",
      "Эпоха 444\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.9433459531177173\n",
      "Среднее значение функции потерь на валидации 2.8460826873779297\n",
      "\n",
      "Эпоха 445\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.944119935685938\n",
      "Среднее значение функции потерь на валидации 2.8550264835357666\n",
      "\n",
      "Эпоха 446\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.9419141953641719\n",
      "Среднее значение функции потерь на валидации 2.8567034244537353\n",
      "\n",
      "Эпоха 447\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.9403991428288547\n",
      "Среднее значение функции потерь на валидации 2.8605466365814207\n",
      "\n",
      "Эпоха 448\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.9391531456600537\n",
      "Среднее значение функции потерь на валидации 2.857000207901001\n",
      "\n",
      "Эпоха 449\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.9409221627495505\n",
      "Среднее значение функции потерь на валидации 2.8496599435806274\n",
      "Epoch   450: reducing learning rate of group 0 to 1.0000e-03.\n",
      "\n",
      "Эпоха 450\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.89364355802536\n",
      "Среднее значение функции потерь на валидации 2.836980676651001\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 451\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.8631491498513655\n",
      "Среднее значение функции потерь на валидации 2.835138726234436\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 452\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.8520203557881443\n",
      "Среднее значение функции потерь на валидации 2.8260524034500123\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 453\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.8472278063947505\n",
      "Среднее значение функции потерь на валидации 2.825020909309387\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 454\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.8394506952979348\n",
      "Среднее значение функции потерь на валидации 2.8208633184432985\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 455\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.8404300917278638\n",
      "Среднее значение функции потерь на валидации 2.8114223957061766\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 456\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.834089609709653\n",
      "Среднее значение функции потерь на валидации 2.8182135343551638\n",
      "\n",
      "Эпоха 457\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.8341399214484475\n",
      "Среднее значение функции потерь на валидации 2.8202389001846315\n",
      "\n",
      "Эпоха 458\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.8327121246944775\n",
      "Среднее значение функции потерь на валидации 2.8203299760818483\n",
      "\n",
      "Эпоха 459\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.8314776095477017\n",
      "Среднее значение функции потерь на валидации 2.8217923164367678\n",
      "\n",
      "Эпоха 460\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.8284776590087197\n",
      "Среднее значение функции потерь на валидации 2.8136593818664553\n",
      "\n",
      "Эпоха 461\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.8249954743818804\n",
      "Среднее значение функции потерь на валидации 2.8181481838226317\n",
      "\n",
      "Эпоха 462\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.8285861773924394\n",
      "Среднее значение функции потерь на валидации 2.814067816734314\n",
      "\n",
      "Эпоха 463\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.8244116739793257\n",
      "Среднее значение функции потерь на валидации 2.815571403503418\n",
      "\n",
      "Эпоха 464\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.8255264921621843\n",
      "Среднее значение функции потерь на валидации 2.81812527179718\n",
      "\n",
      "Эпоха 465\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.8219034346667202\n",
      "Среднее значение функции потерь на валидации 2.810929203033447\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 466\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.822910102930936\n",
      "Среднее значение функции потерь на валидации 2.8169732332229613\n",
      "\n",
      "Эпоха 467\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.8226516951214184\n",
      "Среднее значение функции потерь на валидации 2.8201112270355226\n",
      "\n",
      "Эпоха 468\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.821508071639321\n",
      "Среднее значение функции потерь на валидации 2.815325903892517\n",
      "\n",
      "Эпоха 469\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.8184097084132107\n",
      "Среднее значение функции потерь на валидации 2.8173199892044067\n",
      "\n",
      "Эпоха 470\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.8191276463595303\n",
      "Среднее значение функции потерь на валидации 2.8108355045318603\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 471\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.8179264881394126\n",
      "Среднее значение функции потерь на валидации 2.810373306274414\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 472\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.8189408291469922\n",
      "Среднее значение функции потерь на валидации 2.809000825881958\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 473\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.8186595439910889\n",
      "Среднее значение функции потерь на валидации 2.8013900995254515\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 474\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.8176428079605103\n",
      "Среднее значение функции потерь на валидации 2.8065364599227904\n",
      "\n",
      "Эпоха 475\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.8140490813688799\n",
      "Среднее значение функции потерь на валидации 2.806352066993713\n",
      "\n",
      "Эпоха 476\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.8149616609920154\n",
      "Среднее значение функции потерь на валидации 2.8107653617858888\n",
      "\n",
      "Эпоха 477\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.812956988811493\n",
      "Среднее значение функции потерь на валидации 2.806231880187988\n",
      "\n",
      "Эпоха 478\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.8125655867836692\n",
      "Среднее значение функции потерь на валидации 2.810893416404724\n",
      "\n",
      "Эпоха 479\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.8140661066228694\n",
      "Среднее значение функции потерь на валидации 2.8017184257507326\n",
      "\n",
      "Эпоха 480\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.8121685819192366\n",
      "Среднее значение функции потерь на валидации 2.8070630073547362\n",
      "\n",
      "Эпоха 481\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.8104779395190151\n",
      "Среднее значение функции потерь на валидации 2.8097147941589355\n",
      "\n",
      "Эпоха 482\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.812352261760018\n",
      "Среднее значение функции потерь на валидации 2.8087704181671143\n",
      "\n",
      "Эпоха 483\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.809847961772572\n",
      "Среднее значение функции потерь на валидации 2.806390905380249\n",
      "\n",
      "Эпоха 484\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.8141692334955388\n",
      "Среднее значение функции потерь на валидации 2.8089213132858277\n",
      "\n",
      "Эпоха 485\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.809113085269928\n",
      "Среднее значение функции потерь на валидации 2.8127391576766967\n",
      "\n",
      "Эпоха 486\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.8097673762928357\n",
      "Среднее значение функции потерь на валидации 2.804530930519104\n",
      "\n",
      "Эпоха 487\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.8074226596138694\n",
      "Среднее значение функции потерь на валидации 2.8060117244720457\n",
      "\n",
      "Эпоха 488\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.809499653902921\n",
      "Среднее значение функции потерь на валидации 2.806042265892029\n",
      "\n",
      "Эпоха 489\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.8062978170134805\n",
      "Среднее значение функции потерь на валидации 2.8048742771148683\n",
      "\n",
      "Эпоха 490\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.8066925081339749\n",
      "Среднее значение функции потерь на валидации 2.8069366693496702\n",
      "\n",
      "Эпоха 491\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.810036913915114\n",
      "Среднее значение функции потерь на валидации 2.8040538787841798\n",
      "\n",
      "Эпоха 492\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.8070034926587886\n",
      "Среднее значение функции потерь на валидации 2.809015679359436\n",
      "\n",
      "Эпоха 493\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.8049714998765425\n",
      "Среднее значение функции потерь на валидации 2.801288914680481\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 494\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.8056395649909973\n",
      "Среднее значение функции потерь на валидации 2.8122185945510862\n",
      "Epoch   495: reducing learning rate of group 0 to 5.0000e-04.\n",
      "\n",
      "Эпоха 495\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.782167981971394\n",
      "Среднее значение функции потерь на валидации 2.7982597827911375\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 496\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.7724653265692971\n",
      "Среднее значение функции потерь на валидации 2.7958585739135744\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 497\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.7677206776358865\n",
      "Среднее значение функции потерь на валидации 2.7985682249069215\n",
      "\n",
      "Эпоха 498\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.7604015957225452\n",
      "Среднее значение функции потерь на валидации 2.7902901411056518\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 499\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.758998448198492\n",
      "Среднее значение функции потерь на валидации 2.7971158027648926\n",
      "\n",
      "Эпоха 500\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.7591827782717617\n",
      "Среднее значение функции потерь на валидации 2.796238160133362\n",
      "\n",
      "Эпоха 501\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.756430983543396\n",
      "Среднее значение функции потерь на валидации 2.793645215034485\n",
      "\n",
      "Эпоха 502\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.7569500641389326\n",
      "Среднее значение функции потерь на валидации 2.7964916229248047\n",
      "\n",
      "Эпоха 503\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.7563264044848355\n",
      "Среднее значение функции потерь на валидации 2.792530393600464\n",
      "\n",
      "Эпоха 504\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.7571612108837475\n",
      "Среднее значение функции потерь на валидации 2.7939104795455934\n",
      "\n",
      "Эпоха 505\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.7533095479011536\n",
      "Среднее значение функции потерь на валидации 2.789642834663391\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 506\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.7524471174586902\n",
      "Среднее значение функции потерь на валидации 2.7865763187408445\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 507\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.7512574629350142\n",
      "Среднее значение функции потерь на валидации 2.787251424789429\n",
      "\n",
      "Эпоха 508\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.7461209405552258\n",
      "Среднее значение функции потерь на валидации 2.7870246887207033\n",
      "\n",
      "Эпоха 509\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.7485178112983704\n",
      "Среднее значение функции потерь на валидации 2.7853730440139772\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 510\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.7490685853091152\n",
      "Среднее значение функции потерь на валидации 2.7896466970443727\n",
      "\n",
      "Эпоха 511\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.749690440568057\n",
      "Среднее значение функции потерь на валидации 2.7824230194091797\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 512\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.749379743229259\n",
      "Среднее значение функции потерь на валидации 2.787113642692566\n",
      "\n",
      "Эпоха 513\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.7490748871456494\n",
      "Среднее значение функции потерь на валидации 2.7906725883483885\n",
      "\n",
      "Эпоха 514\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.743339018388228\n",
      "Среднее значение функции потерь на валидации 2.791020226478577\n",
      "\n",
      "Эпоха 515\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.742557476867329\n",
      "Среднее значение функции потерь на валидации 2.7890021085739134\n",
      "\n",
      "Эпоха 516\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.7474679675969211\n",
      "Среднее значение функции потерь на валидации 2.788810873031616\n",
      "\n",
      "Эпоха 517\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.743188820101998\n",
      "Среднее значение функции потерь на валидации 2.7865090131759644\n",
      "\n",
      "Эпоха 518\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.7433668862689624\n",
      "Среднее значение функции потерь на валидации 2.78317506313324\n",
      "\n",
      "Эпоха 519\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.743274824185805\n",
      "Среднее значение функции потерь на валидации 2.793491530418396\n",
      "\n",
      "Эпоха 520\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.7407245473428206\n",
      "Среднее значение функции потерь на валидации 2.7850183248519897\n",
      "\n",
      "Эпоха 521\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.7444309483874927\n",
      "Среднее значение функции потерь на валидации 2.7797674894332887\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 522\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.7419657598842273\n",
      "Среднее значение функции потерь на валидации 2.7883789777755736\n",
      "\n",
      "Эпоха 523\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.7444572665474631\n",
      "Среднее значение функции потерь на валидации 2.789456105232239\n",
      "\n",
      "Эпоха 524\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.7416539246385747\n",
      "Среднее значение функции потерь на валидации 2.7835907697677613\n",
      "\n",
      "Эпоха 525\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.74238858981566\n",
      "Среднее значение функции потерь на валидации 2.7828996419906615\n",
      "\n",
      "Эпоха 526\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.738138735294342\n",
      "Среднее значение функции потерь на валидации 2.7909992933273315\n",
      "\n",
      "Эпоха 527\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.7371846274896101\n",
      "Среднее значение функции потерь на валидации 2.780503249168396\n",
      "\n",
      "Эпоха 528\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.7352060350504788\n",
      "Среднее значение функции потерь на валидации 2.7870935916900637\n",
      "\n",
      "Эпоха 529\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.7351725968447598\n",
      "Среднее значение функции потерь на валидации 2.787944960594177\n",
      "\n",
      "Эпоха 530\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.735205585306341\n",
      "Среднее значение функции потерь на валидации 2.7858644247055055\n",
      "\n",
      "Эпоха 531\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.7355518720366738\n",
      "Среднее значение функции потерь на валидации 2.7904292583465575\n",
      "\n",
      "Эпоха 532\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.7394505088979548\n",
      "Среднее значение функции потерь на валидации 2.7807141542434692\n",
      "\n",
      "Эпоха 533\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.7408419414000078\n",
      "Среднее значение функции потерь на валидации 2.7768867015838623\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 534\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.7391564629294656\n",
      "Среднее значение функции потерь на валидации 2.782599401473999\n",
      "\n",
      "Эпоха 535\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.7390926046804949\n",
      "Среднее значение функции потерь на валидации 2.7771947145462037\n",
      "\n",
      "Эпоха 536\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.7369032827290622\n",
      "Среднее значение функции потерь на валидации 2.779859447479248\n",
      "\n",
      "Эпоха 537\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.735213285142725\n",
      "Среднее значение функции потерь на валидации 2.783252644538879\n",
      "\n",
      "Эпоха 538\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.733606923710216\n",
      "Среднее значение функции потерь на валидации 2.7821587324142456\n",
      "\n",
      "Эпоха 539\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.7353475473143838\n",
      "Среднее значение функции потерь на валидации 2.777159237861633\n",
      "\n",
      "Эпоха 540\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.734839748252522\n",
      "Среднее значение функции потерь на валидации 2.779456305503845\n",
      "\n",
      "Эпоха 541\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.7346537655050105\n",
      "Среднее значение функции потерь на валидации 2.7811106204986573\n",
      "\n",
      "Эпоха 542\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.7357264269482007\n",
      "Среднее значение функции потерь на валидации 2.7779972314834596\n",
      "\n",
      "Эпоха 543\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.7357835986397483\n",
      "Среднее значение функции потерь на валидации 2.779217481613159\n",
      "\n",
      "Эпоха 544\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.7343854633244602\n",
      "Среднее значение функции потерь на валидации 2.7827487230300902\n",
      "\n",
      "Эпоха 545\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.7340385642918674\n",
      "Среднее значение функции потерь на валидации 2.7783567190170286\n",
      "\n",
      "Эпоха 546\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.7347825332121416\n",
      "Среднее значение функции потерь на валидации 2.7822534084320067\n",
      "\n",
      "Эпоха 547\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.7335684136910872\n",
      "Среднее значение функции потерь на валидации 2.778247427940369\n",
      "\n",
      "Эпоха 548\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.7340854081240566\n",
      "Среднее значение функции потерь на валидации 2.784411573410034\n",
      "\n",
      "Эпоха 549\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.731342456557534\n",
      "Среднее значение функции потерь на валидации 2.779058814048767\n",
      "\n",
      "Эпоха 550\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.7324320944872769\n",
      "Среднее значение функции потерь на валидации 2.781316542625427\n",
      "\n",
      "Эпоха 551\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.7314146106893367\n",
      "Среднее значение функции потерь на валидации 2.7797799110412598\n",
      "\n",
      "Эпоха 552\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.7370878512209111\n",
      "Среднее значение функции потерь на валидации 2.7743549823760985\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 553\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.7328561002557927\n",
      "Среднее значение функции потерь на валидации 2.781216049194336\n",
      "\n",
      "Эпоха 554\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.7306270761923357\n",
      "Среднее значение функции потерь на валидации 2.7786943197250364\n",
      "\n",
      "Эпоха 555\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.728904198516499\n",
      "Среднее значение функции потерь на валидации 2.7787312030792237\n",
      "\n",
      "Эпоха 556\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.7306277535178445\n",
      "Среднее значение функции потерь на валидации 2.776463842391968\n",
      "\n",
      "Эпоха 557\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.7297545996579258\n",
      "Среднее значение функции потерь на валидации 2.7797934770584107\n",
      "\n",
      "Эпоха 558\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.730888469652696\n",
      "Среднее значение функции потерь на валидации 2.775925898551941\n",
      "\n",
      "Эпоха 559\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.7265377640724182\n",
      "Среднее значение функции потерь на валидации 2.7798330545425416\n",
      "\n",
      "Эпоха 560\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.723983352834528\n",
      "Среднее значение функции потерь на валидации 2.781183671951294\n",
      "\n",
      "Эпоха 561\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.7281422398307107\n",
      "Среднее значение функции потерь на валидации 2.779630494117737\n",
      "\n",
      "Эпоха 562\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.7284138256853276\n",
      "Среднее значение функции потерь на валидации 2.7837898969650268\n",
      "\n",
      "Эпоха 563\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.7275856299833818\n",
      "Среднее значение функции потерь на валидации 2.7790863275527955\n",
      "\n",
      "Эпоха 564\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.730330841107802\n",
      "Среднее значение функции потерь на валидации 2.7736815214157104\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 565\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.7280202887275002\n",
      "Среднее значение функции потерь на валидации 2.779588007926941\n",
      "\n",
      "Эпоха 566\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.726610086180947\n",
      "Среднее значение функции потерь на валидации 2.774258041381836\n",
      "\n",
      "Эпоха 567\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.7273789698427373\n",
      "Среднее значение функции потерь на валидации 2.780778741836548\n",
      "\n",
      "Эпоха 568\n",
      "Эпоха: 22 итераций, 5.30 сек\n",
      "Среднее значение функции потерь на обучении 1.7258180000565269\n",
      "Среднее значение функции потерь на валидации 2.785305309295654\n",
      "\n",
      "Эпоха 569\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.7277969826351514\n",
      "Среднее значение функции потерь на валидации 2.77480947971344\n",
      "\n",
      "Эпоха 570\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.7269920164888555\n",
      "Среднее значение функции потерь на валидации 2.774209499359131\n",
      "\n",
      "Эпоха 571\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.7279835560105063\n",
      "Среднее значение функции потерь на валидации 2.773803377151489\n",
      "\n",
      "Эпоха 572\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.7276846007867293\n",
      "Среднее значение функции потерь на валидации 2.776836323738098\n",
      "\n",
      "Эпоха 573\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.724881719459187\n",
      "Среднее значение функции потерь на валидации 2.775645685195923\n",
      "\n",
      "Эпоха 574\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.7273165746168657\n",
      "Среднее значение функции потерь на валидации 2.7789531707763673\n",
      "\n",
      "Эпоха 575\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.726826245134527\n",
      "Среднее значение функции потерь на валидации 2.777804470062256\n",
      "\n",
      "Эпоха 576\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.7269978306510232\n",
      "Среднее значение функции потерь на валидации 2.775508451461792\n",
      "\n",
      "Эпоха 577\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.7274158976294778\n",
      "Среднее значение функции потерь на валидации 2.781378698348999\n",
      "\n",
      "Эпоха 578\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.7241083871234546\n",
      "Среднее значение функции потерь на валидации 2.7775798797607423\n",
      "\n",
      "Эпоха 579\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.7292937419631265\n",
      "Среднее значение функции потерь на валидации 2.7731312036514284\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 580\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.7262329350818286\n",
      "Среднее значение функции потерь на валидации 2.767245388031006\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 581\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.7229361479932612\n",
      "Среднее значение функции потерь на валидации 2.7722474575042724\n",
      "\n",
      "Эпоха 582\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.7269403717734597\n",
      "Среднее значение функции потерь на валидации 2.771489906311035\n",
      "\n",
      "Эпоха 583\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.7261495156721636\n",
      "Среднее значение функции потерь на валидации 2.768468713760376\n",
      "\n",
      "Эпоха 584\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.7267212163318286\n",
      "Среднее значение функции потерь на валидации 2.7777238368988035\n",
      "\n",
      "Эпоха 585\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.7238512526858936\n",
      "Среднее значение функции потерь на валидации 2.777719187736511\n",
      "\n",
      "Эпоха 586\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.7237809679724954\n",
      "Среднее значение функции потерь на валидации 2.773759388923645\n",
      "\n",
      "Эпоха 587\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.7243473204699429\n",
      "Среднее значение функции потерь на валидации 2.7744976758956907\n",
      "\n",
      "Эпоха 588\n",
      "Эпоха: 22 итераций, 5.30 сек\n",
      "Среднее значение функции потерь на обучении 1.7227635708722202\n",
      "Среднее значение функции потерь на валидации 2.7776399850845337\n",
      "\n",
      "Эпоха 589\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.7250795689496128\n",
      "Среднее значение функции потерь на валидации 2.770618224143982\n",
      "\n",
      "Эпоха 590\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.7248088392344387\n",
      "Среднее значение функции потерь на валидации 2.7759998083114623\n",
      "\n",
      "Эпоха 591\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.7233224673704668\n",
      "Среднее значение функции потерь на валидации 2.7727190494537353\n",
      "\n",
      "Эпоха 592\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.7220309051600369\n",
      "Среднее значение функции потерь на валидации 2.7698818683624267\n",
      "\n",
      "Эпоха 593\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.7249981544234536\n",
      "Среднее значение функции потерь на валидации 2.774398350715637\n",
      "\n",
      "Эпоха 594\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.7242511023174634\n",
      "Среднее значение функции потерь на валидации 2.7734306335449217\n",
      "\n",
      "Эпоха 595\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.7217784090475603\n",
      "Среднее значение функции потерь на валидации 2.7675554037094114\n",
      "\n",
      "Эпоха 596\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.7193892002105713\n",
      "Среднее значение функции потерь на валидации 2.7730626821517945\n",
      "\n",
      "Эпоха 597\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.7199823206121272\n",
      "Среднее значение функции потерь на валидации 2.7751821517944335\n",
      "\n",
      "Эпоха 598\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.7216744043610313\n",
      "Среднее значение функции потерь на валидации 2.7739171504974367\n",
      "\n",
      "Эпоха 599\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.7205409624359824\n",
      "Среднее значение функции потерь на валидации 2.774725246429443\n",
      "\n",
      "Эпоха 600\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.721191476691853\n",
      "Среднее значение функции потерь на валидации 2.775194525718689\n",
      "\n",
      "Эпоха 601\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.721559394489635\n",
      "Среднее значение функции потерь на валидации 2.776030421257019\n",
      "Epoch   602: reducing learning rate of group 0 to 2.5000e-04.\n",
      "\n",
      "Эпоха 602\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.7122190432115034\n",
      "Среднее значение функции потерь на валидации 2.762265706062317\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 603\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.7086634148250928\n",
      "Среднее значение функции потерь на валидации 2.769845175743103\n",
      "\n",
      "Эпоха 604\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.7069706104018472\n",
      "Среднее значение функции потерь на валидации 2.7665760993957518\n",
      "\n",
      "Эпоха 605\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.6995654431256382\n",
      "Среднее значение функции потерь на валидации 2.770657181739807\n",
      "\n",
      "Эпоха 606\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.6995782256126404\n",
      "Среднее значение функции потерь на валидации 2.7696919679641723\n",
      "\n",
      "Эпоха 607\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.7003998810594732\n",
      "Среднее значение функции потерь на валидации 2.7656891107559205\n",
      "\n",
      "Эпоха 608\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.6991244066845288\n",
      "Среднее значение функции потерь на валидации 2.768538546562195\n",
      "\n",
      "Эпоха 609\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.6975520198995417\n",
      "Среднее значение функции потерь на валидации 2.768632698059082\n",
      "\n",
      "Эпоха 610\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.6994901895523071\n",
      "Среднее значение функции потерь на валидации 2.7606130123138426\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 611\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.6972485943274065\n",
      "Среднее значение функции потерь на валидации 2.7688592195510866\n",
      "\n",
      "Эпоха 612\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.6969720721244812\n",
      "Среднее значение функции потерь на валидации 2.7627878189086914\n",
      "\n",
      "Эпоха 613\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.6947561610828747\n",
      "Среднее значение функции потерь на валидации 2.768823266029358\n",
      "\n",
      "Эпоха 614\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.693432553247972\n",
      "Среднее значение функции потерь на валидации 2.7668801307678224\n",
      "\n",
      "Эпоха 615\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.691829112443057\n",
      "Среднее значение функции потерь на валидации 2.7657023429870606\n",
      "\n",
      "Эпоха 616\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.6931570985100486\n",
      "Среднее значение функции потерь на валидации 2.76721670627594\n",
      "\n",
      "Эпоха 617\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.6938382332975215\n",
      "Среднее значение функции потерь на валидации 2.76496798992157\n",
      "\n",
      "Эпоха 618\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.6914334893226624\n",
      "Среднее значение функции потерь на валидации 2.764471507072449\n",
      "\n",
      "Эпоха 619\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.6914398182522168\n",
      "Среднее значение функции потерь на валидации 2.762905979156494\n",
      "\n",
      "Эпоха 620\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.6900216828693042\n",
      "Среднее значение функции потерь на валидации 2.767744016647339\n",
      "\n",
      "Эпоха 621\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.6904157671061428\n",
      "Среднее значение функции потерь на валидации 2.7641657829284667\n",
      "\n",
      "Эпоха 622\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.6954459764740684\n",
      "Среднее значение функции потерь на валидации 2.767500615119934\n",
      "\n",
      "Эпоха 623\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.693860335783525\n",
      "Среднее значение функции потерь на валидации 2.7660665035247805\n",
      "\n",
      "Эпоха 624\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.6907183907248757\n",
      "Среднее значение функции потерь на валидации 2.7676044940948485\n",
      "\n",
      "Эпоха 625\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.6904810558665881\n",
      "Среднее значение функции потерь на валидации 2.766671323776245\n",
      "\n",
      "Эпоха 626\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.6898149035193704\n",
      "Среднее значение функции потерь на валидации 2.767740821838379\n",
      "\n",
      "Эпоха 627\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.6914156079292297\n",
      "Среднее значение функции потерь на валидации 2.765640211105347\n",
      "\n",
      "Эпоха 628\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.686175292188471\n",
      "Среднее значение функции потерь на валидации 2.765093445777893\n",
      "\n",
      "Эпоха 629\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.6881980950182134\n",
      "Среднее значение функции потерь на валидации 2.7671990633010863\n",
      "\n",
      "Эпоха 630\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.6875678842717952\n",
      "Среднее значение функции потерь на валидации 2.7648561000823975\n",
      "\n",
      "Эпоха 631\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.6915460228919983\n",
      "Среднее значение функции потерь на валидации 2.7626415491104126\n",
      "Epoch   632: reducing learning rate of group 0 to 1.2500e-04.\n",
      "\n",
      "Эпоха 632\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.6837693507021123\n",
      "Среднее значение функции потерь на валидации 2.763942813873291\n",
      "\n",
      "Эпоха 633\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.6839686686342412\n",
      "Среднее значение функции потерь на валидации 2.7586905479431154\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 634\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.68184786493128\n",
      "Среднее значение функции потерь на валидации 2.7663408756256103\n",
      "\n",
      "Эпоха 635\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.6784334074367175\n",
      "Среднее значение функции потерь на валидации 2.76433744430542\n",
      "\n",
      "Эпоха 636\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.6815520254048435\n",
      "Среднее значение функции потерь на валидации 2.7642240285873414\n",
      "\n",
      "Эпоха 637\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.6807641766288064\n",
      "Среднее значение функции потерь на валидации 2.755881428718567\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 638\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.6788911873644048\n",
      "Среднее значение функции потерь на валидации 2.7641073942184446\n",
      "\n",
      "Эпоха 639\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.6807142170992764\n",
      "Среднее значение функции потерь на валидации 2.7626177787780763\n",
      "\n",
      "Эпоха 640\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.6808017438108271\n",
      "Среднее значение функции потерь на валидации 2.7603022336959837\n",
      "\n",
      "Эпоха 641\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.6782934178005566\n",
      "Среднее значение функции потерь на валидации 2.7620623111724854\n",
      "\n",
      "Эпоха 642\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.67812302979556\n",
      "Среднее значение функции потерь на валидации 2.7585082054138184\n",
      "\n",
      "Эпоха 643\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.6741061156446284\n",
      "Среднее значение функции потерь на валидации 2.7626563549041747\n",
      "\n",
      "Эпоха 644\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.6786670739000493\n",
      "Среднее значение функции потерь на валидации 2.7598513841629027\n",
      "\n",
      "Эпоха 645\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.679295924576846\n",
      "Среднее значение функции потерь на валидации 2.7592493295669556\n",
      "\n",
      "Эпоха 646\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.6797975247556514\n",
      "Среднее значение функции потерь на валидации 2.7611225128173826\n",
      "\n",
      "Эпоха 647\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.6792757998813281\n",
      "Среднее значение функции потерь на валидации 2.7595393657684326\n",
      "\n",
      "Эпоха 648\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.6795441562479192\n",
      "Среднее значение функции потерь на валидации 2.7584704875946047\n",
      "\n",
      "Эпоха 649\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.6789811253547668\n",
      "Среднее значение функции потерь на валидации 2.7587799310684202\n",
      "\n",
      "Эпоха 650\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.6742973056706516\n",
      "Среднее значение функции потерь на валидации 2.757871675491333\n",
      "\n",
      "Эпоха 651\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.6787948554212397\n",
      "Среднее значение функции потерь на валидации 2.7613544940948485\n",
      "\n",
      "Эпоха 652\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.6738930236209522\n",
      "Среднее значение функции потерь на валидации 2.7604911804199217\n",
      "\n",
      "Эпоха 653\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.6745531558990479\n",
      "Среднее значение функции потерь на валидации 2.7613672971725465\n",
      "\n",
      "Эпоха 654\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.6785505414009094\n",
      "Среднее значение функции потерь на валидации 2.7607760429382324\n",
      "\n",
      "Эпоха 655\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.676188886165619\n",
      "Среднее значение функции потерь на валидации 2.7598445892333983\n",
      "\n",
      "Эпоха 656\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.6737704331224614\n",
      "Среднее значение функции потерь на валидации 2.7630292892456056\n",
      "\n",
      "Эпоха 657\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.671728713945909\n",
      "Среднее значение функции потерь на валидации 2.7591911792755126\n",
      "\n",
      "Эпоха 658\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.6782507733865217\n",
      "Среднее значение функции потерь на валидации 2.7637089014053347\n",
      "Epoch   659: reducing learning rate of group 0 to 6.2500e-05.\n",
      "\n",
      "Эпоха 659\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.6732555465264753\n",
      "Среднее значение функции потерь на валидации 2.7611657619476317\n",
      "\n",
      "Эпоха 660\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.67260389436375\n",
      "Среднее значение функции потерь на валидации 2.7576837301254273\n",
      "\n",
      "Эпоха 661\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.6678992672400041\n",
      "Среднее значение функции потерь на валидации 2.761865568161011\n",
      "\n",
      "Эпоха 662\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.6655912886966358\n",
      "Среднее значение функции потерь на валидации 2.754818391799927\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 663\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.6690765185789629\n",
      "Среднее значение функции потерь на валидации 2.756309175491333\n",
      "\n",
      "Эпоха 664\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.6699703119017861\n",
      "Среднее значение функции потерь на валидации 2.7607759475708007\n",
      "\n",
      "Эпоха 665\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.668923470106992\n",
      "Среднее значение функции потерь на валидации 2.7590672731399537\n",
      "\n",
      "Эпоха 666\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.6700210083614697\n",
      "Среднее значение функции потерь на валидации 2.758750629425049\n",
      "\n",
      "Эпоха 667\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.6687054959210483\n",
      "Среднее значение функции потерь на валидации 2.7622718095779417\n",
      "\n",
      "Эпоха 668\n",
      "Эпоха: 22 итераций, 5.45 сек\n",
      "Среднее значение функции потерь на обучении 1.6657281517982483\n",
      "Среднее значение функции потерь на валидации 2.7611647129058836\n",
      "\n",
      "Эпоха 669\n",
      "Эпоха: 22 итераций, 5.32 сек\n",
      "Среднее значение функции потерь на обучении 1.6691320701078936\n",
      "Среднее значение функции потерь на валидации 2.7561924695968627\n",
      "\n",
      "Эпоха 670\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.6691973155195063\n",
      "Среднее значение функции потерь на валидации 2.7597195863723756\n",
      "\n",
      "Эпоха 671\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.6702265360138633\n",
      "Среднее значение функции потерь на валидации 2.757847213745117\n",
      "\n",
      "Эпоха 672\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.6648342284289273\n",
      "Среднее значение функции потерь на валидации 2.7613091230392457\n",
      "\n",
      "Эпоха 673\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.6658967245708813\n",
      "Среднее значение функции потерь на валидации 2.760067176818848\n",
      "\n",
      "Эпоха 674\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.6709821224212646\n",
      "Среднее значение функции потерь на валидации 2.757877492904663\n",
      "\n",
      "Эпоха 675\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.6656343720176003\n",
      "Среднее значение функции потерь на валидации 2.758651089668274\n",
      "\n",
      "Эпоха 676\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.6668092608451843\n",
      "Среднее значение функции потерь на валидации 2.7607938766479494\n",
      "\n",
      "Эпоха 677\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.6679895574396306\n",
      "Среднее значение функции потерь на валидации 2.7583197593688964\n",
      "\n",
      "Эпоха 678\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.6669265736233105\n",
      "Среднее значение функции потерь на валидации 2.7600600481033326\n",
      "\n",
      "Эпоха 679\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.669063221324574\n",
      "Среднее значение функции потерь на валидации 2.7582050561904907\n",
      "\n",
      "Эпоха 680\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.6654485355723987\n",
      "Среднее значение функции потерь на валидации 2.7590233087539673\n",
      "\n",
      "Эпоха 681\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.6701925884593616\n",
      "Среднее значение функции потерь на валидации 2.7554601192474366\n",
      "\n",
      "Эпоха 682\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.6629304940050298\n",
      "Среднее значение функции потерь на валидации 2.758879470825195\n",
      "\n",
      "Эпоха 683\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.6659019210121848\n",
      "Среднее значение функции потерь на валидации 2.760760045051575\n",
      "Epoch   684: reducing learning rate of group 0 to 3.1250e-05.\n",
      "\n",
      "Эпоха 684\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.6651491143486716\n",
      "Среднее значение функции потерь на валидации 2.756253743171692\n",
      "\n",
      "Эпоха 685\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.6637849861925298\n",
      "Среднее значение функции потерь на валидации 2.75915105342865\n",
      "\n",
      "Эпоха 686\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.6657603003761985\n",
      "Среднее значение функции потерь на валидации 2.757428693771362\n",
      "\n",
      "Эпоха 687\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.6680846647782759\n",
      "Среднее значение функции потерь на валидации 2.7561968564987183\n",
      "\n",
      "Эпоха 688\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.6647801019928672\n",
      "Среднее значение функции потерь на валидации 2.75864725112915\n",
      "\n",
      "Эпоха 689\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.6660963188518176\n",
      "Среднее значение функции потерь на валидации 2.7571983098983766\n",
      "\n",
      "Эпоха 690\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.66512822562998\n",
      "Среднее значение функции потерь на валидации 2.7587029457092287\n",
      "\n",
      "Эпоха 691\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.6644023169170727\n",
      "Среднее значение функции потерь на валидации 2.7530016183853148\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 692\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.6633154912428423\n",
      "Среднее значение функции потерь на валидации 2.7592992782592773\n",
      "\n",
      "Эпоха 693\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.6708674214103005\n",
      "Среднее значение функции потерь на валидации 2.759410929679871\n",
      "\n",
      "Эпоха 694\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.6630884300578723\n",
      "Среднее значение функции потерь на валидации 2.7585142612457276\n",
      "\n",
      "Эпоха 695\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.661976765502583\n",
      "Среднее значение функции потерь на валидации 2.756104850769043\n",
      "\n",
      "Эпоха 696\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.6656744209202854\n",
      "Среднее значение функции потерь на валидации 2.7588628053665163\n",
      "\n",
      "Эпоха 697\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.6651743650436401\n",
      "Среднее значение функции потерь на валидации 2.75692355632782\n",
      "\n",
      "Эпоха 698\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.6626075289466165\n",
      "Среднее значение функции потерь на валидации 2.75748028755188\n",
      "\n",
      "Эпоха 699\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.6662747914140874\n",
      "Среднее значение функции потерь на валидации 2.76012921333313\n",
      "\n",
      "Эпоха 700\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.6657852259549228\n",
      "Среднее значение функции потерь на валидации 2.7595083236694338\n",
      "\n",
      "Эпоха 701\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.664525953206149\n",
      "Среднее значение функции потерь на валидации 2.7548501968383787\n",
      "\n",
      "Эпоха 702\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.6619537201794712\n",
      "Среднее значение функции потерь на валидации 2.7553878307342528\n",
      "\n",
      "Эпоха 703\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.6615025726231663\n",
      "Среднее значение функции потерь на валидации 2.7596373558044434\n",
      "\n",
      "Эпоха 704\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.6623835617845708\n",
      "Среднее значение функции потерь на валидации 2.7589075326919557\n",
      "\n",
      "Эпоха 705\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.6647300015796314\n",
      "Среднее значение функции потерь на валидации 2.7581847667694093\n",
      "\n",
      "Эпоха 706\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.6653525179082698\n",
      "Среднее значение функции потерь на валидации 2.7569597721099854\n",
      "\n",
      "Эпоха 707\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.6657558950510891\n",
      "Среднее значение функции потерь на валидации 2.7560134887695313\n",
      "\n",
      "Эпоха 708\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.6626035896214573\n",
      "Среднее значение функции потерь на валидации 2.7583719730377196\n",
      "\n",
      "Эпоха 709\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.6658244729042053\n",
      "Среднее значение функции потерь на валидации 2.759276294708252\n",
      "\n",
      "Эпоха 710\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.665461171757091\n",
      "Среднее значение функции потерь на валидации 2.7569904804229735\n",
      "\n",
      "Эпоха 711\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.6638750650665977\n",
      "Среднее значение функции потерь на валидации 2.7589133024215697\n",
      "\n",
      "Эпоха 712\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.6658754348754883\n",
      "Среднее значение функции потерь на валидации 2.7561480045318603\n",
      "Epoch   713: reducing learning rate of group 0 to 1.5625e-05.\n",
      "\n",
      "Эпоха 713\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.6618858521634883\n",
      "Среднее значение функции потерь на валидации 2.7541226625442503\n",
      "\n",
      "Эпоха 714\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.6624103784561157\n",
      "Среднее значение функции потерь на валидации 2.7575226783752442\n",
      "\n",
      "Эпоха 715\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.6618573990735142\n",
      "Среднее значение функции потерь на валидации 2.756368613243103\n",
      "\n",
      "Эпоха 716\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.6616938276724382\n",
      "Среднее значение функции потерь на валидации 2.757499599456787\n",
      "\n",
      "Эпоха 717\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.6590992483225735\n",
      "Среднее значение функции потерь на валидации 2.75754976272583\n",
      "\n",
      "Эпоха 718\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.663828898559917\n",
      "Среднее значение функции потерь на валидации 2.7578356742858885\n",
      "\n",
      "Эпоха 719\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.6599106680263171\n",
      "Среднее значение функции потерь на валидации 2.7576082706451417\n",
      "\n",
      "Эпоха 720\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.6657003381035544\n",
      "Среднее значение функции потерь на валидации 2.7588521242141724\n",
      "\n",
      "Эпоха 721\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.6641241799701343\n",
      "Среднее значение функции потерь на валидации 2.7588300466537476\n",
      "\n",
      "Эпоха 722\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.6646206053820523\n",
      "Среднее значение функции потерь на валидации 2.755287933349609\n",
      "\n",
      "Эпоха 723\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.6636352864178745\n",
      "Среднее значение функции потерь на валидации 2.7551008462905884\n",
      "\n",
      "Эпоха 724\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.6613890799609097\n",
      "Среднее значение функции потерь на валидации 2.7515533447265623\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 725\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.6644100709394976\n",
      "Среднее значение функции потерь на валидации 2.755597400665283\n",
      "\n",
      "Эпоха 726\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.6595008048144253\n",
      "Среднее значение функции потерь на валидации 2.7569660902023316\n",
      "\n",
      "Эпоха 727\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.6630011255090886\n",
      "Среднее значение функции потерь на валидации 2.759253740310669\n",
      "\n",
      "Эпоха 728\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.66406681320884\n",
      "Среднее значение функции потерь на валидации 2.755901002883911\n",
      "\n",
      "Эпоха 729\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.6594185558232395\n",
      "Среднее значение функции потерь на валидации 2.7586777925491335\n",
      "\n",
      "Эпоха 730\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.6597444144162266\n",
      "Среднее значение функции потерь на валидации 2.7599732875823975\n",
      "\n",
      "Эпоха 731\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.665274522521279\n",
      "Среднее значение функции потерь на валидации 2.758635139465332\n",
      "\n",
      "Эпоха 732\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.6600004217841409\n",
      "Среднее значение функции потерь на валидации 2.7542473554611204\n",
      "\n",
      "Эпоха 733\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.6609021912921558\n",
      "Среднее значение функции потерь на валидации 2.755398178100586\n",
      "\n",
      "Эпоха 734\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.665163966742429\n",
      "Среднее значение функции потерь на валидации 2.758580732345581\n",
      "\n",
      "Эпоха 735\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.6646201718937268\n",
      "Среднее значение функции потерь на валидации 2.756232476234436\n",
      "\n",
      "Эпоха 736\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.6607313806360418\n",
      "Среднее значение функции потерь на валидации 2.759695816040039\n",
      "\n",
      "Эпоха 737\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.6622283838012002\n",
      "Среднее значение функции потерь на валидации 2.7535727977752686\n",
      "\n",
      "Эпоха 738\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.6630686846646396\n",
      "Среднее значение функции потерь на валидации 2.7588053703308106\n",
      "\n",
      "Эпоха 739\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.6604217345064336\n",
      "Среднее значение функции потерь на валидации 2.757244110107422\n",
      "\n",
      "Эпоха 740\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.6617628390138799\n",
      "Среднее значение функции потерь на валидации 2.7553643941879273\n",
      "\n",
      "Эпоха 741\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.6619129668582568\n",
      "Среднее значение функции потерь на валидации 2.757191562652588\n",
      "\n",
      "Эпоха 742\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.6610499891367825\n",
      "Среднее значение функции потерь на валидации 2.755572247505188\n",
      "\n",
      "Эпоха 743\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.6622923070734197\n",
      "Среднее значение функции потерь на валидации 2.758932876586914\n",
      "\n",
      "Эпоха 744\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.662933349609375\n",
      "Среднее значение функции потерь на валидации 2.756844162940979\n",
      "\n",
      "Эпоха 745\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.6615846753120422\n",
      "Среднее значение функции потерь на валидации 2.7556910037994387\n",
      "Epoch   746: reducing learning rate of group 0 to 7.8125e-06.\n",
      "\n",
      "Эпоха 746\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.6614189689809626\n",
      "Среднее значение функции потерь на валидации 2.756563186645508\n",
      "\n",
      "Эпоха 747\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.6625278808853843\n",
      "Среднее значение функции потерь на валидации 2.755314254760742\n",
      "\n",
      "Эпоха 748\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.6628740484064275\n",
      "Среднее значение функции потерь на валидации 2.758826160430908\n",
      "\n",
      "Эпоха 749\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.6629136204719543\n",
      "Среднее значение функции потерь на валидации 2.752861738204956\n",
      "\n",
      "Эпоха 750\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.6610730723901228\n",
      "Среднее значение функции потерь на валидации 2.7551777362823486\n",
      "\n",
      "Эпоха 751\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.6644361994483254\n",
      "Среднее значение функции потерь на валидации 2.755763554573059\n",
      "\n",
      "Эпоха 752\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.6625490296970715\n",
      "Среднее значение функции потерь на валидации 2.757158613204956\n",
      "\n",
      "Эпоха 753\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.660714637149464\n",
      "Среднее значение функции потерь на валидации 2.7552717447280886\n",
      "\n",
      "Эпоха 754\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.6634369167414578\n",
      "Среднее значение функции потерь на валидации 2.7562920331954954\n",
      "\n",
      "Эпоха 755\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.6634216904640198\n",
      "Среднее значение функции потерь на валидации 2.7542437314987183\n",
      "\n",
      "Эпоха 756\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.6598320928486912\n",
      "Среднее значение функции потерь на валидации 2.7560624837875367\n",
      "\n",
      "Эпоха 757\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.660286708311601\n",
      "Среднее значение функции потерь на валидации 2.754441523551941\n",
      "\n",
      "Эпоха 758\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.661871081048792\n",
      "Среднее значение функции потерь на валидации 2.759272599220276\n",
      "\n",
      "Эпоха 759\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.6558107354424216\n",
      "Среднее значение функции потерь на валидации 2.7544294357299806\n",
      "\n",
      "Эпоха 760\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.6617205576463179\n",
      "Среднее значение функции потерь на валидации 2.7587859869003295\n",
      "\n",
      "Эпоха 761\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.6636222709308972\n",
      "Среднее значение функции потерь на валидации 2.754327178001404\n",
      "\n",
      "Эпоха 762\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.6595482338558545\n",
      "Среднее значение функции потерь на валидации 2.7546969413757325\n",
      "\n",
      "Эпоха 763\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.6601875966245478\n",
      "Среднее значение функции потерь на валидации 2.7554054260253906\n",
      "\n",
      "Эпоха 764\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.661970853805542\n",
      "Среднее значение функции потерь на валидации 2.756561589241028\n",
      "\n",
      "Эпоха 765\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.6630839705467224\n",
      "Среднее значение функции потерь на валидации 2.7567806482315063\n",
      "\n",
      "Эпоха 766\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.6600594249638645\n",
      "Среднее значение функции потерь на валидации 2.7590519428253173\n",
      "Epoch   767: reducing learning rate of group 0 to 3.9063e-06.\n",
      "\n",
      "Эпоха 767\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.6604089736938477\n",
      "Среднее значение функции потерь на валидации 2.7569577932357787\n",
      "\n",
      "Эпоха 768\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.6584973822940479\n",
      "Среднее значение функции потерь на валидации 2.759262466430664\n",
      "\n",
      "Эпоха 769\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.663510181687095\n",
      "Среднее значение функции потерь на валидации 2.7558261871337892\n",
      "\n",
      "Эпоха 770\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.6595915989442305\n",
      "Среднее значение функции потерь на валидации 2.7559534549713134\n",
      "\n",
      "Эпоха 771\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.6614865823225542\n",
      "Среднее значение функции потерь на валидации 2.7537160396575926\n",
      "\n",
      "Эпоха 772\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.660248263315721\n",
      "Среднее значение функции потерь на валидации 2.75584237575531\n",
      "\n",
      "Эпоха 773\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.660111048004844\n",
      "Среднее значение функции потерь на валидации 2.7571211099624633\n",
      "\n",
      "Эпоха 774\n",
      "Эпоха: 22 итераций, 5.28 сек\n",
      "Среднее значение функции потерь на обучении 1.662664982405576\n",
      "Среднее значение функции потерь на валидации 2.7539512395858763\n",
      "\n",
      "Эпоха 775\n",
      "Эпоха: 22 итераций, 5.29 сек\n",
      "Среднее значение функции потерь на обучении 1.6582504998553882\n",
      "Среднее значение функции потерь на валидации 2.7578887701034547\n",
      "Модель не улучшилась за последние 50 эпох, прекращаем обучение\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (best_val_loss,\n",
    "#  best_my_transf_model) = train_eval_loop(my_transf_model,\n",
    "#                                          train_dataset,\n",
    "#                                          test_dataset,\n",
    "#                                          lm_cross_entropy,\n",
    "#                                          lr=2e-3,\n",
    "#                                          epoch_n=2000,\n",
    "#                                         #  batch_size=512, # Исходный батсайз пришлось уменьшить \n",
    "#                                          batch_size=256,\n",
    "#                                          device='cuda',\n",
    "#                                          early_stopping_patience=50,\n",
    "#                                          max_batches_per_epoch_train=1000,\n",
    "#                                          max_batches_per_epoch_val=1000,\n",
    "#                                          lr_scheduler_ctor=lr_scheduler)\n",
    "# # Если Вы запускаете ноутбук на colab или kaggle, добавьте в начало пути ./stepik-dl-nlp\n",
    "# torch.save(best_my_transf_model.state_dict(), './models/4.6.war_and_peace_my_transf_best.pth')\n",
    "\n",
    "# Если Вы запускаете ноутбук на colab или kaggle, добавьте в начало пути ./stepik-dl-nlp\n",
    "my_transf_model.load_state_dict(torch.load('./models/4.6.war_and_peace_my_transf_best.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Наша реализация - жадная генерация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ну, и давайте проверим, вообще, работает ли наша модель, генерирует ли она что-то осмысленное... В целом — да. Заметьте, что из того же начального предложения эта модель выдаёт другое предложение, в отличие от первой модели, которую мы обучили в этом семинаре. На самом деле, если мы запустим обучение ещё раз, оно сойдётся к другому минимуму и эта модель тоже будет генерить что-то другое. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T18:29:31.862429Z",
     "start_time": "2019-11-05T18:29:31.841831Z"
    }
   },
   "outputs": [],
   "source": [
    "my_greedy_generator = GreedyGenerator(my_transf_model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T18:29:32.263263Z",
     "start_time": "2019-11-05T18:29:31.988891Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'сказала княжна, оглядывая Андрею, как будто не удивляясь, говорил: - Vous savez, mon ami, 192 - сказала она, нежно улыбнув руку и'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_greedy_generator('сказала княжна, оглядывая Андре')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Визуализация карт внимания"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Помните, из функции, которая реализует механизм внимания с несколькими головами, мы возвращали ещё и карты внимания (то есть тензор нормированных релевантностей — то, что получается после софтмакса и после dropout). Мы это делали не случайно, а для того, чтобы иметь возможность нарисовать эти карты активации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T18:29:33.644923Z",
     "start_time": "2019-11-05T18:29:33.614615Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_attention_maps(model, input_string, tokenizer, device='cuda', max_heads=2, figsize=(16, 10)):\n",
    "    device = torch.device(device)\n",
    "\n",
    "    token_ids = tokenizer.encode([input_string])[0]\n",
    "\n",
    "    token_strs = [tokenizer.id_to_subword(i) for i in token_ids]\n",
    "    in_len = len(token_ids)\n",
    "    ticks = np.arange(0, in_len)\n",
    "\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    in_batch = torch.tensor(token_ids).unsqueeze(0).to(device)\n",
    "    model(in_batch)\n",
    "\n",
    "    for module in model.modules():\n",
    "        if isinstance(module, MyMultiheadSelfAttention):\n",
    "            cur_last_attention_map = module.last_attention_map[0].cpu().numpy()\n",
    "            n_heads = cur_last_attention_map.shape[-1]\n",
    "            n_heads_to_vis = min(n_heads, max_heads)\n",
    "\n",
    "            fig, axes = plt.subplots(1, n_heads_to_vis)\n",
    "            fig.set_size_inches(figsize)\n",
    "            for head_i in range(n_heads_to_vis):\n",
    "                ax = axes[head_i]\n",
    "                ax.imshow(cur_last_attention_map[..., head_i])\n",
    "\n",
    "                ax.set_yticks(ticks)\n",
    "                ax.set_ylim(bottom=in_len - 0.5, top=-0.5)\n",
    "                ax.set_yticklabels(token_strs)\n",
    "\n",
    "                ax.set_xticks(ticks)\n",
    "                ax.set_xticklabels(token_strs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T18:29:34.935250Z",
     "start_time": "2019-11-05T18:29:33.745970Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1152x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1152x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1152x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_attention_maps(my_transf_model, 'сказал Кутузов, оглядывая Бонапарта', tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Здесь мы видим несколько графиков, каждая вот такая вот строка (слова вдоль оси Y) соответствует слою трансформера (то есть это самый первый слой трансформера, дальше идёт второй слой трансформера...), а каждый столбец соответствует голове (то есть, это — первые головы, это — вторые головы для каждого слоя). Можно больше, у нас в модели всего 16 голов, но, просто — не влезло бы. По строкам здесь отложены запросы, и каждая позиция помечена токеном во входной последовательности, который стоял на этой позиции. По столбцам отложены ключи. Здесь у нас запросы (queries, ось Y), а здесь у нас ключи (keys ось X). И, чем ярче клеточка на пересечении строки и столбца, тем более значим этот ключ для этого запроса (по мнению модели). Мы видим, что на первом слое карты активации очень контрастные, очень разреженные. То есть, для каждой выходной позиции близок только один ключ. Интересно обратить внимание вот на эти строки. Эти стройки соответствуют токенам, то есть N-граммам из имени Бонапарта. Интересно, что для почти всех N-грамм из имени, наиболее значимым ключом является первая N-грамма этого имени (то есть у нас есть такие связи). То есть для вычисления признаков (вот, например, для этой позиции) очень важны признаки начала имени. Это и есть учёт контекста. У второй головы карта активации совершенно другая. Здесь, кажется, в вычислении признаков для всех токенов после запятой самый важный исходный токен — это сама \"запятая\", то есть мы, как бы, отделяем деепричастный оборот здесь. Конечно, это всего лишь — мои попытки натянуть какую-то рационализацию на эти карты активации, неочевидно, что вообще эти карты активации для человека будут понятны или полезны. Но иногда на них просто интересно посмотреть. На втором слое трансформера карты активации уже более сглаженные, уже нету каких-то отдельных, выделенных, наиболее значимых позиций, уже каждая позиция обращает внимание, в принципе, на все предыдущие позиции. Обратите внимание, что верхняя половина этих карт — тёмная. Это именно то, чего мы хотели добиться, применяя маску зависимостей. То есть здесь в маске зависимости на этих позициях стоит -infinity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ну, что ж, это был большой семинар, который был посвящён сразу нескольким темам — а именно, моделированию языка, byte pair encoding (то есть какая-то токенизация универсальная, современная, которая позволяет выбирать между длиной последовательностей и размером словаря). Мы попробовали применить такую токенизацию путём использования библиотеки \"YouTokenToMe\". Затем мы собрали и обучили языковую модель, используя реализацию трансформера из стандартной библиотеки pytorch, мы попробовали погенерировать тексты с помощью \"полностью жадного\" алгоритма и с помощью \"лучевого поиска\". А затем мы рассмотрели — а как же можно руками, самостоятельно, не используя готовой библиотеки, реализовать механизм внимания — используя только базовые операции из pytorch. И, таким образом, мы собрали свой энкодер для трансформера, реализовав механизм внимания с несколькими головами, реализовав \"self attention\", реализовав отдельный слой трансформера и собрав это всё в encoder. А также мы обучили нашу реализацию и увидели, что она, в принципе, работает примерно так же, как и стандартная реализация — значит, что, кажется, мы не ошиблись. А ещё, напоследок, мы заглянули внутрь обученной модели и посмотрели, как между собой связываются входные и выходные позиции на разных уровнях и для разных голов. Спасибо за внимание!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img](img/4.6.1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
