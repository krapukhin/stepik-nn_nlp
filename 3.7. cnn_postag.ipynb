{"cells":[{"cell_type":"markdown","metadata":{"id":"z7zxCP0KDhdW"},"source":["Воспользуемся сверточной нейросетью на примере задачи определения частей речи слов \"POS-tagging\" (part of speech tagging). pyconll — потребуется для загрузки корпуса. В этом семинаре мы будем использовать размеченный корпус, который называется \"SynTag Rus\". Этот корпус был размечен руками, лингвистами, и в нём содержится разметка по частям речи, по нормальным формам слов, синтаксическая разметка. Он предназначен для того, чтобы настраивать и проверять методы лингвистического анализа текстов, а именно — морфологического разбора и синтаксического разбора. Разметка в этом корпусе представлена в формате CoNLL — это достаточно распространённый формат для того, чтобы хранить аннотированные деревья и разную лингвистическую разметку.  "]},{"cell_type":"markdown","metadata":{"id":"kfAIQ-gKaZtN"},"source":["# Свёрточные нейросети и POS-теггинг\n","\n","POS-теггинг - определение частей речи (снятие частеречной неоднозначности)"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":112412,"status":"ok","timestamp":1640341641292,"user":{"displayName":"Дмитрий Крапухин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggc2v_CQHmxf2sl_IRluFRrUm2MTBhbfr-oOZ_PGnk=s64","userId":"11342788103765688294"},"user_tz":-180},"id":"0ih0-6y9aZtP","outputId":"0a1d22df-fda5-40ac-8923-fbbc10e35379"},"outputs":[],"source":["# Если Вы запускаете ноутбук на colab или kaggle,\n","# выполните следующие строчки, чтобы подгрузить библиотеку dlnlputils:\n","\n","# !git clone https://github.com/Samsung-IT-Academy/stepik-dl-nlp.git && pip install -r stepik-dl-nlp/requirements.txt\n","# import sys; sys.path.append('./stepik-dl-nlp')\n","# !pip install pyconll\n","\n","%load_ext autoreload\n","%autoreload 2\n","\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","from sklearn.metrics import classification_report\n","\n","import numpy as np\n","\n","import pyconll\n","\n","import torch\n","from torch import nn\n","from torch.nn import functional as F\n","from torch.utils.data import TensorDataset\n","\n","import dlnlputils\n","from dlnlputils.data import tokenize_corpus, build_vocabulary, \\\n","    character_tokenize, pos_corpus_to_tensor, POSTagger\n","from dlnlputils.pipeline import train_eval_loop, predict_with_model, init_random_seed\n","\n","init_random_seed()"]},{"cell_type":"markdown","metadata":{"id":"wWV2HDilaZtR"},"source":["## Загрузка текстов и разбиение на обучающую и тестовую подвыборки"]},{"cell_type":"code","execution_count":2,"metadata":{"ExecuteTime":{"end_time":"2019-10-29T19:47:08.433599Z","start_time":"2019-10-29T19:46:05.110693Z"},"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":27148,"status":"ok","timestamp":1640341679313,"user":{"displayName":"Дмитрий Крапухин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggc2v_CQHmxf2sl_IRluFRrUm2MTBhbfr-oOZ_PGnk=s64","userId":"11342788103765688294"},"user_tz":-180},"id":"v4FIbo58aZtS","outputId":"4cfef2da-3b90-44af-bc8a-04cd932925b9"},"outputs":[{"name":"stdout","output_type":"stream","text":["--2022-02-08 23:51:57--  https://raw.githubusercontent.com/UniversalDependencies/UD_Russian-SynTagRus/r2.8/ru_syntagrus-ud-train.conllu\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 81039282 (77M) [text/plain]\n","Saving to: ‘./datasets/ru_syntagrus-ud-train.conllu’\n","\n","./datasets/ru_synta 100%[===================>]  77.28M  33.0MB/s    in 2.3s    \n","\n","2022-02-08 23:52:02 (33.0 MB/s) - ‘./datasets/ru_syntagrus-ud-train.conllu’ saved [81039282/81039282]\n","\n","--2022-02-08 23:52:03--  https://raw.githubusercontent.com/UniversalDependencies/UD_Russian-SynTagRus/r2.8/ru_syntagrus-ud-dev.conllu\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.108.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 10902738 (10M) [text/plain]\n","Saving to: ‘./datasets/ru_syntagrus-ud-dev.conllu’\n","\n","./datasets/ru_synta 100%[===================>]  10.40M  19.5MB/s    in 0.5s    \n","\n","2022-02-08 23:52:04 (19.5 MB/s) - ‘./datasets/ru_syntagrus-ud-dev.conllu’ saved [10902738/10902738]\n","\n"]}],"source":["# Если Вы запускаете ноутбук на colab или kaggle, добавьте в начало пути ./stepik-dl-nlp\n","# !wget -O ./stepik-dl-nlp/datasets/ru_syntagrus-ud-train.conllu https://raw.githubusercontent.com/UniversalDependencies/UD_Russian-SynTagRus/r2.8/ru_syntagrus-ud-train.conllu\n","# !wget -O ./stepik-dl-nlp/datasets/ru_syntagrus-ud-dev.conllu https://raw.githubusercontent.com/UniversalDependencies/UD_Russian-SynTagRus/master/ru_syntagrus-ud-dev.conllu\n","\n","!wget -O ./datasets/ru_syntagrus-ud-train.conllu https://raw.githubusercontent.com/UniversalDependencies/UD_Russian-SynTagRus/r2.8/ru_syntagrus-ud-train.conllu\n","!wget -O ./datasets/ru_syntagrus-ud-dev.conllu https://raw.githubusercontent.com/UniversalDependencies/UD_Russian-SynTagRus/r2.8/ru_syntagrus-ud-dev.conllu\n","\n","# Если Вы запускаете ноутбук на colab или kaggle, добавьте в начало пути ./stepik-dl-nlp\n","full_train = pyconll.load_from_file('./datasets/ru_syntagrus-ud-train.conllu')\n","full_test = pyconll.load_from_file('./datasets/ru_syntagrus-ud-dev.conllu')"]},{"cell_type":"markdown","metadata":{"id":"DY95auamDuil"},"source":["Возьмём пару первых предложений и посмотрим, как выглядит разметка для задачи определения частей речи слов. Предложения разделены пустой строкой, то есть первое предложение — это, по сути, просто заголовок: \"анкета\", \"точка\". И мы видим, что \"анкета\" — это существительное, а \"точка\" получила тэг \"PUNCT\", то есть — пунктуация. Второе предложение гораздо длиннее, и в нём для каждого токена проставлены тэги частей речи. "]},{"cell_type":"code","execution_count":3,"metadata":{"ExecuteTime":{"end_time":"2019-10-29T19:49:56.548127Z","start_time":"2019-10-29T19:49:56.527559Z"},"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1640341679314,"user":{"displayName":"Дмитрий Крапухин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggc2v_CQHmxf2sl_IRluFRrUm2MTBhbfr-oOZ_PGnk=s64","userId":"11342788103765688294"},"user_tz":-180},"id":"_GarLEJpaZtS","outputId":"02f3a20c-a9af-4259-f088-0a1dd61ec9a8"},"outputs":[{"name":"stdout","output_type":"stream","text":["Анкета NOUN\n",". PUNCT\n","\n","Начальник NOUN\n","областного ADJ\n","управления NOUN\n","связи NOUN\n","Семен PROPN\n","Еремеевич PROPN\n","был AUX\n","человек NOUN\n","простой ADJ\n",", PUNCT\n","приходил VERB\n","на ADP\n","работу NOUN\n","всегда ADV\n","вовремя ADV\n",", PUNCT\n","здоровался VERB\n","с ADP\n","секретаршей NOUN\n","за ADP\n","руку NOUN\n","и CCONJ\n","иногда ADV\n","даже PART\n","писал VERB\n","в ADP\n","стенгазету NOUN\n","заметки NOUN\n","под ADP\n","псевдонимом NOUN\n","\" PUNCT\n","Муха NOUN\n","\" PUNCT\n",". PUNCT\n","\n"]}],"source":["for sent in full_train[:2]:\n","    for token in sent:\n","        print(token.form, token.upos)\n","    print()"]},{"cell_type":"markdown","metadata":{"id":"yM67sqAWD8dL"},"source":["Посчитаем пару статистик по нашему корпусу. В первую очередь нас интересует наибольшая длина предложения и наибольшая длина токена. Выведем несколько первых предложений. Решать задачу определения части речи мы будем с помощью свёрточных нейросетей, причём будем использовать нейросети, которые принимают на вход номера отдельных символов — то есть они работают не на уровне целых токенов а на уровне символов. Это вполне оправдано, потому что часть речи во многом определяется структурой слова, наличием суффиксов, окончаний определённого вида. Если бы мы работали на уровне отдельных токенов, то мы бы просто не могли анализировать структуру слов, нам бы приходилось просто запоминать, что такое-то слово — это существительное, другое слово это просто глагол. Следующий этап обработки корпуса — это построение словаря символов."]},{"cell_type":"code","execution_count":4,"metadata":{"ExecuteTime":{"end_time":"2019-10-29T19:49:56.916262Z","start_time":"2019-10-29T19:49:56.549806Z"},"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":734,"status":"ok","timestamp":1640341680040,"user":{"displayName":"Дмитрий Крапухин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggc2v_CQHmxf2sl_IRluFRrUm2MTBhbfr-oOZ_PGnk=s64","userId":"11342788103765688294"},"user_tz":-180},"id":"uqftzkxuaZtT","outputId":"fb605a4c-4a8e-4494-e349-6026f1639f7f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Наибольшая длина предложения 205\n","Наибольшая длина токена 47\n"]}],"source":["MAX_SENT_LEN = max(len(sent) for sent in full_train)\n","MAX_ORIG_TOKEN_LEN = max(len(token.form) for sent in full_train for token in sent)\n","print('Наибольшая длина предложения', MAX_SENT_LEN)\n","print('Наибольшая длина токена', MAX_ORIG_TOKEN_LEN)"]},{"cell_type":"code","execution_count":5,"metadata":{"ExecuteTime":{"end_time":"2019-10-29T19:49:57.251433Z","start_time":"2019-10-29T19:49:56.919818Z"},"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":551,"status":"ok","timestamp":1640341680585,"user":{"displayName":"Дмитрий Крапухин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggc2v_CQHmxf2sl_IRluFRrUm2MTBhbfr-oOZ_PGnk=s64","userId":"11342788103765688294"},"user_tz":-180},"id":"OyxYsDElaZtT","outputId":"18522144-de74-454a-ad5d-e67acfe4d8c0"},"outputs":[{"name":"stdout","output_type":"stream","text":["Анкета .\n","Начальник областного управления связи Семен Еремеевич был человек простой , приходил на работу всегда вовремя , здоровался с секретаршей за руку и иногда даже писал в стенгазету заметки под псевдонимом \" Муха \" .\n","В приемной его с утра ожидали посетители , - кое-кто с важными делами , а кое-кто и с такими , которые легко можно было решить в нижестоящих инстанциях , не затрудняя Семена Еремеевича .\n","Однако стиль работы Семена Еремеевича заключался в том , чтобы принимать всех желающих и лично вникать в дело .\n","Приемная была обставлена просто , но по-деловому .\n","У двери стоял стол секретарши , на столе - пишущая машинка с широкой кареткой .\n","В углу висел репродуктор и играло радио для развлечения ожидающих и еще для того , чтобы заглушать голос начальника , доносившийся из кабинета , так как , бесспорно , среди посетителей могли находиться и случайные люди .\n","Кабинет отличался скромностью , присущей Семену Еремеевичу .\n","В глубине стоял широкий письменный стол с бронзовыми чернильницами и перед ним два кожаных кресла .\n","Справа был стол для заседаний - длинный , накрытый зеленым сукном и с обеих сторон аккуратно заставленный стульями .\n"]}],"source":["all_train_texts = [' '.join(token.form for token in sent) for sent in full_train]\n","print('\\n'.join(all_train_texts[:10]))"]},{"cell_type":"markdown","metadata":{"id":"tt6niWiDFNXM"},"source":["Словарь символов — это стандартный \"dict\", который отображает подстроку, содержащую единственный элемент (это сам символ) в номер этого символа. Можем каждый токен представить как список чисел. Также нам опять пригодится фиктивный символ, который будет означать отсутствие символа. Он будет использоваться для того, чтобы уравнять длины всех токенов и всех предложений. Как мы видим, всего у нас в корпусе 150 уникальных символов. Самый частотный символ — это пробел, затем идут гласные. Аналогичную процедуру проделаем и с метками частей речи. Для того, чтобы составить обучающую выборку, нам нужно преобразовать строковые метки частей речи в их номера. Как мы видим, всего в корпусе 17 частей речи и мы добавляем сюда фиктивную \"часть речи\" — опять же, для того, чтобы выравнивать длины предложений. Что же значат эти метки частей речи? \"VERB\" — это глагол, \"PROPN\" — это имя собственное, \"NUM\" — это числительное, \"NOUN\" — это существительное. Ну, и наконец, мы перекладываем весь исходный корпус в специальные структуры, для того, чтобы подавать их в наш цикл для обучения. То есть мы перекладываем их в pytorch Dataset. Мы используем стандартный TensorDataset, он принимает на вход список тензоров, то есть, для того чтобы использовать этот Dataset, нам нужно подготовить эти тензоры. Первый — это тензор идентификаторов символов, а второй — это идентификаторы меток частей речи. Рассмотрим поподробнее, как именно мы составляем эти тензоры. Функция, которая нас интересует — на вход получает список токенизированных предложений. На самом деле, это не просто список токенизированных предложений, а это результаты разбора исходного корпуса в формате CoNLL, то есть в нём токены имеют дополнительную информацию, а именно — информацию о частях речи. То есть эта функция предназначена для преобразования обучающей и тестовой выборки в 2 тензора тензора — тензор входных идентификаторов символов и тензор выходных идентификаторов тэгов. Кроме списка исходных предложений нам нужно отображение из символов в номера символов, а также отображение из меток в номера; нам нужна оценка максимальной длины предложения и максимальной длины токена в символах. Создаём заготовки для тензоров — сначала мы эти тензоры инициализируем нулями. Тензор номеров символов имеет следующую размерность: \\[количество предложений (всего в обучающей выборке) на количество токенов в предложений на максимальную длину токена]. Но, кроме этого, мы добавляем ещё 2 дополнительных колоночки к каждому токену. Эти колоночки дополнительные мы будем заполнять нулями — они нам нужны для того, чтобы указать нейросети, что определённая N-грамма символов встречается именно в начале токена или именно в конце токена, но не в середине. То есть это нужно для того, чтобы нейросеть умела отличать начало слова и конец слова от середины слова."]},{"cell_type":"code","execution_count":6,"metadata":{"ExecuteTime":{"end_time":"2019-10-29T19:49:58.124148Z","start_time":"2019-10-29T19:49:57.254191Z"},"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1400,"status":"ok","timestamp":1640341681980,"user":{"displayName":"Дмитрий Крапухин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggc2v_CQHmxf2sl_IRluFRrUm2MTBhbfr-oOZ_PGnk=s64","userId":"11342788103765688294"},"user_tz":-180},"id":"CS6Fa9IeaZtT","outputId":"9bbfb64f-4a96-43d3-e296-dcd644aff973"},"outputs":[{"name":"stdout","output_type":"stream","text":["Количество уникальных символов 150\n","[('<PAD>', 0), (' ', 1), ('о', 2), ('е', 3), ('а', 4), ('т', 5), ('и', 6), ('н', 7), ('.', 8), ('с', 9)]\n"]}],"source":["# каждый токен можем представить как список чисел\n","train_char_tokenized = tokenize_corpus(all_train_texts, tokenizer=character_tokenize)\n","char_vocab, word_doc_freq = build_vocabulary(train_char_tokenized, max_doc_freq=1.0, min_count=5, pad_word='<PAD>')\n","print(\"Количество уникальных символов\", len(char_vocab))\n","print(list(char_vocab.items())[:10])"]},{"cell_type":"code","execution_count":7,"metadata":{"ExecuteTime":{"end_time":"2019-10-29T19:49:58.524125Z","start_time":"2019-10-29T19:49:58.125577Z"},"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1640341681982,"user":{"displayName":"Дмитрий Крапухин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggc2v_CQHmxf2sl_IRluFRrUm2MTBhbfr-oOZ_PGnk=s64","userId":"11342788103765688294"},"user_tz":-180},"id":"ARLJHL3UaZtT","outputId":"d04f4bdf-1402-44ad-b2a0-ad35bcc4f5a0"},"outputs":[{"data":{"text/plain":["{'<NOTAG>': 0,\n"," 'ADJ': 1,\n"," 'ADP': 2,\n"," 'ADV': 3,\n"," 'AUX': 4,\n"," 'CCONJ': 5,\n"," 'DET': 6,\n"," 'INTJ': 7,\n"," 'NOUN': 8,\n"," 'NUM': 9,\n"," 'PART': 10,\n"," 'PRON': 11,\n"," 'PROPN': 12,\n"," 'PUNCT': 13,\n"," 'SCONJ': 14,\n"," 'SYM': 15,\n"," 'VERB': 16,\n"," 'X': 17}"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["# Аналогично посчитаем для частей речи\n","UNIQUE_TAGS = ['<NOTAG>'] + sorted({token.upos for sent in full_train for token in sent if token.upos})\n","label2id = {label: i for i, label in enumerate(UNIQUE_TAGS)}\n","label2id"]},{"cell_type":"markdown","metadata":{"id":"C_xE8_U9FdS_"},"source":["Процедура заполнения тензоров достаточно простая — итерируемся по всем предложениям, по всем токенам в предложении, и для каждого токена кладём в соответствующую ячейку тензора меток идентификатор метки, а также кладём в соответствующую ячейку входного тензора идентификатор очередного символа. Теперь посмотрим, как данные будут выглядеть для нейросети во время обучения. Для этого выведем фрагмент тензора, представляющего второе предложение из обучающей выборки — первые пять слов этого предложения. Мы видим прямоугольный тензор, каждая строчка этого тензора представляет один токен и содержит номера символов, которые в этом токене используются, в том порядке, в котором они встречались в самом токене. Обратить внимание здесь нужно на две вещи — первая: это стартовый нолик, он нам нужен для того, чтобы указать нейросети, что это — начало токена. Всё, что после последнего символа — заполняется нулями. Количество значимых элементов в каждой такой строчке у нас отличается. У нас есть короткие и длинные токены. Так выглядит входной тензор. Давайте теперь посмотрим, как выглядит тензор меток. Целевой тензор для этого же предложения — мы выбрали второе предложение из обучающей выборки, и это уже не двухмерный тензор, это одномерный тензор, то есть это просто список чисел, каждое число представляет номер тэга соответствующего токена. Для первого токена из этого предложения мы должны будем предсказать класс номер \"8\", для 2 — класс номер \"1\". Для токенов фиктивных, ненастоящих, мы всегда должны будем предсказывать \"0\". Фиктивные токены у нас не являются частью исходного предложения, они используют для того, чтобы выровнять длины всех предложений и иметь возможность упаковывать предложения разной длины в прямоугольный тензор и обрабатывать в пакетном режиме в нейросети. Это нужно для того, чтобы эффективно использовать возможности современных вычислителей — видеокарт. Определим вспомогательный нейросетевой модуль. Он состоит из свёрток, функции активации и дропаута. Посмотрим на функцию \"forward\". В основе модуля лежит набор одинаковых блоков. Попробуем изобразить этот модуль графически. У нас в начале есть \"x\", он подаётся в некий блок \"layer 1\", затем выход \"layer 1\" приплюсовывается к его же входу. Это всё подаётся в следующий — такой же блок \"layer 2\" и снова приплюсовывается. Это простенький ResNet. Использование вот этих связей (skip connection) ускоряет сходимость, а также позволяет нам сделать нейросеть более глубокой. Другими словами, без \"skip connection\" мы можем сделать нейросеть максимум из 5...9 блоков глубиной, но, используя \"skip connection\", мы можем делать нейросеть произвольной глубины, она по-прежнему будет обучаться. Давайте теперь посмотрим, как же устроен каждый из вот этих блоков. Каждый из этих блоков реализуется с помощью модуля pytorch \"sequential\" — это базовый модуль, который берёт список других модулей и выполняет их по-очереди, передавая результат первого во второй, из второго в третий, и так далее. В этом блоке первый слой — это свёрточный слой. Это одномерные свёртки — для текстов чаще всего используются одномерные свёртки. По умолчанию, мы говорим, что размер ядра равен 3. При этом, свёрточный слой не меняет количества каналов — он принимает одно и то же число каналов и возвращает одно и то же число каналов. Кроме того, здесь мы используем padding. Мы делаем, чтобы размерность тензора вообще никак не менялась, то есть по умолчанию при нулевом padding свёртки немного сжимают тензор по пространственному измерению. Здесь, чтобы размерность тензора оставалась прежней. Для этого, перед тем, как применять свёртки, нужно добавить какое-то количество нулей в начало и в конец тензора. Реализацию свёрточного модуля мы рассмотрим попозже. Второй слой в нашем блоке — это dropout. Он нужен для того, чтобы нейросеть меньше переобучалась. В режиме обучения dropout зануляет случайные ячейки тензора. Когда нейросеть обучена, dropout ничего не делает. Третий слой блока — это функция активации. Здесь мы используем Leaky ReLU, часто это — неплохой выбор. Таким образом, мы определили достаточно универсальный свёрточный модуль, который можно использовать в абсолютно разных ситуациях и, в рамках этого семинара, мы будем использовать его, как минимум, в двух разных случаях. !"]},{"cell_type":"code","execution_count":8,"metadata":{"ExecuteTime":{"end_time":"2019-10-29T19:49:58.752672Z","start_time":"2019-10-29T19:49:58.526431Z"},"executionInfo":{"elapsed":39827,"status":"ok","timestamp":1640341721801,"user":{"displayName":"Дмитрий Крапухин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggc2v_CQHmxf2sl_IRluFRrUm2MTBhbfr-oOZ_PGnk=s64","userId":"11342788103765688294"},"user_tz":-180},"id":"Ohcm8s6OaZtT"},"outputs":[],"source":["# перекладываем их в pytorch Dataset. Мы используем стандартный TensorDataset, он \n","# принимает на вход список тензоров, то есть, для того чтобы использовать этот \n","# Dataset, нам нужно подготовить эти тензоры. \n","\n","train_inputs, train_labels = pos_corpus_to_tensor(full_train, char_vocab, label2id, MAX_SENT_LEN, MAX_ORIG_TOKEN_LEN)\n","train_dataset = TensorDataset(train_inputs, train_labels)\n","\n","test_inputs, test_labels = pos_corpus_to_tensor(full_test, char_vocab, label2id, MAX_SENT_LEN, MAX_ORIG_TOKEN_LEN)\n","test_dataset = TensorDataset(test_inputs, test_labels)\n","# из исходников\n","# def pos_corpus_to_tensor(sentences, char2id, label2id, max_sent_len, max_token_len):\n","#     inputs = torch.zeros((len(sentences), max_sent_len, max_token_len + 2), dtype=torch.long)\n","#     targets = torch.zeros((len(sentences), max_sent_len), dtype=torch.long)\n","\n","#     for sent_i, sent in enumerate(sentences): Итерируемся по предложениям\n","#         for token_i, token in enumerate(sent): итерируемся по токенам\n","#             targets[sent_i, token_i] = label2id.get(token.upos, 0) кладем в нужное место токен\n","#             for char_i, char in enumerate(token.form):\n","#                 inputs[sent_i, token_i, char_i + 1] = char2id.get(char, 0) идентификатор очередного символа\n","\n","#     return inputs, targets"]},{"cell_type":"markdown","metadata":{"id":"dTj7LJ6Tbs-P"},"source":["pos_corpus_to_tensor на вход получает список токенизированных предложений. На самом деле, это не просто список токенизированных предложений, а это результаты разбора исходного корпуса в формате CoNLL, то есть в нём токены имеют дополнительную информацию, а именно — информацию о частях речи. То есть эта функция предназначена для преобразования обучающей и тестовой выборки в 2 тензора тензора — тензор входных идентификаторов символов и тензор выходных идентификаторов тэгов. Кроме списка исходных предложений нам нужно отображение из символов в номера символов, а также отображение из меток в номера; нам нужна оценка максимальной длины предложения и максимальной длины токена в символах. Создаём заготовки для тензоров — сначала мы эти тензоры инициализируем нулями. Тензор номеров символов имеет следующую размерность: [количество предложений (всего в обучающей выборке) на количество токенов в предложений на максимальную длину токена]. Но, кроме этого, мы добавляем ещё 2 дополнительных колоночки к каждому токену. Эти колоночки дополнительные мы будем заполнять нулями — они нам нужны для того, чтобы указать нейросети, что определённая N-грамма символов встречается именно в начале токена или именно в конце токена, но не в середине. То есть это нужно для того, чтобы нейросеть умела отличать начало слова и конец слова от середины слова."]},{"cell_type":"code","execution_count":9,"metadata":{"ExecuteTime":{"end_time":"2019-10-29T19:49:58.754883Z","start_time":"2019-10-29T19:49:40.582Z"},"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19,"status":"ok","timestamp":1640341721801,"user":{"displayName":"Дмитрий Крапухин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggc2v_CQHmxf2sl_IRluFRrUm2MTBhbfr-oOZ_PGnk=s64","userId":"11342788103765688294"},"user_tz":-180},"id":"hWafZLpIaZtU","outputId":"0af75b83-442b-4486-9e04-58ca94bb7e7a","scrolled":true},"outputs":[{"data":{"text/plain":["tensor([[ 0, 39,  4, 25,  4, 11, 20,  7,  6, 13,  0,  0,  0,  0,  0,  0,  0,  0,\n","          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n","        [ 0,  2, 23, 11,  4,  9,  5,  7,  2, 22,  2,  0,  0,  0,  0,  0,  0,  0,\n","          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n","        [ 0, 17, 16, 10,  4, 12, 11,  3,  7,  6, 19,  0,  0,  0,  0,  0,  0,  0,\n","          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n","        [ 0,  9, 12, 19, 21,  6,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n","        [ 0, 40,  3, 15,  3,  7,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]])"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["train_inputs[1][:5] # первые 5 слов второго предложения\n","# получаем номера символов которые в этом токене используются\n","# стартовый нолик, он нам нужен для того, чтобы указать нейросети, что это — \n","# начало токена. Всё, что после последнего символа — заполняется нулями. \n","# Количество значимых элементов в каждой такой строчке у нас отличается. \n","# У нас есть короткие и длинные токены"]},{"cell_type":"code","execution_count":10,"metadata":{"ExecuteTime":{"end_time":"2019-10-29T19:49:58.756496Z","start_time":"2019-10-29T19:49:40.711Z"},"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1640341721802,"user":{"displayName":"Дмитрий Крапухин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggc2v_CQHmxf2sl_IRluFRrUm2MTBhbfr-oOZ_PGnk=s64","userId":"11342788103765688294"},"user_tz":-180},"id":"fJbSC-mMaZtU","outputId":"e30fd18d-2648-42a0-e764-dcb096b88bff"},"outputs":[{"data":{"text/plain":["tensor([ 8,  1,  8,  8, 12, 12,  4,  8,  1, 13, 16,  2,  8,  3,  3, 13, 16,  2,\n","         8,  2,  8,  5,  3, 10, 16,  2,  8,  8,  2,  8, 13,  8, 13, 13,  0,  0,\n","         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","         0,  0,  0,  0,  0,  0,  0])"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["train_labels[1]\n","# Целевой тензор для этого же предложения — мы выбрали второе предложение из \n","# обучающей выборки, и это уже не двухмерный тензор, это одномерный тензор, то \n","# есть это просто список чисел, каждое число представляет номер тэга \n","# соответствующего токена. Для первого токена из этого предложения мы должны будем\n","# предсказать класс номер \"8\", для 2 — класс номер \"1\". Для токенов фиктивных, \n","# ненастоящих, мы всегда должны будем предсказывать \"0\". Напомню, что фиктивные \n","# токены у нас не являются частью исходного предложения, они используют для того,\n","# чтобы выровнять длины всех предложений и иметь возможность упаковывать \n","# предложения разной длины в прямоугольный тензор и обрабатывать в пакетном \n","# режиме в нейросети. Это нужно для того, чтобы эффективно использовать \n","# возможности современных вычислителей — видеокарт."]},{"cell_type":"markdown","metadata":{"id":"g1VV3XhxaZtU"},"source":["## Вспомогательная свёрточная архитектура"]},{"cell_type":"code","execution_count":11,"metadata":{"ExecuteTime":{"end_time":"2019-10-29T19:47:48.316516Z","start_time":"2019-10-29T19:46:17.539Z"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1640341721802,"user":{"displayName":"Дмитрий Крапухин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggc2v_CQHmxf2sl_IRluFRrUm2MTBhbfr-oOZ_PGnk=s64","userId":"11342788103765688294"},"user_tz":-180},"id":"1oBU2QmVaZtU"},"outputs":[],"source":["class StackedConv1d(nn.Module):\n","    def __init__(self, features_num, layers_n=1, kernel_size=3, conv_layer=nn.Conv1d, dropout=0.0):\n","        super().__init__()\n","        layers = []\n","        for _ in range(layers_n):\n","            layers.append(nn.Sequential(\n","                # Одномерная свертка. Ядро равно 3. Паддинг чтобы размерность не менялась\n","                conv_layer(features_num, features_num, kernel_size, padding=kernel_size//2),\n","                nn.Dropout(dropout), # для меньшего переобучения \n","                nn.LeakyReLU())) # активация\n","        self.layers = nn.ModuleList(layers)\n","    \n","    def forward(self, x):\n","        \"\"\"x - BatchSize x FeaturesNum x SequenceLen\"\"\"\n","        for layer in self.layers: # каждый layer это sequential\n","            x = x + layer(x) # выход с layer1 суммируется с исходным сигналом и подается в layer2\n","            # это простой resnet\n","        return x"]},{"cell_type":"markdown","metadata":{"id":"-Z73j9NeFnCT"},"source":["Первая попытка решить нашу задачу. Для этого нам необходимо описать нейросетевой модуль для pytorch. Он будет предсказывать метки частей речи токенов, используя информацию, содержащуюся только в самих токенах. Другими словами, эта модель никак не будет использовать контекст, в котором слово употребляется. Опять же, давайте начнём с метода \"forward\". Для начала, получим переменные, представляющие форму исходного тензора. На вход нам приходит трёхмерный тензор, размерности которого соответствуют \\[размеру батча, наибольшей длине предложения в токенах и наибольшей длине каждого токена в символах]. Далее мы схлопываем первое и второе измерения, чтобы получить двухмерный тензор. Другими словами, мы забываем о том, что токены у нас были как-то объединены в предложения (для этой модели нам совершенно неважно). Далее мы используем embedding-слой для того, чтобы для каждого символа получить вектора. Таким образом, мы снова получаем трёхмерный тензор, который соответствует \\[количеству токенов в батче на длину каждого токена на размер вектора для символа]. Затем мы транспонируем этот тензор для того, чтобы мы могли его подать в свёрточную нейросеть. В pytotch принята следующая конвенция о порядке размерностей: сначала идёт размер батча, затем идёт количество признаков для каждого элемента (в данном случае — это размер вектора), а затем идёт какое-то количество размерностей, соответствующих самим элементам, то есть дальше идут пространственные измерения. В текстах мы работаем с одномерными данными, то есть у нас, в данном случае это длина токена. После всех этих операций, переменная \"char embeddings\" содержит векторы для отдельных символов. Пока что, эти векторы не содержат информации о том, в каком контексте используется каждый символ — это просто какие-то априорные знания о том, что это вообще за символ. Вначале обучения эти вектора инициализируется случайными числами. Затем эти вектора мы передаём в свёрточный модуль, для того, чтобы учесть локальный контекст — то есть ту ситуацию, в которой каждый конкретный символ используется. Для этого мы применяем \"backbone\"-сетку, роль которой выполняет простенький ResNet, который мы определили чуть выше. В результате мы получаем трёхмерный тензор такой же размерности кладём его в переменную features, и эта переменная содержит векторы символов уже с учётом к их контекста. Тут нужно вспомнить, что тэги нам нужно предсказывать не для каждого символа, а для каждого токена. Поэтому нам нужно как-то агрегировать признаки символов в токене, чтобы получить вектор токена. Для этого мы используем pooling — в данном случае это max pooling. Допустим, у нас есть некоторая матричка, строки в этой матричке представляют отдельные символы в токене, а столбцы — это признаки этих символов. И max pooling делает из этого один вектор — количество элементов в этом векторе соответствует количеству столбцов в исходной матрице, и каждый элемент получен взятием функции максимума из соответствующего столбца. В результате применения global пулинга мы получаем тензор, на этот раз — уже двумерный, каждая строчка этого тензора представляет отдельный токен. Ну и наконец, по каждому токену нам нужно принять решение касательно его метки. Для этого признаки токенов мы передаём в ещё один нейросетевой модуль, который называется out — это просто полносвязный блок. В результате применения этого блока мы получаем также двухмерный тензор, но у него уже размер строки не \"embedding size\", a \"количество меток частей речи\". Далее мы меняем форму этого тензора, преобразуем его в трёхмерный, то есть \"вспоминаем\" о том, что у нас есть предложения, и транспонируем для того, чтобы порядок измерений соответствовал порядку измерений в исходном тензоре \"tokens\". В чём же физический смысл того, что мы только что рассмотрели? Физический смысл того, что мы сейчас описали, заключается в том, чтобы рассмотреть все возможные N-граммы символов, которые встречаются в каждом токене, и по ним попробовать определить часть речи. Благодаря тому, что основная наша нейросеть (backbone) содержит \"skip connections\", N-граммы, которые учитываются этой нейросетью, по сути, имеют различную длину. Например, если мы используем размер ядра свёртки, равный 3, то первый блок учитывает трёхграммы, второй блок уже учитывает пятиграммы, а третий — семиграммы, соответственно. При этом, благодаря тому, что есть \"skip connection\", информация о трёхграммах не теряется, она пробрасывать до самого конца.\n"]},{"cell_type":"markdown","metadata":{"id":"4PrbLk21aZtU"},"source":["## Предсказание частей речи на уровне отдельных токенов"]},{"cell_type":"code","execution_count":12,"metadata":{"ExecuteTime":{"end_time":"2019-10-29T19:47:48.317452Z","start_time":"2019-10-29T19:46:23.135Z"},"executionInfo":{"elapsed":245,"status":"ok","timestamp":1640341722041,"user":{"displayName":"Дмитрий Крапухин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggc2v_CQHmxf2sl_IRluFRrUm2MTBhbfr-oOZ_PGnk=s64","userId":"11342788103765688294"},"user_tz":-180},"id":"JvEP1f8MaZtU"},"outputs":[],"source":["class SingleTokenPOSTagger(nn.Module):\n","    def __init__(self, vocab_size, labels_num, embedding_size=32, **kwargs):\n","        super().__init__()\n","        self.char_embeddings = nn.Embedding(vocab_size, embedding_size, padding_idx=0)\n","        self.backbone = StackedConv1d(embedding_size, **kwargs)\n","        self.global_pooling = nn.AdaptiveMaxPool1d(1)\n","        self.out = nn.Linear(embedding_size, labels_num)\n","        self.labels_num = labels_num\n","    \n","    def forward(self, tokens):\n","        \"\"\"tokens - BatchSize x MaxSentenceLen x MaxTokenLen\"\"\"\n","        batch_size, max_sent_len, max_token_len = tokens.shape # формы тензоров\n","        tokens_flat = tokens.view(batch_size * max_sent_len, max_token_len) # схлопываем тензоры\n","        \n","        char_embeddings = self.char_embeddings(tokens_flat)  # BatchSize*MaxSentenceLen x MaxTokenLen x EmbSize\n","        char_embeddings = char_embeddings.permute(0, 2, 1)  # BatchSize*MaxSentenceLen x EmbSize x MaxTokenLen\n","        \n","        # После всех этих операций, переменная \"char embeddings\" содержит \n","        # векторы для отдельных символов. Пока что, эти векторы не содержат \n","        # информации о том, в каком контексте используется каждый символ — это \n","        # просто какие-то априорные знания о том, что это вообще за символ. \n","        # Вначале обучения эти вектора инициализируется случайными числами. \n","        # Затем эти вектора мы передаём в свёрточный модуль, для того, чтобы \n","        # учесть локальный контекст — то есть ту ситуацию, в которой каждый \n","        # конкретный символ используется. Для этого мы применяем \"backbone\"-сетку,\n","        #  роль которой выполняет простенький ResNet, который мы определили выше.\n","        features = self.backbone(char_embeddings) # В результате мы получаем трёхмерный тензор такой же размерности \n","        \n","        global_features = self.global_pooling(features).squeeze(-1)  # BatchSize*MaxSentenceLen x EmbSize\n","        \n","        logits_flat = self.out(global_features)  # BatchSize*MaxSentenceLen x LabelsNum\n","        logits = logits_flat.view(batch_size, max_sent_len, self.labels_num)  # BatchSize x MaxSentenceLen x LabelsNum\n","        logits = logits.permute(0, 2, 1)  # BatchSize x LabelsNum x MaxSentenceLen\n","        return logits"]},{"cell_type":"markdown","metadata":{"id":"4HDLWvbH1SdW"},"source":["Физический смысл того, что мы сейчас описали, заключается в том, чтобы рассмотреть все возможные N-граммы символов, которые встречаются в каждом токене, и по ним попробовать определить часть речи. Благодаря тому, что основная наша нейросеть (backbone) содержит \"skip connections\", N-граммы, которые учитываются этой нейросетью, по сути, имеют различную длину. Например, если мы используем размер ядра свёртки, равный 3, то первый блок учитывает трёхграммы, второй блок уже учитывает пятиграммы, а третий — семиграммы, соответственно. При этом, благодаря тому, что есть \"skip connection\", информация о трёхграммах не теряется, она пробрасывать до самого конца."]},{"cell_type":"markdown","metadata":{"id":"EhArgZna1sN4"},"source":["Попробуем обучить эту нейросеть и посмотрим, как хорошо мы можем определять часть речи слова, не используя информацию о его контексте. Сначала мы создаём экземпляр описанного нами нейросетевого модуля, передаём ему в конструктор количество уникальных символов в датасете, количество меток, рабочий размер модели, то есть каждый символ мы будем представлять вектором из 64 элементов, дальше мы указываем количество свёрточных блоков, то есть глубину нашей нейросети (мы будем использовать глубину равную трём), размер ядра свёртки, а также вероятность дропаута. Вероятность равная 0.3 означает, что на каждом проходе по нейросети в режиме обучения будет, случайным образом, зануляться примерно треть активации.  "]},{"cell_type":"code","execution_count":13,"metadata":{"ExecuteTime":{"end_time":"2019-10-29T19:47:48.318497Z","start_time":"2019-10-29T19:46:23.764Z"},"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1640341722994,"user":{"displayName":"Дмитрий Крапухин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggc2v_CQHmxf2sl_IRluFRrUm2MTBhbfr-oOZ_PGnk=s64","userId":"11342788103765688294"},"user_tz":-180},"id":"ZcRWXGalaZtV","outputId":"0fc4f092-a070-4a94-893c-7aef41e50cf3"},"outputs":[{"name":"stdout","output_type":"stream","text":["Количество параметров 47826\n"]}],"source":["single_token_model = SingleTokenPOSTagger(len(char_vocab), len(label2id), embedding_size=64, layers_n=3, kernel_size=3, dropout=0.3)\n","print('Количество параметров', sum(np.product(t.shape) for t in single_token_model.parameters()))"]},{"cell_type":"markdown","metadata":{"id":"lZowTU8318ka"},"source":["Далее мы используем нашу стандартную функцию для тренировки нейросетей, которая описана в нашей библиотеке специально для этого курса, передаём туда модель, датасеты, а также указываем функцию потерь — мы будем использовать кросс-энтропию, эта функция потерь используется в многоклассовых задачах. Полное обучение описанной нейросети до сходимости на этом корпусе требует примерно одного часа работы видеокарты. Мы не будем ждать всё это время — мы просто загрузим модельку, которую я обучил заранее и оценим её качество. ."]},{"cell_type":"code","execution_count":14,"metadata":{"ExecuteTime":{"end_time":"2019-10-29T19:47:48.319470Z","start_time":"2019-10-29T19:46:25.552Z"},"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4471984,"status":"ok","timestamp":1640346194974,"user":{"displayName":"Дмитрий Крапухин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggc2v_CQHmxf2sl_IRluFRrUm2MTBhbfr-oOZ_PGnk=s64","userId":"11342788103765688294"},"user_tz":-180},"id":"LwMetqjcaZtV","outputId":"a5bfb1a2-dc2d-4c62-8f2f-50f27f501037","scrolled":false},"outputs":[{"name":"stdout","output_type":"stream","text":["Эпоха 0\n","Эпоха: 501 итераций, 45.69 сек\n","Среднее значение функции потерь на обучении 0.07997052162558495\n","Среднее значение функции потерь на валидации 0.03771348909871413\n","Новая лучшая модель!\n","\n","Эпоха 1\n","Эпоха: 501 итераций, 44.95 сек\n","Среднее значение функции потерь на обучении 0.02819045022605898\n","Среднее значение функции потерь на валидации 0.02991329000727965\n","Новая лучшая модель!\n","\n","Эпоха 2\n","Эпоха: 501 итераций, 44.95 сек\n","Среднее значение функции потерь на обучении 0.024262320893461593\n","Среднее значение функции потерь на валидации 0.02679025984857932\n","Новая лучшая модель!\n","\n","Эпоха 3\n","Эпоха: 501 итераций, 44.93 сек\n","Среднее значение функции потерь на обучении 0.022401973770600474\n","Среднее значение функции потерь на валидации 0.0258692220351336\n","Новая лучшая модель!\n","\n","Эпоха 4\n","Эпоха: 501 итераций, 44.95 сек\n","Среднее значение функции потерь на обучении 0.021007792802969973\n","Среднее значение функции потерь на валидации 0.02294884014432088\n","Новая лучшая модель!\n","\n","Эпоха 5\n","Эпоха: 501 итераций, 44.94 сек\n","Среднее значение функции потерь на обучении 0.02014860604330154\n","Среднее значение функции потерь на валидации 0.023813558594867733\n","\n","Эпоха 6\n","Эпоха: 501 итераций, 44.94 сек\n","Среднее значение функции потерь на обучении 0.019755042936957762\n","Среднее значение функции потерь на валидации 0.02349609560748138\n","\n","Эпоха 7\n","Эпоха: 501 итераций, 44.94 сек\n","Среднее значение функции потерь на обучении 0.01924896806463629\n","Среднее значение функции потерь на валидации 0.021251871149138648\n","Новая лучшая модель!\n","\n","Эпоха 8\n","Эпоха: 501 итераций, 44.94 сек\n","Среднее значение функции потерь на обучении 0.018729905361781814\n","Среднее значение функции потерь на валидации 0.02028857704510193\n","Новая лучшая модель!\n","\n","Эпоха 9\n","Эпоха: 501 итераций, 44.95 сек\n","Среднее значение функции потерь на обучении 0.018332841155489166\n","Среднее значение функции потерь на валидации 0.020125487459694395\n","Новая лучшая модель!\n","\n"]}],"source":["(best_val_loss,\n"," best_single_token_model) = train_eval_loop(single_token_model,\n","                                            train_dataset,\n","                                            test_dataset,\n","                                            F.cross_entropy,\n","                                            lr=5e-3,\n","                                            epoch_n=10,\n","                                            batch_size=64,\n","                                            device='cuda',\n","                                            early_stopping_patience=5,\n","                                            max_batches_per_epoch_train=500,\n","                                            max_batches_per_epoch_val=100,\n","                                            lr_scheduler_ctor=lambda optim: torch.optim.lr_scheduler.ReduceLROnPlateau(optim, patience=2,\n","                                                                                                                       factor=0.5,\n","                                                                                                                       verbose=True))"]},{"cell_type":"code","execution_count":15,"metadata":{"ExecuteTime":{"end_time":"2019-10-29T19:47:48.320568Z","start_time":"2019-10-29T19:46:47.579Z"},"executionInfo":{"elapsed":255,"status":"ok","timestamp":1640346195219,"user":{"displayName":"Дмитрий Крапухин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggc2v_CQHmxf2sl_IRluFRrUm2MTBhbfr-oOZ_PGnk=s64","userId":"11342788103765688294"},"user_tz":-180},"id":"TCCKLfi4aZtV"},"outputs":[],"source":["# Если Вы запускаете ноутбук на colab или kaggle, добавьте в начало пути ./stepik-dl-nlp\n","torch.save(best_single_token_model.state_dict(), './models/3.7.single_token_pos.pth')"]},{"cell_type":"code","execution_count":16,"metadata":{"ExecuteTime":{"end_time":"2019-10-29T19:47:48.321566Z","start_time":"2019-10-29T19:46:47.731Z"},"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1640346195220,"user":{"displayName":"Дмитрий Крапухин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggc2v_CQHmxf2sl_IRluFRrUm2MTBhbfr-oOZ_PGnk=s64","userId":"11342788103765688294"},"user_tz":-180},"id":"j33puGJEaZtV","outputId":"6ba677ff-f588-49c7-855a-a6303fb45213"},"outputs":[{"data":{"text/plain":["<All keys matched successfully>"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["# Если Вы запускаете ноутбук на colab или kaggle, добавьте в начало пути ./stepik-dl-nlp\n","single_token_model.load_state_dict(torch.load('./models/3.7.single_token_pos.pth'))"]},{"cell_type":"markdown","metadata":{"id":"aVd4PeHf2ffp"},"source":["Для того, чтобы оценить качество, мы используем обученную нейросеть, чтобы получить предсказание для обучающей выборки, а дальше используем функцию \"classification_report\" из библиотеки scikit-learn. Эта функция выдаёт самые стандартные метрики качества классификации (а именно, точность, полнота и f-мера) для каждого класса. А также, для каждого класса выдаётся количество примеров. Как мы видим, в этом случае датасет имеет сильно скошенное распределение классов, другими словами у нас есть очень частые классы и таких классов мало, а есть очень редкие классы. В таком случае нам вообще нет смысла использовать \"accuracy\", то есть долю верно угаданных ответов — она абсолютно неинформативна. На обучающей выборке она равна единице, хотя есть классы, которые не очень хорошо определяются. В случае сильно скошенного распределения классов, самое правильное — это считать сразу несколько метрик, устойчивых к распределению классов (в данном случае, это — точность, полнота и f-мера) и смотреть на них всех. Часто бывает удобно получить не большую пачку цифр, а всего лишь одно число, по которому мы сможем понять, насколько хорошо модель работает. В данном случае лучше всего нам подходит \"macro-среднее\". Что значит \"macro-среднее\"? Это значит, что сначала мы считаем каждую метрику по каждому классу, а потом усредняем. Macro-среднее более устойчиво к скошенным распределениям классов"]},{"cell_type":"code","execution_count":17,"metadata":{"ExecuteTime":{"end_time":"2019-10-29T19:47:48.324276Z","start_time":"2019-10-29T19:46:48.445Z"},"colab":{"base_uri":"https://localhost:8080/"},"id":"dbq4gGr_aZtV","outputId":"68477587-f02c-43a7-aaaa-a37b503a5e3a"},"outputs":[{"name":"stderr","output_type":"stream","text":["1526it [00:28, 54.04it/s]                               \n"]},{"name":"stdout","output_type":"stream","text":["Среднее значение функции потерь на обучении 0.018453510478138924\n","              precision    recall  f1-score   support\n","\n","     <NOTAG>       1.00      1.00      1.00   9136391\n","         ADJ       0.83      0.96      0.89     85589\n","         ADP       1.00      0.99      0.99     81963\n","         ADV       0.93      0.82      0.87     44101\n","         AUX       0.87      0.63      0.73      7535\n","       CCONJ       0.88      0.98      0.93     30432\n","         DET       0.90      0.75      0.82     21968\n","        INTJ       0.58      0.09      0.16        78\n","        NOUN       0.98      0.92      0.95    214497\n","         NUM       0.96      0.94      0.95     13746\n","        PART       0.96      0.78      0.86     26638\n","        PRON       0.86      0.89      0.87     38438\n","       PROPN       0.80      0.95      0.87     32401\n","       PUNCT       1.00      1.00      1.00    157989\n","       SCONJ       0.80      0.93      0.86     16219\n","         SYM       1.00      0.99      1.00       840\n","        VERB       0.93      0.94      0.93     97670\n","           X       0.99      0.43      0.60       375\n","\n","    accuracy                           0.99  10006870\n","   macro avg       0.90      0.83      0.85  10006870\n","weighted avg       0.99      0.99      0.99  10006870\n","\n","\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 206/205.75 [00:03<00:00, 55.13it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Среднее значение функции потерь на валидации 0.019972970709204674\n","              precision    recall  f1-score   support\n","\n","     <NOTAG>       1.00      1.00      1.00   1231232\n","         ADJ       0.82      0.95      0.88     11222\n","         ADP       0.99      0.99      0.99     10585\n","         ADV       0.92      0.80      0.86      6165\n","         AUX       0.87      0.56      0.68      1108\n","       CCONJ       0.89      0.98      0.93      4410\n","         DET       0.89      0.72      0.80      3085\n","        INTJ       0.00      0.00      0.00        11\n","        NOUN       0.97      0.92      0.95     27974\n","         NUM       0.95      0.92      0.93      1829\n","        PART       0.96      0.79      0.87      3875\n","        PRON       0.85      0.88      0.86      5598\n","       PROPN       0.79      0.94      0.86      4438\n","       PUNCT       1.00      1.00      1.00     22694\n","       SCONJ       0.78      0.94      0.85      2258\n","         SYM       1.00      0.96      0.98        53\n","        VERB       0.91      0.94      0.92     13078\n","           X       1.00      0.47      0.64       105\n","\n","    accuracy                           0.99   1349720\n","   macro avg       0.87      0.82      0.83   1349720\n","weighted avg       0.99      0.99      0.99   1349720\n","\n"]}],"source":["train_pred = predict_with_model(single_token_model, train_dataset)\n","train_loss = F.cross_entropy(torch.tensor(train_pred),\n","                             torch.tensor(train_labels))\n","print('Среднее значение функции потерь на обучении', float(train_loss))\n","print(classification_report(train_labels.view(-1), train_pred.argmax(1).reshape(-1), target_names=UNIQUE_TAGS))\n","print()\n","\n","test_pred = predict_with_model(single_token_model, test_dataset)\n","test_loss = F.cross_entropy(torch.tensor(test_pred),\n","                            torch.tensor(test_labels))\n","print('Среднее значение функции потерь на валидации', float(test_loss))\n","print(classification_report(test_labels.view(-1), test_pred.argmax(1).reshape(-1), target_names=UNIQUE_TAGS))"]},{"cell_type":"markdown","metadata":{"id":"Q5qq46wK3Nz_"},"source":["Мы видим, что, несмотря на то, что модель была очень простая и она никак не учитывала контексты, на обучающей выборке она показывает достаточно высокую f-меру (0.9). На валидационной выборке macro-средняя f-мера не сильно меньше, всего лишь на 1% (0.89 — достаточно неплохо).   \n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"bi0EbLlyaZtW"},"source":["## Предсказание частей речи на уровне предложений (с учётом контекста)"]},{"cell_type":"markdown","metadata":{"id":"hWl_LpeG3fi1"},"source":["Частиречная омонимия — это когда слова \"с разной частью речи\" пишутся абсолютно одинаково. Например, \"мама мыла раму\": здесь \"мыла\" — это глагол. Или \"в ванной не было мыла\": здесь \"мыла\" — это уже существительное. Такие случаи принципиально невозможно отлавливать, используя только информацию изнутри слова — нам нужно учитывать контекст в предложении. Давайте опишем вторую модельку, которая учитывает такой контекст. Опять же, давайте посмотрим на метод forward. Первая часть этого метода — ровно такая же, как и в предыдущей модели. Берём номера символов, делаем выборку из таблицы эмбеддингов, получаем векторы символов. Потом, с помощью свёрточной нейросети, которая в данном случае называется \"single token backbone\", получаем векторы символов с учётом их контекста. Затем используем глобальный пулинг для того, чтобы получить вектор токена. Далее мы проделываем примерно то же самое, но уже на уровне токенов в предложении. Сначала мы немного изменяем форму и транспонируем тензор признаков таким образом, чтобы получить трёхмерный тензор с размерностями \"количество предложений в батче\", \"количество признаков для каждого токена\" и \"количество токенов в предложении\". Этот тензор содержит признаки токенов без учёта их контекста. Далее мы эти признаки подаём в другой свёрточный модуль для того, чтобы учесть это самый контекст. Для учёта контекста символов и для учёта контекста слов мы используем две разных нейросети, но архитектура их одинакова — это ровно та самая свёрточная сеть со \"skip connections\", которую мы описали в начале нашего семинара. Несмотря на то, что архитектура у этих модулей одинаковая, веса у них отличаются. На старте обучения они инициализируются случайно, а затем — настраиваются. В результате мы получаем также трёхмерный тензор, той же размерности, но теперь — вектор для каждого токена уже содержит информацию о его контексте. И, наконец, нам нужно принять решение о части речи каждого токена. Для этого мы проецируем признаки каждого токена в пространство классов. Для этого мы используем одномерный свёрточный блок с ядром свёртки 1, то есть он за раз видит только один токен. Физический смысл того, что мы описали сейчас, заключается в том, чтобы сначала проанализировать структуру каждого слова, найти там какие-то суффиксы и окончания (за это отвечает первая часть) а затем — смешать информацию о структуре каждого слова с контекстом, в котором это слово употребляется."]},{"cell_type":"code","execution_count":18,"metadata":{"ExecuteTime":{"end_time":"2019-10-29T19:47:48.325744Z","start_time":"2019-10-29T19:46:50.139Z"},"id":"bg0FVrdUaZtW"},"outputs":[],"source":["class SentenceLevelPOSTagger(nn.Module):\n","    def __init__(self, vocab_size, labels_num, embedding_size=32, single_backbone_kwargs={}, context_backbone_kwargs={}):\n","        super().__init__()\n","        self.embedding_size = embedding_size\n","        self.char_embeddings = nn.Embedding(vocab_size, embedding_size, padding_idx=0)\n","        self.single_token_backbone = StackedConv1d(embedding_size, **single_backbone_kwargs)\n","        self.context_backbone = StackedConv1d(embedding_size, **context_backbone_kwargs)\n","        self.global_pooling = nn.AdaptiveMaxPool1d(1)\n","        self.out = nn.Conv1d(embedding_size, labels_num, 1)\n","        self.labels_num = labels_num\n","    \n","    def forward(self, tokens):\n","        \"\"\"tokens - BatchSize x MaxSentenceLen x MaxTokenLen\"\"\"\n","        batch_size, max_sent_len, max_token_len = tokens.shape\n","        tokens_flat = tokens.view(batch_size * max_sent_len, max_token_len)\n","        \n","        char_embeddings = self.char_embeddings(tokens_flat)  # BatchSize*MaxSentenceLen x MaxTokenLen x EmbSize\n","        char_embeddings = char_embeddings.permute(0, 2, 1)  # BatchSize*MaxSentenceLen x EmbSize x MaxTokenLen\n","        char_features = self.single_token_backbone(char_embeddings)\n","        \n","        token_features_flat = self.global_pooling(char_features).squeeze(-1)  # BatchSize*MaxSentenceLen x EmbSize\n","\n","        token_features = token_features_flat.view(batch_size, max_sent_len, self.embedding_size)  # BatchSize x MaxSentenceLen x EmbSize\n","        token_features = token_features.permute(0, 2, 1)  # BatchSize x EmbSize x MaxSentenceLen\n","        context_features = self.context_backbone(token_features)  # BatchSize x EmbSize x MaxSentenceLen\n","\n","        logits = self.out(context_features)  # BatchSize x LabelsNum x MaxSentenceLen\n","        return logits"]},{"cell_type":"markdown","metadata":{"id":"Ki5C7Xak4Rxc"},"source":["Сначала мы создаём экземпляр класса, который только что описали, и передаём туда, на самом деле, все те же самые параметры — это количество символов, количество выходных меток, количество признаков для каждого символа, но теперь это ещё и количество признаков для каждого токена (оно у нас одинаково), а также два набора параметров для свёрточных модулей. Первый набор параметров — для анализа символов на уровне каждого токена, а второй набор параметров — для анализа контекста токенов. Мы решили задать одни и те же параметры, потому что это неплохо работает. В результате мы получили нейросеть, в которой в два раза больше параметров"]},{"cell_type":"code","execution_count":19,"metadata":{"ExecuteTime":{"end_time":"2019-10-29T19:47:48.326925Z","start_time":"2019-10-29T19:46:50.310Z"},"id":"WoFFX7pPaZtW"},"outputs":[{"name":"stdout","output_type":"stream","text":["Количество параметров 84882\n"]}],"source":["sentence_level_model = SentenceLevelPOSTagger(len(char_vocab), len(label2id), embedding_size=64,\n","                                              single_backbone_kwargs=dict(layers_n=3, kernel_size=3, dropout=0.3),\n","                                              context_backbone_kwargs=dict(layers_n=3, kernel_size=3, dropout=0.3))\n","print('Количество параметров', sum(np.product(t.shape) for t in sentence_level_model.parameters()))"]},{"cell_type":"markdown","metadata":{"id":"AIpS_ekK5Fa4"},"source":["Далее мы используем всё тот же цикл обучения — здесь никаких существенных отличий нет. Если вы потом внимательно посмотрите на вывод обучения, вы увидите, что для второй модели, которая учитывает контекст токенов, значение функции потерь во время обучения падает гораздо быстрее и, в итоге, достигает существенно меньшего значения. е"]},{"cell_type":"code","execution_count":20,"metadata":{"ExecuteTime":{"end_time":"2019-10-29T19:47:48.327888Z","start_time":"2019-10-29T19:46:50.737Z"},"id":"uyCL5RkkaZtW","scrolled":false},"outputs":[{"name":"stdout","output_type":"stream","text":["Эпоха 0\n","Эпоха: 501 итераций, 45.92 сек\n","Среднее значение функции потерь на обучении 0.06945245525615658\n","Среднее значение функции потерь на валидации 0.026779627989940713\n","Новая лучшая модель!\n","\n","Эпоха 1\n","Эпоха: 501 итераций, 45.93 сек\n","Среднее значение функции потерь на обучении 0.02525442752786382\n","Среднее значение функции потерь на валидации 0.019473401589853927\n","Новая лучшая модель!\n","\n","Эпоха 2\n","Эпоха: 501 итераций, 45.93 сек\n","Среднее значение функции потерь на обучении 0.020784088282171122\n","Среднее значение функции потерь на валидации 0.0157019424224549\n","Новая лучшая модель!\n","\n","Эпоха 3\n","Эпоха: 501 итераций, 45.95 сек\n","Среднее значение функции потерь на обучении 0.018439713393351036\n","Среднее значение функции потерь на валидации 0.014976288957318456\n","Новая лучшая модель!\n","\n","Эпоха 4\n","Эпоха: 501 итераций, 45.96 сек\n","Среднее значение функции потерь на обучении 0.01716930501742991\n","Среднее значение функции потерь на валидации 0.013994390827299344\n","Новая лучшая модель!\n","\n","Эпоха 5\n","Эпоха: 501 итераций, 45.94 сек\n","Среднее значение функции потерь на обучении 0.015939749383224462\n","Среднее значение функции потерь на валидации 0.014135834765574425\n","\n","Эпоха 6\n","Эпоха: 501 итераций, 45.95 сек\n","Среднее значение функции потерь на обучении 0.015289177809527772\n","Среднее значение функции потерь на валидации 0.012828381520022851\n","Новая лучшая модель!\n","\n","Эпоха 7\n","Эпоха: 501 итераций, 45.97 сек\n","Среднее значение функции потерь на обучении 0.014902165726555916\n","Среднее значение функции потерь на валидации 0.012299404258258862\n","Новая лучшая модель!\n","\n","Эпоха 8\n","Эпоха: 501 итераций, 45.94 сек\n","Среднее значение функции потерь на обучении 0.014620564400242593\n","Среднее значение функции потерь на валидации 0.012152184109839767\n","Новая лучшая модель!\n","\n","Эпоха 9\n","Эпоха: 501 итераций, 45.94 сек\n","Среднее значение функции потерь на обучении 0.01429456232967015\n","Среднее значение функции потерь на валидации 0.011965245607834641\n","Новая лучшая модель!\n","\n"]}],"source":["(best_val_loss,\n"," best_sentence_level_model) = train_eval_loop(sentence_level_model,\n","                                              train_dataset,\n","                                              test_dataset,\n","                                              F.cross_entropy,\n","                                              lr=5e-3,\n","                                              epoch_n=10,\n","                                              batch_size=64,\n","                                              device='cuda',\n","                                              early_stopping_patience=5,\n","                                              max_batches_per_epoch_train=500,\n","                                              max_batches_per_epoch_val=100,\n","                                              lr_scheduler_ctor=lambda optim: torch.optim.lr_scheduler.ReduceLROnPlateau(optim, patience=2,\n","                                                                                                                         factor=0.5,\n","                                                                                                                         verbose=True))"]},{"cell_type":"code","execution_count":21,"metadata":{"ExecuteTime":{"end_time":"2019-08-29T13:56:16.542052Z","start_time":"2019-08-29T13:56:16.529110Z"},"id":"wmEBolxyaZtX"},"outputs":[],"source":["# Если Вы запускаете ноутбук на colab или kaggle, добавьте в начало пути ./stepik-dl-nlp\n","torch.save(best_sentence_level_model.state_dict(), './models/3.7.sentence_level_pos.pth')"]},{"cell_type":"code","execution_count":22,"metadata":{"ExecuteTime":{"end_time":"2019-08-29T13:56:16.564926Z","start_time":"2019-08-29T13:56:16.544481Z"},"id":"htvynqT7aZtX"},"outputs":[{"data":{"text/plain":["<All keys matched successfully>"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["# Если Вы запускаете ноутбук на colab или kaggle, добавьте в начало пути ./stepik-dl-nlp\n","sentence_level_model.load_state_dict(torch.load('./models/3.7.sentence_level_pos.pth'))"]},{"cell_type":"markdown","metadata":{"id":"Ef_LVkZH5Xl6"},"source":["Здесь у нас macro f-мера, равна 0.93, а для первой модели, как мы помним, она была равна 0.89. То есть, мы получили прирост в 4%, добавив всего лишь ещё один свёрточный модуль для учёта контекста токенов."]},{"cell_type":"code","execution_count":23,"metadata":{"ExecuteTime":{"end_time":"2019-08-29T13:56:42.092139Z","start_time":"2019-08-29T13:56:16.567242Z"},"id":"BauJDnlDaZtX"},"outputs":[{"name":"stderr","output_type":"stream","text":["1526it [00:27, 54.60it/s]                               \n"]},{"name":"stdout","output_type":"stream","text":["Среднее значение функции потерь на обучении 0.010619516484439373\n","              precision    recall  f1-score   support\n","\n","     <NOTAG>       1.00      1.00      1.00   9136391\n","         ADJ       0.91      0.95      0.93     85589\n","         ADP       1.00      0.99      0.99     81963\n","         ADV       0.89      0.93      0.91     44101\n","         AUX       0.92      0.88      0.90      7535\n","       CCONJ       0.93      0.99      0.96     30432\n","         DET       0.85      0.95      0.90     21968\n","        INTJ       1.00      0.15      0.27        78\n","        NOUN       0.98      0.96      0.97    214497\n","         NUM       0.95      0.96      0.95     13746\n","        PART       0.97      0.86      0.91     26638\n","        PRON       0.98      0.88      0.93     38438\n","       PROPN       0.90      0.98      0.94     32401\n","       PUNCT       1.00      1.00      1.00    157989\n","       SCONJ       0.91      0.84      0.87     16219\n","         SYM       1.00      1.00      1.00       840\n","        VERB       0.95      0.96      0.96     97670\n","           X       0.92      0.64      0.75       375\n","\n","    accuracy                           1.00  10006870\n","   macro avg       0.95      0.88      0.90  10006870\n","weighted avg       1.00      1.00      1.00  10006870\n","\n","\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 206/205.75 [00:03<00:00, 54.67it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Среднее значение функции потерь на валидации 0.011860478669404984\n","              precision    recall  f1-score   support\n","\n","     <NOTAG>       1.00      1.00      1.00   1231232\n","         ADJ       0.91      0.94      0.92     11222\n","         ADP       1.00      0.99      0.99     10585\n","         ADV       0.89      0.92      0.90      6165\n","         AUX       0.90      0.88      0.89      1108\n","       CCONJ       0.93      0.99      0.96      4410\n","         DET       0.83      0.94      0.88      3085\n","        INTJ       1.00      0.27      0.43        11\n","        NOUN       0.97      0.95      0.96     27974\n","         NUM       0.94      0.95      0.94      1829\n","        PART       0.97      0.86      0.91      3875\n","        PRON       0.97      0.88      0.92      5598\n","       PROPN       0.88      0.97      0.93      4438\n","       PUNCT       1.00      1.00      1.00     22694\n","       SCONJ       0.89      0.84      0.86      2258\n","         SYM       0.98      0.98      0.98        53\n","        VERB       0.95      0.95      0.95     13078\n","           X       0.97      0.81      0.88       105\n","\n","    accuracy                           1.00   1349720\n","   macro avg       0.94      0.90      0.91   1349720\n","weighted avg       1.00      1.00      1.00   1349720\n","\n"]}],"source":["train_pred = predict_with_model(sentence_level_model, train_dataset)\n","train_loss = F.cross_entropy(torch.tensor(train_pred),\n","                             torch.tensor(train_labels))\n","print('Среднее значение функции потерь на обучении', float(train_loss))\n","print(classification_report(train_labels.view(-1), train_pred.argmax(1).reshape(-1), target_names=UNIQUE_TAGS))\n","print()\n","\n","test_pred = predict_with_model(sentence_level_model, test_dataset)\n","test_loss = F.cross_entropy(torch.tensor(test_pred),\n","                            torch.tensor(test_labels))\n","print('Среднее значение функции потерь на валидации', float(test_loss))\n","print(classification_report(test_labels.view(-1), test_pred.argmax(1).reshape(-1), target_names=UNIQUE_TAGS))"]},{"cell_type":"markdown","metadata":{"id":"Pok7Lwo1aZtX"},"source":["## Применение полученных теггеров и сравнение"]},{"cell_type":"markdown","metadata":{"id":"NPELhYnW5fQe"},"source":["Для того, чтобы вручную поэкспериментировать с обученными моделями мы сделали специальный класс \"POS tagger\", который принимает на вход а обученную модель, а также те же самые параметры — это отображение символов в их идентификаторы, это количество уникальных тэгов. Кроме этого, он на вход принимает отображение символов в их номера, отображение из номеров тэгов обратно в их строковое представление, а также статистики корпуса — максимальную длину предложения и максимальную длину токена. И мы создаём два экземпляра этого класса для модели, обученной на отдельных токенах, и для модели, которая учитывает контекст. Класс \"POS tagger\" достаточно простой. В конструктор он принимает все эти параметры, которые мы сейчас описали, и у него есть ещё метод — этот метод применяет нашу обученную модель к переданным предложениям для того, чтобы получить части речи токенов. Для того, чтобы определить части речи токенов, сначала мы токенизируем переданное нам предложение, затем делаем то, что мы делали при обучении — а именно, перекладываем информацию о символах в тензор, затем, в цикле, применяем нашу модель для каждого предложения. В результате применения нашей модели к каждому предложению мы получаем трёхмерный тензор, первая размерность этого тензора соответствует количеству предложений, вторая — это количество меток, а третья — это максимальная длина предложения. Таким образом, для каждого предложения и для каждого токена у нас есть распределение вероятностей по меткам. И здесь мы просто выбираем для каждого токена наиболее вероятную метку. Затем преобразовываем полученную информацию в формат, удобный для человека, то есть мы преобразовываем номера тэгов в их строковое название"]},{"cell_type":"code","execution_count":24,"metadata":{"ExecuteTime":{"end_time":"2019-08-29T13:56:42.105418Z","start_time":"2019-08-29T13:56:42.093744Z"},"id":"AV2rK72RaZtX"},"outputs":[],"source":["single_token_pos_tagger = POSTagger(single_token_model, char_vocab, UNIQUE_TAGS, MAX_SENT_LEN, MAX_ORIG_TOKEN_LEN)\n","sentence_level_pos_tagger = POSTagger(sentence_level_model, char_vocab, UNIQUE_TAGS, MAX_SENT_LEN, MAX_ORIG_TOKEN_LEN)"]},{"cell_type":"markdown","metadata":{"id":"eSMsHiI_6DOk"},"source":["Предложений про \"глокую куздру\" в обучающей выборке не было. Таким образом это тест на неизвестные слова, а ещё есть несколько тестов на контекст — на учёт контекста, а именно здесь: \"ведро дало течь\" — это существительное, а \"вода стала течь\" — это глагол. \"Сорок сорок\" — здесь одно из слов числительное, а другое — существительное. ."]},{"cell_type":"code","execution_count":25,"metadata":{"ExecuteTime":{"end_time":"2019-08-29T13:56:42.125540Z","start_time":"2019-08-29T13:56:42.106771Z"},"id":"uyGOp44DaZtX"},"outputs":[],"source":["test_sentences = [\n","    'Мама мыла раму.',\n","    'Косил косой косой косой.',\n","    'Глокая куздра штеко будланула бокра и куздрячит бокрёнка.',\n","    'Сяпала Калуша с Калушатами по напушке.',\n","    'Пирожки поставлены в печь, мама любит печь.',\n","    'Ведро дало течь, вода стала течь.',\n","    'Три да три, будет дырка.',\n","    'Три да три, будет шесть.',\n","    'Сорок сорок'\n","]\n","test_sentences_tokenized = tokenize_corpus(test_sentences, min_token_size=1)"]},{"cell_type":"markdown","metadata":{"id":"gqNAfzBL6bPH"},"source":["Мы видим, что, например, в последнем предложений \"сорок сорок\", модель назначает просто наиболее вероятный тэг: слово \"сорок\" всё-таки чаще используются как числительное. Для неизвестных слов модель отработала просто отлично. Хотя допустила пару ошибок, а именно — \"штеко\" — это не существительное, а наречие. "]},{"cell_type":"code","execution_count":26,"metadata":{"ExecuteTime":{"end_time":"2019-08-29T13:56:42.148124Z","start_time":"2019-08-29T13:56:42.126930Z"},"id":"5TPTY443aZtY"},"outputs":[{"name":"stderr","output_type":"stream","text":["1it [00:00, 137.75it/s]                    "]},{"name":"stdout","output_type":"stream","text":["мама-NOUN мыла-VERB раму-NOUN\n","\n","косил-VERB косой-ADJ косой-ADJ косой-ADJ\n","\n","глокая-ADJ куздра-NOUN штеко-ADV будланула-VERB бокра-NOUN и-CCONJ куздрячит-VERB бокрёнка-NOUN\n","\n","сяпала-VERB калуша-NOUN с-ADP калушатами-NOUN по-ADP напушке-NOUN\n","\n","пирожки-NOUN поставлены-VERB в-ADP печь-NOUN мама-NOUN любит-VERB печь-NOUN\n","\n","ведро-NOUN дало-VERB течь-NOUN вода-NOUN стала-VERB течь-NOUN\n","\n","три-NUM да-PART три-NUM будет-AUX дырка-NOUN\n","\n","три-NUM да-PART три-NUM будет-AUX шесть-NUM\n","\n","сорок-NOUN сорок-NOUN\n","\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["for sent_tokens, sent_tags in zip(test_sentences_tokenized, single_token_pos_tagger(test_sentences)):\n","    print(' '.join('{}-{}'.format(tok, tag) for tok, tag in zip(sent_tokens, sent_tags)))\n","    print()"]},{"cell_type":"markdown","metadata":{"id":"-AGXRsRD7Mv7"},"source":["Ну что ж, теперь — вторая модель. Мы сразу видим, что \"сорок сорок\" уже разобраны более-менее правильно, то есть одно из этих слов — это числительное, а второе — это существительное. Также в предложении про \"глокую куздру\" исправлена ошибка с наречием, в предложении про \"пирожки\" эта нейросеть уже смогла различить ситуации, в которых и слово \"печь\" используется как существительное, и как глагол. Забавно, что во втором аналогичном предложений нейросеть тоже отличила две ситуации, но перепутала. То есть, в том случае, где должен был быть глагол, получилось существительное, а во втором случае должно было быть существительное, а получился глагол. Предложение про \"косого косого\", который \"косил косой\" тоже разобрано чуть лучше, хотя и не идеально. Предложения про \"три да три будет шесть\" или \"будет дырка\" разобрались так же, предположительно — потому, что мы использовали только три слоя свёрток для учёта контекста токенов и, возможно, нейросети просто не хватило рецептивного поля, то есть для слова \"три\" она не могла увидеть, что в конце предложения есть слово \"шесть\". Мы увидели, что, действительно, для задачи определения частей речи, учитывать контекст токенов действительно важно, в определённых случаях. "]},{"cell_type":"code","execution_count":27,"metadata":{"ExecuteTime":{"end_time":"2019-08-29T13:56:42.168810Z","start_time":"2019-08-29T13:56:42.149698Z"},"id":"RC3R9THXaZtY"},"outputs":[{"name":"stderr","output_type":"stream","text":["1it [00:00, 156.61it/s]                    "]},{"name":"stdout","output_type":"stream","text":["мама-NOUN мыла-NOUN раму-NOUN\n","\n","косил-VERB косой-ADJ косой-ADJ косой-NOUN\n","\n","глокая-ADJ куздра-NOUN штеко-NOUN будланула-VERB бокра-NOUN и-CCONJ куздрячит-VERB бокрёнка-NOUN\n","\n","сяпала-VERB калуша-NOUN с-ADP калушатами-NOUN по-ADP напушке-NOUN\n","\n","пирожки-NOUN поставлены-VERB в-ADP печь-NOUN мама-NOUN любит-VERB печь-NOUN\n","\n","ведро-NOUN дало-VERB течь-NOUN вода-NOUN стала-VERB течь-NOUN\n","\n","три-NUM да-CCONJ три-NUM будет-VERB дырка-NOUN\n","\n","три-NUM да-CCONJ три-NUM будет-VERB шесть-NUM\n","\n","сорок-NOUN сорок-NOUN\n","\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["for sent_tokens, sent_tags in zip(test_sentences_tokenized, sentence_level_pos_tagger(test_sentences)):\n","    print(' '.join('{}-{}'.format(tok, tag) for tok, tag in zip(sent_tokens, sent_tags)))\n","    print()"]},{"cell_type":"markdown","metadata":{"id":"QqEmZ3cdaZtZ"},"source":["## Свёрточный модуль своими руками"]},{"cell_type":"markdown","metadata":{"id":"mrjrbHTv7tAQ"},"source":["Давайте копнём чуть чуть глубже — посмотрим, как же можно реализовать свёртки своими руками. Для этого давайте опишем класс — все pytorch-модули наследуются от базового класса \"nn.module\", давайте реализуем не весь, но основной функционал стандартного модуля \"nn.conv1d\". При этом, давайте будем, по возможности, делать так, чтобы наш модуль можно было использовать как замену — один в один. Итак, входные параметры — это количество исходных каналов, количество результирующих каналов, размер ядра и размер паддинга. В конструкторе а мы создаём два тензора — это наши веса. \"self.weight\" — это ядро свёртки. В отличие от стандартного модуля, мы будем использовать здесь прямоугольную матрицу, в этой матрице количество строк равно количеству входных каналов умноженному на размер свёртки (на размер ядра), а количество столбцов этой матрицы равно количеству выходных каналов. Инициализируем этот тензор мы шумом из нормального распределения с маленькой дисперсией. Также у нас есть второй тензор параметров — это смещение. Это просто вектор размерности, равной количеству выходных каналов, его мы инициализируем нулями. Теперь давайте посмотрим на метод \"forward\". На вход одномерные свёртки принимают трёхмерные тензоры, первая размерность которых соответствует размеру батча, вторая — количеству входных каналов, и третья — длине последовательности. А в качестве результата возвращают также трёхмерный тензор размерности [\"количество элементов в батче\", \"количество выходных каналов\" на \"новую длину последовательности\"]. Она может либо остаться прежней, либо уменьшится, либо увеличиться — это зависит от размеров ядра и от паддинга. Сначала мы делаем паддинг (вот этот кусок кода отвечает за паддинг). Здесь мы реализовали паддинг только нулями. В случае одномерных свёрток, паддинг заключается в том, что мы увеличиваем третье измерение (удлиняем тензор по третьему измерению — то есть, по длине последовательности) на указанное количество элементов, как спереди, так и сзади. Для этого мы создаём тензор нулей, а затем — конкатенируем его вместе с исходным тензором признаков, так, чтобы паддинги были и в начале тензора, и в конце. И нам нужно вычислить заново длину последовательности, переприсвоить переменной. Далее мы подготавливаем матрицу признаков. Как мы это делаем? Вот этот кусок кода отвечает за подготовку признаков. Предположим, что на вход нам пришла вот такая матрица. В ней каждый столбец соответствует какому-то элементу последовательности. Давайте их условно перенумеруем \"1, 2, 3, 4, 5\". И у нас ядро свёртки, допустим, равно трём. Тогда мы из исходной матрицы сформируем новую матрицу, в которой количество столбцов — новое, оно вычисляется как длина исходной последовательности минус размер ядра плюс 1 (длина исходной последовательности, конечно, берётся уже с учётом паддинга). Для примера — допустим, что у нас нету паддинга. Итак — как мы будем готовить матрицу признаков? Мы будем перебирать все смещения от 0 до размера ядра - 1 и для каждого смещения мы будем брать фрагмент исходной матрицы, начиная с этого смещения, длины равной результирующей длине. Давайте на примере — для исходной последовательности длины 5 и ядра свёртки 3, длина выходной последовательности будет также равна 3 (то есть, chunk size будет равен 3). Тогда — перебирать все смещения от 0 до 2 и выбирать фрагмент исходной матрицы (сначала мы берём такую под-матрицу, затем берём начиная со второго элемента, затем — начиная с третьего элемента). Потом, когда мы перебрали все возможные смещения, мы объединяем все эти кусочки в одну матрицу, причём объединяем её по второму измерению, то есть по измерению признаков — мы получаем, в итоге, вот такую новую матрицу, в ней три столбца, а количество строк равно количеству исходных каналов умноженное на размер ядра свёртки (здесь у нас, по сути, значения будут такие). Таким образом, мы реализовали скользящее окно, которым мы идём по данным. То есть, каждый столбец этой матрицы содержит признаки всех данных, которые попадают в скользящее окно, которым мы идём по исходной последовательности и преобразовываем исходную последовательность в каждом окне.   \n","\n","12345->123,234,345.  \n","\n","После объединения кусочков в одну матрицу признаков мы её транспонируем и применяем ядро свёртки. Делать мы это будем с помощью функции \"torch.bmm\" (\"BMM\" расшифровывается как \"batch matrix multiplication\", то есть это пакетное матричное перемножение). эта функция принимает на вход два трёхмерных тензора и, для каждой пары матриц в этих тензорах, делает матричное умножение. Первый тензор — это признаки, которые мы только что составили из кусочков, и второй тензор — это наше ядро свёртки, но наше ядро свёртки — это матрица, а нам нужно получить трёхмерный тензор. Для этого мы добавляем фиктивное нулевое измерение, соответствующее размеру батча и вызываем функцию \"expand\" (\"expand\" изменяет размер тензора, но, при этом, она делает это без выделения дополнительной памяти, то есть снаружи выглядит, что тензор большой, а на самом деле это — просто плоская матрица). Итак, ядро свёртки применили, теперь добавляем смещение и транспонируем полученную матрицу так, чтобы у нас смысл измерений в результирующем тензоре соответствовал смыслу измерений во входном тензоре, то есть — сначала размер батча, потом количество каналов, а потом — пространственные измерения, то есть длина последовательности. "]},{"cell_type":"code","execution_count":28,"metadata":{"ExecuteTime":{"end_time":"2019-08-29T13:56:42.193140Z","start_time":"2019-08-29T13:56:42.170233Z"},"id":"nrkI1ehKaZtZ"},"outputs":[],"source":["class MyConv1d(nn.Module):\n","    def __init__(self, in_channels, out_channels, kernel_size, padding=0):\n","        super().__init__()\n","        self.in_channels = in_channels\n","        self.out_channels = out_channels\n","        self.kernel_size = kernel_size\n","        self.padding = padding\n","        self.weight = nn.Parameter(torch.randn(in_channels * kernel_size, out_channels) / (in_channels * kernel_size),\n","                                   requires_grad=True)\n","        self.bias = nn.Parameter(torch.zeros(out_channels), requires_grad=True)\n","    \n","    def forward(self, x):\n","        \"\"\"x - BatchSize x InChannels x SequenceLen\"\"\"\n","\n","        batch_size, src_channels, sequence_len = x.shape        \n","        if self.padding > 0:\n","            pad = x.new_zeros(batch_size, src_channels, self.padding)\n","            x = torch.cat((pad, x, pad), dim=-1)\n","            sequence_len = x.shape[-1]\n","\n","        chunks = []\n","        chunk_size = sequence_len - self.kernel_size + 1\n","        for offset in range(self.kernel_size):\n","            chunks.append(x[:, :, offset:offset + chunk_size])\n","\n","        in_features = torch.cat(chunks, dim=1)  # BatchSize x InChannels * KernelSize x ChunkSize\n","        in_features = in_features.permute(0, 2, 1)  # BatchSize x ChunkSize x InChannels * KernelSize\n","        out_features = torch.bmm(in_features, self.weight.unsqueeze(0).expand(batch_size, -1, -1)) + self.bias.unsqueeze(0).unsqueeze(0)\n","        out_features = out_features.permute(0, 2, 1)  # BatchSize x OutChannels x ChunkSize\n","        return out_features"]},{"cell_type":"code","execution_count":29,"metadata":{"ExecuteTime":{"end_time":"2019-08-29T13:56:42.210013Z","start_time":"2019-08-29T13:56:42.194620Z"},"id":"J1rQyKfOaZta"},"outputs":[{"name":"stdout","output_type":"stream","text":["Количество параметров 84882\n"]}],"source":["sentence_level_model_my_conv = SentenceLevelPOSTagger(len(char_vocab), len(label2id), embedding_size=64,\n","                                                      single_backbone_kwargs=dict(layers_n=3, kernel_size=3, dropout=0.3, conv_layer=MyConv1d),\n","                                                      context_backbone_kwargs=dict(layers_n=3, kernel_size=3, dropout=0.3, conv_layer=MyConv1d))\n","print('Количество параметров', sum(np.product(t.shape) for t in sentence_level_model_my_conv.parameters()))"]},{"cell_type":"markdown","metadata":{"id":"i64-cbo7CCH8"},"source":["Попробуем обучить модель для определения частей речи токенов, но свёрточный модуль заменим на наш свёрточный модуль, возьмём за основу модель, которая учитывает контекст токенов, и создадим экземпляр этой модели, и передадим туда все те же самые параметры, которые передавали и раньше, но добавим ещё один — а именно, скажем ей \"используй, пожалуйста, наш модуль — не стандартный nn.conv1d из pytorch, а наш модуль, который мы только что описали\". Как мы видим, количество параметров в результате мы получили ровно такое же. "]},{"cell_type":"code","execution_count":30,"metadata":{"ExecuteTime":{"end_time":"2019-08-29T14:06:00.233326Z","start_time":"2019-08-29T13:56:42.211456Z"},"id":"kOxRHolOaZta"},"outputs":[{"name":"stdout","output_type":"stream","text":["Эпоха 0\n","Эпоха: 501 итераций, 93.38 сек\n","Среднее значение функции потерь на обучении 0.0749039586499601\n","Среднее значение функции потерь на валидации 0.018735384135184312\n","Новая лучшая модель!\n","\n","Эпоха 1\n","Эпоха: 501 итераций, 93.42 сек\n","Среднее значение функции потерь на обучении 0.020598441505518383\n","Среднее значение функции потерь на валидации 0.015261760359574663\n","Новая лучшая модель!\n","\n","Эпоха 2\n","Эпоха: 501 итераций, 93.48 сек\n","Среднее значение функции потерь на обучении 0.017871170827074203\n","Среднее значение функции потерь на валидации 0.013712439824375186\n","Новая лучшая модель!\n","\n","Эпоха 3\n","Эпоха: 501 итераций, 93.59 сек\n","Среднее значение функции потерь на обучении 0.016590953531290243\n","Среднее значение функции потерь на валидации 0.013132767922401723\n","Новая лучшая модель!\n","\n","Эпоха 4\n","Эпоха: 501 итераций, 93.65 сек\n","Среднее значение функции потерь на обучении 0.015701849050745516\n","Среднее значение функции потерь на валидации 0.012663036658622251\n","Новая лучшая модель!\n","\n","Эпоха 5\n","Эпоха: 501 итераций, 93.68 сек\n","Среднее значение функции потерь на обучении 0.015037811814831522\n","Среднее значение функции потерь на валидации 0.012032126343928942\n","Новая лучшая модель!\n","\n","Эпоха 6\n","Эпоха: 501 итераций, 93.67 сек\n","Среднее значение функции потерь на обучении 0.014634863064510974\n","Среднее значение функции потерь на валидации 0.011943200967357596\n","Новая лучшая модель!\n","\n","Эпоха 7\n","Эпоха: 501 итераций, 93.68 сек\n","Среднее значение функции потерь на обучении 0.014043952433202795\n","Среднее значение функции потерь на валидации 0.010895801934017109\n","Новая лучшая модель!\n","\n","Эпоха 8\n","Эпоха: 501 итераций, 93.67 сек\n","Среднее значение функции потерь на обучении 0.013914183430938783\n","Среднее значение функции потерь на валидации 0.010819569866329726\n","Новая лучшая модель!\n","\n","Эпоха 9\n","Эпоха: 501 итераций, 93.67 сек\n","Среднее значение функции потерь на обучении 0.013858984044182324\n","Среднее значение функции потерь на валидации 0.010379182741894285\n","Новая лучшая модель!\n","\n"]}],"source":["(best_val_loss,\n"," best_sentence_level_model_my_conv) = train_eval_loop(sentence_level_model_my_conv,\n","                                                      train_dataset,\n","                                                      test_dataset,\n","                                                      F.cross_entropy,\n","                                                      lr=5e-3,\n","                                                      epoch_n=10,\n","                                                      batch_size=64,\n","                                                      device='cuda',\n","                                                      early_stopping_patience=5,\n","                                                      max_batches_per_epoch_train=500,\n","                                                      max_batches_per_epoch_val=100,\n","                                                      lr_scheduler_ctor=lambda optim: torch.optim.lr_scheduler.ReduceLROnPlateau(optim, patience=2,\n","                                                                                                                                 factor=0.5,\n","                                                                                                                                 verbose=True))"]},{"cell_type":"markdown","metadata":{"id":"D3XexcTJCN3n"},"source":["Обучаем нашу модель, используя ту же самую функцию. Любопытно, что модель, которая использует наш свёрточный модуль, на одну эпоху требует 52 секунды. А модель, которая использовала стандартный свёрточный модуль требовала примерно 120 секунд на одну эпоху, то есть получается, что наш модуль чуть-чуть побыстрее. Эта разница имеет значение только для той версии pytorch, которую используем мы сейчас, в другой версии pytorch разница может быть совершенно другая. Наиболее вероятно, что это ускорение вызвано тем, что наша реализация свёрток узкоспециализирована, в ней нету кучи разных вариантов паддинга, в ней нет механизма прореживания ядра, а также нет страйдов — в ней нельзя задавать шаг, с которым нужно идти скользящим окном по исходной последовательности. Другими словами, она проще гораздо, чем стандартная реализация свёрток. Таким образом, иногда имеет смысл что-то реализовать самому, но надо помнить, что в машинном обучении, часто, гораздо важнее быстро проверять разные гипотезы, а для этого лучше использовать стандартные модули, которые проверены, работают надёжно в разных ситуациях, они универсальны и вам не нужно тратить время на написание своих модулей. Свои модули имеет смысл писать только тогда, когда вы точно знаете ту архитектуру, которая вам нужна для решения вашей прикладной задачи, и вы хотите её ускорить. Например — для того, чтобы уметь запускать её на мобильном телефоне."]},{"cell_type":"code","execution_count":31,"metadata":{"ExecuteTime":{"end_time":"2019-08-29T14:06:39.145214Z","start_time":"2019-08-29T14:06:00.234936Z"},"id":"S_Cou5P-aZta"},"outputs":[{"name":"stderr","output_type":"stream","text":["1526it [00:43, 34.92it/s]                               \n"]},{"name":"stdout","output_type":"stream","text":["Среднее значение функции потерь на обучении 0.009122215211391449\n","              precision    recall  f1-score   support\n","\n","     <NOTAG>       1.00      1.00      1.00   9136391\n","         ADJ       0.93      0.94      0.94     85589\n","         ADP       1.00      0.99      1.00     81963\n","         ADV       0.93      0.91      0.92     44101\n","         AUX       0.92      0.88      0.90      7535\n","       CCONJ       0.95      0.97      0.96     30432\n","         DET       0.91      0.94      0.92     21968\n","        INTJ       0.93      0.35      0.50        78\n","        NOUN       0.98      0.97      0.97    214497\n","         NUM       0.95      0.96      0.96     13746\n","        PART       0.96      0.90      0.93     26638\n","        PRON       0.95      0.93      0.94     38438\n","       PROPN       0.92      0.97      0.95     32401\n","       PUNCT       1.00      1.00      1.00    157989\n","       SCONJ       0.90      0.93      0.92     16219\n","         SYM       1.00      0.99      1.00       840\n","        VERB       0.95      0.97      0.96     97670\n","           X       0.93      0.67      0.78       375\n","\n","    accuracy                           1.00  10006870\n","   macro avg       0.95      0.90      0.92  10006870\n","weighted avg       1.00      1.00      1.00  10006870\n","\n","\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 206/205.75 [00:05<00:00, 35.03it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Среднее значение функции потерь на валидации 0.010301370173692703\n","              precision    recall  f1-score   support\n","\n","     <NOTAG>       1.00      1.00      1.00   1231232\n","         ADJ       0.93      0.93      0.93     11222\n","         ADP       1.00      0.99      1.00     10585\n","         ADV       0.93      0.91      0.92      6165\n","         AUX       0.91      0.86      0.88      1108\n","       CCONJ       0.95      0.97      0.96      4410\n","         DET       0.90      0.92      0.91      3085\n","        INTJ       1.00      0.27      0.43        11\n","        NOUN       0.97      0.96      0.97     27974\n","         NUM       0.95      0.94      0.95      1829\n","        PART       0.95      0.90      0.92      3875\n","        PRON       0.95      0.92      0.93      5598\n","       PROPN       0.91      0.95      0.93      4438\n","       PUNCT       1.00      1.00      1.00     22694\n","       SCONJ       0.89      0.92      0.91      2258\n","         SYM       1.00      0.96      0.98        53\n","        VERB       0.94      0.97      0.95     13078\n","           X       0.99      0.79      0.88       105\n","\n","    accuracy                           1.00   1349720\n","   macro avg       0.95      0.90      0.91   1349720\n","weighted avg       1.00      1.00      1.00   1349720\n","\n"]}],"source":["train_pred = predict_with_model(best_sentence_level_model_my_conv, train_dataset)\n","train_loss = F.cross_entropy(torch.tensor(train_pred),\n","                             torch.tensor(train_labels))\n","print('Среднее значение функции потерь на обучении', float(train_loss))\n","print(classification_report(train_labels.view(-1), train_pred.argmax(1).reshape(-1), target_names=UNIQUE_TAGS))\n","print()\n","\n","test_pred = predict_with_model(best_sentence_level_model_my_conv, test_dataset)\n","test_loss = F.cross_entropy(torch.tensor(test_pred),\n","                            torch.tensor(test_labels))\n","print('Среднее значение функции потерь на валидации', float(test_loss))\n","print(classification_report(test_labels.view(-1), test_pred.argmax(1).reshape(-1), target_names=UNIQUE_TAGS))"]},{"cell_type":"markdown","metadata":{"id":"gVyNS7yoDIXN"},"source":["Перейдём к оценке качества модели, которая использует наши свёртки. Видим, что она достигает f-меры 0.91, таким образом мы видим, что мы свёртки реализовали правильно, модели работает, всё отлично. Давайте подытожим. В этом семинаре мы рассмотрели, как можно применять свёрточные нейросети для обработки текстов. Мы описали базовую архитектуру — свёрточный ResNet, а также применили её в разных ситуациях для анализа контекста символов и для анализа контекста токенов. Демонстрировали мы работу свёрточной нейросети на задаче предсказания частей речи токенов. Эта задача относится к области лингвистического анализа, то есть анализа структуры текстов. Основная сложность в этой задаче, обычно, заключается в том, чтобы правильно определять часть речи для омонимов, то есть для слов, которые пишутся одинаково, но, на самом деле, имеют разные части речи. Другая сложность заключается в том, чтобы правильно определять части речи для неизвестных слов, то есть каких-нибудь неологизмов или специальной редкой лексики (научной, например). В результате семинара мы увидели, что учёт контекста токенов действительно важен в определённых случаях, хотя, чаще всего, часть речи можно определить, просто посмотрев на само слово. Модели, которые мы обучили в этом семинаре — достаточно неплохие, хотя промышленные POS тэггеры работают с гораздо более высоким качеством (на уровне 0.97 f-мер). Кроме того, мы реализовали свёрточный модуль своими руками и убедились в том, что он работает. "]},{"cell_type":"code","execution_count":32,"metadata":{"id":"I5XbiqrT-fq0"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[1m\u001b[37msnwbl                     \u001b[m  Wed Feb  9 00:28:16 2022  \u001b[1m\u001b[30m470.103.01\u001b[m\n","\u001b[36m[0]\u001b[m \u001b[34mNVIDIA GeForce RTX 3060\u001b[m |\u001b[31m 47'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m 7360\u001b[m / \u001b[33m12020\u001b[m MB | \u001b[1m\u001b[30mdmitry\u001b[m(\u001b[33m6903M\u001b[m) \u001b[1m\u001b[30mgdm\u001b[m(\u001b[33m101M\u001b[m) \u001b[1m\u001b[30mdmitry\u001b[m(\u001b[33m315M\u001b[m) \u001b[1m\u001b[30mdmitry\u001b[m(\u001b[33m24M\u001b[m)\n"]}],"source":["!gpustat"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"task3_cnn_postag.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"},"latex_envs":{"LaTeX_envs_menu_present":true,"autoclose":false,"autocomplete":true,"bibliofile":"biblio.bib","cite_by":"apalike","current_citInitial":1,"eqLabelWithNumbers":true,"eqNumInitial":1,"hotkeys":{"equation":"Ctrl-E","itemize":"Ctrl-I"},"labels_anchors":false,"latex_user_defs":false,"report_style_numbering":false,"user_envs_cfg":false},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":true}},"nbformat":4,"nbformat_minor":0}
