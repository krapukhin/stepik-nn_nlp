{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Генерация кода по вопросам со StackOverflow\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Научим нейронную сеть отвечать на вопросы про языки программирования. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Самые популярные sequence to sequence модели — это модели вида \"encoder-decorder\". Они используют RNN для того, чтобы закодировать входную последовательность в некоторый вектор. Этот вектор — представление входного предложения в некоторым заранее зафиксированном формате. Затем этот вектор декодируется второй RNN (декодером), который учится предсказывать выходную последовательность, генерируя последовательно токен за токеном. Давайте немного вспомним лекцию и освежим в памяти простой пример с машинным переводом. Перевод вопроса со StackOverflow на язык python будет проходить по концептуально такой же схеме, как и перевод с немецкого на английский, если мы говорим про использование seq2seq моделей. На картинке вы можете видеть пример перевода с помощью seq2seq модели. На вход мы подаём фразу \"gutten morgen\" (\"доброго утра\") — фразу на немецком языке. В энкодер она подается слово за словом. Кроме того, в начало предложения мы добавляем тэг \"start of sequence\" (коротко — SOS), а в конец мы добавляем токен \"end of sequence\" (EOS). В каждый момент времени, входом энкодера является текущей токен — назовём его \"x\", а также некоторое скрытое состояние — назовём его \"h\" (от слова \"hidden\"). Причём, в каждый момент времени мы подаём скрытое состояние с предыдущего шага. Выходом будет являться новое скрытое состояние. Скрытое состояние содержит в себе информацию обо всём предложении, которую сеть видела к текущему моменту. Нулевое скрытое состояние можно инициализировать нулями или использовать, например, равномерное распределение. Как только последнее слово было передано в RNN, будем использовать последнее скрытое состояние как вектор, содержащий в себе информацию обо всём предложении. Имея такой вектор, можно начинать декодировать его — генерировать выходную последовательность с помощью декодера. Давайте посмотрим на картинку — в каждый момент времени в мы подаём текущее слово и скрытое состояние с предыдущего шага. При этом, нулевое скрытое состояние декодера равно последнему скрытому состоянию энкодера. И энкодер и декодер мы можем представить как функции от x и h, то есть от текущего входного слова и скрытого состояния. В декодере на каждом шаге нам нужно предсказывать следующее слово. Для этого будем на каждом шаге пропускать текущее скрытое состояние через линейный слой и предсказывать следующее слово. После того как мы сгенерировали всю выходную последовательность, мы можем сравнить её с переводом из нашей обучающей выборки. Затем посчитаем функцию потерь и обновим веса сети, проделав в backward-шаг и посчитав градиент функции потерь.Остаётся только упомянуть о некоторых фишках, которые позволяют сделать процесс обучения декодера чуть более простым и понятным. Вспомним что такое \"teacher forcing\".[1,2] Это достаточно простая идея. Давайте в качестве некоторых токенов выходной последовательности иногда использовать \"ground truth\" из нашего датасета, а иногда — слово предсказанное нашим декодером. Таким образом, наша сеть периодически будет получать некоторую дополнительную информацию из нашей обучающей выборки. Ещё один небольшой трюк — это подход, который касается длины генерируемой последовательности. При генерации выходной последовательности не обязательно ждать, пока модель сгенерирует end-of-sequence токен. Можно, вместо этого, прекратить генерацию, когда мы выдали достаточное количество слов. Например, когда длина выходной последовательности стала примерно равна длине и входной последовательности. Это позволит нам избежать слишком долгого обучения, либо генерирования излишнего количества символов в конце нашей последовательности.  \n",
    "\n",
    "[1] Williams R. J., Zipser D. A learning algorithm for continually running fully recurrent neural networks //Neural computation. – 1989. – Т. 1. – №. 2. – С. 270-280.  \n",
    "[2] Lamb A. M. et al. Professor forcing: A new algorithm for training recurrent networks //Advances In Neural Information Processing Systems. – 2016. – С. 4601-4609."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь давайте закодируем этот алгоритм с помощью библиотек pytorch и \"torchtext\". Обучать сеть мы будем не для стандартной (и немного надоевшей) задачи машинного перевода, а для чуть более сложной задачи ответов на вопросы со StackOverflow. Итак, сначала импортируем все библиотеки, которые нам могут понадобиться (это \"torch\", \"torchtext\" и некоторые другие библиотеки). После этого задаём \"random.seed\" для воспроизводимости результатов. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Если Вы запускаете ноутбук на colab или kaggle,\n",
    "# выполните следующие строчки, чтобы подгрузить библиотеку dlnlputils:\n",
    "\n",
    "# !git clone https://github.com/Samsung-IT-Academy/stepik-dl-nlp.git && pip install -r stepik-dl-nlp/requirements.txt\n",
    "# import sys; sys.path.append('./stepik-dl-nlp')\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchtext.legacy.datasets import TranslationDataset, Multi30k\n",
    "from torchtext.legacy.data import Field, BucketIterator\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "import spacy\n",
    "\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "\n",
    "SEED = 1234\n",
    "\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Прочитаем CSV с помощью библиотеки pandas. Он лежит в папке data. Откроем файл с тестовой выборкой и посмотрим на первые три строки из неё. Мы видим, что в нашем датасете есть два поля: intent и snippet. Intent — это, собственно, вопрос со StackOverflow, а snippet — это кусочек кода, который отвечает на этот вопрос. Теперь нам нужно написать токенизаторы, которые помогут нам поделить на токены вопросы со StackOverflow и кусочек кода. Функция \"tokenize_question\" токенизирует наш вопрос — делаем это с помощью простой регулярки. Кроме того, мы отрезаем слишком длинные слова, которые, скорее всего, являются названиями веб-сайтов, либо слишком длинными названиями каких-то текстовых полей и тд. Кроме того, мы будем подавать наш вопрос в обратном порядке в нашу сеть. То есть, будем начинать с последнего слова и заканчивать первым. Функция \"tokenize_snippet\" токенизирует кусочек кода. Работает она примерно так же, с помощью чуть другой регулярки, где мы перечисляем знаки пунктуации, которые нас могут интересовать. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def tokenize_question(text):\n",
    "    \"\"\"\n",
    "    Tokenizes question from a string into a list of strings (tokens) and reverses it\n",
    "    \"\"\"\n",
    "    return list(filter(lambda x: len(x) < 16, re.findall(r\"[\\w']+\", text)[::-1]))\n",
    "\n",
    "def tokenize_snippet(text):\n",
    "    \"\"\"\n",
    "    Tokenizes code snippet into a list of operands\n",
    "    \"\"\"\n",
    "    return list(filter(lambda x: len(x) < 10, re.findall(r\"[\\w']+|[.,!?;:@~(){}\\[\\]+-/=\\\\\\'\\\"\\`]\", text)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишем обработчик входных данных с помощью библиотеки \"torchtext\". Torchtext позволяет сделать это достаточно быстро и с минимальным числом строк кода. Field позволяет нам определить, как должны обрабатываться данные. Напишем два разных обработчика для вопросов на естественном языке и для кода. Intent, то есть текстовый вопрос — это исходная последовательность, назовём её \"src\" (source), а код назовём \"trg\" (target). Field позволяет задать параметр tokenize, куда мы можем передать наши функции-токенизаторы отдельно для вопроса или для кода. В нашем примере, Field также добавит два дополнительных токена — это \"end of sequence\" и \"start of sequence\". Все токены будут приведены к нижнему регистру, а также, для вопроса, мы будем учитывать длину этого вопроса. Таким образом, \"field\" будет возвращать нам пары, а именно — вопрос и его длина. В дальнейшем это нам понадобится для обучения seq2seq модели. Далее разделим наши данные на обучающую, валидационную и тестовую выборки. Это уже сделано за нас, наша выборка поделена на 3 CSV-файла, и всё, что нам нужно — это, всего лишь, скачать эти данные с помощью, например, \"data.TabularDataset\". Данные мы собрали из следующего источника — он называется CoNaLa-corpus, это объединённый проект лаборатории из Carnegie Mellon и лаборатории со смешным названием STRUDEL. Этот датасет достаточно маленький, включает в себя всего 2.5 тысячи примеров. Мы поделили их следующим образом: 2000 на обучение, примерно 350 на валидацию и 500 на тест. Кроме того, данные с похожей тематикой можно найти, загуглив следующее сочетание слов: \"StackOverflow question code dataset\". Это датасет, намайненный автоматически со StackOverflow, с помощью \"Bi-View Hierarchical Neural Network\". Cтатья про \"bi view hierarchical neural network\" была представлена в 2018 году[1], её авторы — сотрудники университетов Огайо, Вашингтона и компании Fujitsu, и их датасет включает в себя гораздо больше данных (там есть около 150 тысяч пар вопрос и сниппет на python и около 120 тысяч пар вопросов и ответов на SQL). Для обучения мы оставили только пары из первого датасета, так как он был собран вручную, гораздо менее шумный и позволяет обучить seq2seq модели с большим качеством. Второй датасет необходимо предварительно чистить, чтобы получить гораздо более хорошее качество. Вы можете попробовать выкачать этот датасет и обучить модель с использованием большего количества данных и посмотреть на результат — посмотреть на метрики, которые вас получатся.  \n",
    "\n",
    "[1] Yao Z. et al. Staqc: A systematically mined question-code dataset from stack overflow //Proceedings of the 2018 World Wide Web Conference. – 2018. – С. 1693-1703.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выберите правильные утверждения про загрузку данных через torchtext.data.TabularDataset\n",
    "\n",
    "+Неважно, заглавными или маленькими буквами прописывать формат входных данных в поле format (оба варианта format='csv' и format='CSV' сработают)  \n",
    "+В качестве формата входных данных можно использовать CSV, TSV или JSON  \n",
    "-При использовании torchtext.data.TabularDataset.splits(...) нужно обязательно указать пути до файлов с обучающей, валидационной и тестовой выборками (параметры train, validation, test). Поделить выборку две части (train и test) нельзя  \n",
    "-Обязательными параметрами являются path, format, fields, skip_header  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchtext.legacy import data, datasets\n",
    "\n",
    "SRC = data.Field(\n",
    "    tokenize = tokenize_question, \n",
    "    init_token = '<sos>', \n",
    "    eos_token = '<eos>', \n",
    "    lower = True,\n",
    "    include_lengths = True\n",
    ")\n",
    "\n",
    "TRG = data.Field(\n",
    "    tokenize = tokenize_snippet, \n",
    "    init_token = '<sos>', \n",
    "    eos_token = '<eos>', \n",
    "    lower = True\n",
    ")\n",
    "\n",
    "fields = {\n",
    "    'intent': ('src', SRC),\n",
    "    'snippet': ('trg', TRG)\n",
    "}\n",
    "\n",
    "# Если Вы запускаете ноутбук на colab или kaggle, добавьте в начало пути ./stepik-dl-nlp\n",
    "train_data, valid_data, test_data = data.TabularDataset.splits(\n",
    "                            path = 'datasets/stackoverflow_code_generation/conala/',\n",
    "                            train = 'conala-train.csv',\n",
    "                            validation = 'conala-valid.csv',\n",
    "                            test = 'conala-test.csv',\n",
    "                            format = 'csv',\n",
    "                            fields = fields\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь сформируем словарь. Задаём максимально возможный размер слоя и минимальную встречаемость слова для того, чтобы попасть в словарь. Для вопроса мы выбираем минимальную встречаемость равную \"3\", для сниппета с кодом — \"5\". Эти числа можно вариировать и постараться подобрать такие, чтобы словарь выглядел наиболее адекватно — чтобы в нём не было мусорных слов, и чтобы, при этом, не отрезались слова, которые действительно несут некоторый смысл и помогут нам обучить более адекватную модель. Кроме того, для того, чтобы использовать паддинг, \"torchtext\" требует, чтобы все элементы в батче были отсортированы по их длине до применения паддинга, в убывающем порядке. То есть, первая последовательность должна быть самой длинной. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('a', 1285), ('in', 949), ('python', 922), ('to', 851), ('how', 633), ('of', 602), ('list', 558), ('string', 397), ('the', 328), ('from', 275), ('with', 228), ('pandas', 192), ('i', 191), ('dictionary', 162), ('get', 151), ('convert', 134), ('values', 131), ('do', 125), ('dataframe', 111), ('into', 110)]\n",
      "[(')', 3480), ('(', 3475), ('.', 2595), (',', 1899), ('[', 1122), (']', 1121), ('=', 927), (\"'\", 885), ('\\\\', 697), (':', 587), ('in', 504), ('x', 498), ('\"', 496), ('for', 450), ('1', 377), ('-', 279), ('a', 265), ('0', 259), ('/', 257), ('df', 234)]\n",
      "Уникальные токены в словаре интентов: 612\n",
      "Уникальные токены в словаре сниппетов: 395\n"
     ]
    }
   ],
   "source": [
    "SRC.build_vocab([train_data.src], max_size=25000, min_freq=3)\n",
    "print(SRC.vocab.freqs.most_common(20))\n",
    "\n",
    "\n",
    "TRG.build_vocab([train_data.trg], min_freq=5)\n",
    "print(TRG.vocab.freqs.most_common(20))\n",
    "\n",
    "print(f\"Уникальные токены в словаре интентов: {len(SRC.vocab)}\")\n",
    "print(f\"Уникальные токены в словаре сниппетов: {len(TRG.vocab)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер обучающей выборки: 2000\n",
      "Размер валидационной выборки: 379\n",
      "Размер тестовой выборки: 500\n"
     ]
    }
   ],
   "source": [
    "print(f\"Размер обучающей выборки: {len(train_data.examples)}\")\n",
    "print(f\"Размер валидационной выборки: {len(valid_data.examples)}\")\n",
    "print(f\"Размер тестовой выборки: {len(test_data.examples)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, сколько уникальных токенов в словаре интентов и в словаре сниппетов. Оказывается, что их 754 и 551 (выглядит вполне адекватно для выборки, состоящей из чуть более чем 2000 вопросно-ответных пар). Также мы можем посмотреть на размеры наших обучающей, валидационной и тестовой выборки. Последний этап нашей простой предобработки данных — это создать итераторы. Мы хотим, чтобы итератор возвращал батчи с данными, у которых есть атрибут \"src\" — это тензоры, кодирующие входные предложения (вопросы на естественном языке) и атрибут \"trg\" (target) — это тензоры, кодирующие сниппеты с кодом. Под кодированием здесь понимается простое сопоставление токена его числовому индексу. Это соответствие, собственно, и прописано в слове. Удобно, что torchtext-итераторы умеют автоматически добавлять паддинг (делать все последовательности одной длины). Мы будем использовать \"BucketIterator\" (здесь), а не обычный итератор, потому что он минимизирует количество паддинга для входных и выходных предложений, что достаточно удобно в нашей задаче.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.cuda.set_device(0)\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 2\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), \n",
    "     batch_size = BATCH_SIZE,\n",
    "     sort_within_batch = True,\n",
    "     sort_key = lambda x : len(x.src),\n",
    "     device = device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим код энкодера и декодера модели. Итак, энкодер, в нашем случае — это двухслойная LSTM. В статье, которая упоминается в начале семинара, использовалась четырёхслойная сеть, но мы попробуем сэкономить время на обучении сети и обучим двухслойную сетку. Для многослойной LSTM входная последовательность идёт в первый слой сети, а скрытое состояние первого слоя используется как входная последовательность следующего слоя. Скрытое состояние первого слоя можно представить формулой, зависящей от входных токенов и от предыдущего скрытого состояния. Напомню что, в отличие от RNN, LSTM, кроме того, что берёт на вход предыдущее скрытые состояние и возвращает следующее, ещё и принимает на вход так называемое \"cell state\". Его обычно обозначают буквой \"c\". Можно воспринимать его как другой вид скрытого состояния. В итоге, конечное представление входной последовательности в виде вектора будет конкатенацией скрытого состояния и нашего cell state, которое будем обозначать буквой \"с\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, создаём модуль \"encoder\". Он наследуется от \"torch.nn.module\" и энкодер принимает на вход следующие параметры. Это входная размерность данных — это размерности наших \"one-hot\" векторов, которая совпадает с размерностью словаря интентов; это размерность эмбеддингов, размерность слоя с эмбеддингами — например, можно сделать его равным 100 или 200, любому другому числу, которое кажется вам наиболее подходящим. Есть параметр, который называется \"encoding hidden dimension\" (вот он) — это размерность скрытого состояния; есть то же самое для декодера; и \"dropout\" — это количество дропаута, которое мы будем использовать. Здесь мы должны задать число от 0 до 1. Слой эмбеддингов создаётся с помощью \"nn.embedding\" . Дальше мы используем GRU-слой, вместо него можно с таким же успехом использовать LSTM. Дропаут будем добавлять между слоями нашей многослойной сети, то есть между скрытыми состояниями, которые идут на вход слою \"2\". Дальше — давайте рассмотрим метод \"forward\". В метод \"forward\" мы передаём входное предложение, которое превращено в dense-вектора с помощью эмбеддинг-слоя, и затем применяем дропаут (вот здесь). После того, как мы передали всю входную последовательность в RNN, она автоматически посчитает скрытое состояние по всей последовательности. Мы не передаём то, чем нужно инициализировать скрытое состояние. По дефолту тензоры инициализируются нулями, что нас вполне устраивает в этом примере. Сеть нам возвращает две вещи — это \"outputs\" и скрытый слой. Размерности каждого тензора прописаны в коде в виде комментариев, что упрощает процесс дебага и его осмысление. Ещё один параметр, который нужно упомянуть, называется \"bidirectional\". Он отвечает за то — двунаправленная или однонаправленная сеть используется нашем примере. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.input_dim = input_dim\n",
    "        self.emb_dim = emb_dim\n",
    "        self.enc_hid_dim = enc_hid_dim\n",
    "        self.dec_hid_dim = dec_hid_dim\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
    "        \n",
    "        self.rnn = nn.GRU(emb_dim, enc_hid_dim, bidirectional = True)\n",
    "        \n",
    "        self.fc = nn.Linear(enc_hid_dim * 2, dec_hid_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, src, src_len):\n",
    "        \n",
    "        #src = [src sent len, batch size]\n",
    "        #src_len = [src sent len]\n",
    "        \n",
    "        embedded = self.dropout(self.embedding(src))\n",
    "        \n",
    "        #embedded = [src sent len, batch size, emb dim]\n",
    "        \n",
    "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, src_len)\n",
    "        \n",
    "        packed_outputs, hidden = self.rnn(packed_embedded)\n",
    "                     \n",
    "        #packed_outputs is a packed sequence containing all hidden states\n",
    "        #hidden is now from the final non-padded element in the batch\n",
    "            \n",
    "        outputs, _ = nn.utils.rnn.pad_packed_sequence(packed_outputs) \n",
    "            \n",
    "        #outputs is now a non-packed sequence, all hidden states obtained\n",
    "        #  when the input is a pad token are all zeros\n",
    "            \n",
    "        #outputs = [sent len, batch size, hid dim * num directions]\n",
    "        #hidden = [n layers * num directions, batch size, hid dim]\n",
    "        \n",
    "        #hidden is stacked [forward_1, backward_1, forward_2, backward_2, ...]\n",
    "        #outputs are always from the last layer\n",
    "        \n",
    "        #hidden [-2, :, : ] is the last of the forwards RNN \n",
    "        #hidden [-1, :, : ] is the last of the backwards RNN\n",
    "        \n",
    "        #initial decoder hidden is final hidden state of the forwards and backwards \n",
    "        #  encoder RNNs fed through a linear layer\n",
    "        hidden = torch.tanh(self.fc(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1)))\n",
    "        \n",
    "        #outputs = [sent len, batch size, enc hid dim * 2]\n",
    "        #hidden = [batch size, dec hid dim]\n",
    "        \n",
    "        return outputs, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кроме того, в нашем примере мы используем attention. В этом модуле мы будем считать веса attention. В нашем примере мы будем использовать attention. На коде attention не будем останавливаться подробно, скажем лишь, что здесь мы будем использовать стандартный attention, который посчитает нам веса по нашей входной последовательности. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, enc_hid_dim, dec_hid_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.enc_hid_dim = enc_hid_dim\n",
    "        self.dec_hid_dim = dec_hid_dim\n",
    "        \n",
    "        self.attn = nn.Linear((enc_hid_dim * 2) + dec_hid_dim, dec_hid_dim)\n",
    "        self.v = nn.Parameter(torch.rand(dec_hid_dim))\n",
    "        \n",
    "    def forward(self, hidden, encoder_outputs, mask):\n",
    "        \n",
    "        #hidden = [batch size, dec hid dim]\n",
    "        #encoder_outputs = [src sent len, batch size, enc hid dim * 2]\n",
    "        #mask = [batch size, src sent len]\n",
    "        \n",
    "        batch_size = encoder_outputs.shape[1]\n",
    "        src_len = encoder_outputs.shape[0]\n",
    "        \n",
    "        #repeat encoder hidden state src_len times\n",
    "        hidden = hidden.unsqueeze(1).repeat(1, src_len, 1)\n",
    "        \n",
    "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
    "        \n",
    "        #hidden = [batch size, src sent len, dec hid dim]\n",
    "        #encoder_outputs = [batch size, src sent len, enc hid dim * 2]\n",
    "        \n",
    "        energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), dim = 2))) \n",
    "        \n",
    "        #energy = [batch size, src sent len, dec hid dim]\n",
    "                \n",
    "        energy = energy.permute(0, 2, 1)\n",
    "        \n",
    "        #energy = [batch size, dec hid dim, src sent len]\n",
    "        \n",
    "        #v = [dec hid dim]\n",
    "        \n",
    "        v = self.v.repeat(batch_size, 1).unsqueeze(1)\n",
    "        \n",
    "        #v = [batch size, 1, dec hid dim]\n",
    "            \n",
    "        attention = torch.bmm(v, energy).squeeze(1)\n",
    "        \n",
    "        #attention = [batch size, src sent len]\n",
    "        \n",
    "        attention = attention.masked_fill(mask == 0, -1e10)\n",
    "        \n",
    "        return F.softmax(attention, dim = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Архитектура декодера аналогична архитектуре энкодедра — это GRU unit, первый слой получает пару с прошлого шага и прогоняет её через нашу сеть вместе с текущим токеном, чтобы предсказать новую пару — таким образом, уравнения декодера будут очень похожи на уравнения энкодера. Затем мы прогоняем наше скрытое состояние с верхнего слоя через линейный слой, чтобы сделать предсказание следующего токена в выходном генерируемом предложении. Входные аргументы класса \"decoder\" похоже на аргументы класса \"encoder\", исключения — у нас здесь есть параметр, который называется \"output_dimension\" (это размер one-hot векторов, которые подаются на вход декодеру). Это число должно быть равно размеру словаря таргета. Forward-метод декодера принимает батч входных данных, а также скрытое состояние с предыдущего шага. Мы применяем unsqueeze к выходным токенам, чтобы добавить ещё одну размерность. Далее, аналогично энкодеру, применяем эмбеддинг-слой и дропаут. Дальше применяем attention, и потом батч с токенами передаём в RNN вместе с \"h\" и \"c\" векторами с предыдущего шага. Аналогично энкодеру, мы получаем на выходе output (это скрытое состояние с верхнего слоя нашей сети), новое скрытое состояние и новое cell состояние, то есть новые вектора \"h\" и \"c\". И мы прогоняем output (после того, как избавились от лишней размерности) через линейный слой, чтобы получить предсказание следующего слова в нашей последовательности. И возвращать здесь мы будем, собственно — output, скрытое состояние и вектор \"а\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout, attention):\n",
    "        super().__init__()\n",
    "\n",
    "        self.emb_dim = emb_dim\n",
    "        self.enc_hid_dim = enc_hid_dim\n",
    "        self.dec_hid_dim = dec_hid_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.dropout = dropout\n",
    "        self.attention = attention\n",
    "        \n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
    "        \n",
    "        self.rnn = nn.GRU((enc_hid_dim * 2) + emb_dim, dec_hid_dim)\n",
    "        \n",
    "        self.out = nn.Linear((enc_hid_dim * 2) + dec_hid_dim + emb_dim, output_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, input, hidden, encoder_outputs, mask):\n",
    "             \n",
    "        #input = [batch size]\n",
    "        #hidden = [batch size, dec hid dim]\n",
    "        #encoder_outputs = [src sent len, batch size, enc hid dim * 2]\n",
    "        #mask = [batch size, src sent len]\n",
    "        \n",
    "        input = input.unsqueeze(0)\n",
    "        \n",
    "        #input = [1, batch size]\n",
    "        \n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        \n",
    "        #embedded = [1, batch size, emb dim]\n",
    "        \n",
    "        a = self.attention(hidden, encoder_outputs, mask)\n",
    "                \n",
    "        #a = [batch size, src sent len]\n",
    "        \n",
    "        a = a.unsqueeze(1)\n",
    "        \n",
    "        #a = [batch size, 1, src sent len]\n",
    "        \n",
    "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
    "        \n",
    "        #encoder_outputs = [batch size, src sent len, enc hid dim * 2]\n",
    "        \n",
    "        weighted = torch.bmm(a, encoder_outputs)\n",
    "        \n",
    "        #weighted = [batch size, 1, enc hid dim * 2]\n",
    "        \n",
    "        weighted = weighted.permute(1, 0, 2)\n",
    "        \n",
    "        #weighted = [1, batch size, enc hid dim * 2]\n",
    "        \n",
    "        rnn_input = torch.cat((embedded, weighted), dim = 2)\n",
    "        \n",
    "        #rnn_input = [1, batch size, (enc hid dim * 2) + emb dim]\n",
    "            \n",
    "        output, hidden = self.rnn(rnn_input, hidden.unsqueeze(0))\n",
    "        \n",
    "        #output = [sent len, batch size, dec hid dim * n directions]\n",
    "        #hidden = [n layers * n directions, batch size, dec hid dim]\n",
    "        \n",
    "        #sent len, n layers and n directions will always be 1 in this decoder, therefore:\n",
    "        #output = [1, batch size, dec hid dim]\n",
    "        #hidden = [1, batch size, dec hid dim]\n",
    "        #this also means that output == hidden\n",
    "        assert (output == hidden).all()\n",
    "        \n",
    "        embedded = embedded.squeeze(0)\n",
    "        output = output.squeeze(0)\n",
    "        weighted = weighted.squeeze(0)\n",
    "        \n",
    "        output = self.out(torch.cat((output, weighted, embedded), dim = 1))\n",
    "        \n",
    "        #output = [bsz, output dim]\n",
    "        \n",
    "        return output, hidden.squeeze(0), a.squeeze(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модуль для seq2seq модели. Она будет содержать внутри себя энкодер, декодер и уметь обрабатывать входные последовательности (то есть вопросы) и выдавать сниппеты в качестве ответов. Входные параметры seq2seq модели —это энкодер, декодер, device, а также токены, с помощью которых мы кодируем паддинг, начало последовательности и конец последовательности. В этой имплементации их можно менять. Нам нужно убедиться, что количество слоёв и размерность скрытых состояний — одинакова для энкодера и декодера. Это не обязательное условие, но в противном случае (в случае разного количества слоёв) нам придётся придумывать некоторые способы это обойти. Например, если в энкодере два слоя, а в декоре один, то можно использовать оба вектора, либо можно их усреднить. \"forward\"-метод в классе seq2seq берёт на вход вопрос, сниппет с кодом и \"teacher forcing ratio\". На выход он отдаёт нам output, а также веса attention, которые мы посчитали в модуле attention. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, pad_idx, sos_idx, eos_idx, device):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.pad_idx = pad_idx\n",
    "        self.sos_idx = sos_idx\n",
    "        self.eos_idx = eos_idx\n",
    "        self.device = device\n",
    "        \n",
    "    def create_mask(self, src):\n",
    "        mask = (src != self.pad_idx).permute(1, 0)\n",
    "        return mask\n",
    "        \n",
    "    def forward(self, src, src_len, trg, teacher_forcing_ratio = 0.5):\n",
    "        \n",
    "        #src = [src sent len, batch size]\n",
    "        #src_len = [batch size]\n",
    "        #trg = [trg sent len, batch size]\n",
    "        #teacher_forcing_ratio is probability to use teacher forcing\n",
    "        #e.g. if teacher_forcing_ratio is 0.75 we use teacher forcing 75% of the time\n",
    "        \n",
    "        if trg is None:\n",
    "            assert teacher_forcing_ratio == 0, \"Must be zero during inference\"\n",
    "            inference = True\n",
    "            trg = torch.zeros((100, src.shape[1])).long().fill_(self.sos_idx).to(src.device)\n",
    "        else:\n",
    "            inference = False\n",
    "            \n",
    "        batch_size = src.shape[1]\n",
    "        max_len = trg.shape[0]\n",
    "        trg_vocab_size = self.decoder.output_dim\n",
    "        \n",
    "        #tensor to store decoder outputs\n",
    "        outputs = torch.zeros(max_len, batch_size, trg_vocab_size).to(self.device)\n",
    "        \n",
    "        #tensor to store attention\n",
    "        attentions = torch.zeros(max_len, batch_size, src.shape[0]).to(self.device)\n",
    "        \n",
    "        #encoder_outputs is all hidden states of the input sequence, back and forwards\n",
    "        #hidden is the final forward and backward hidden states, passed through a linear layer\n",
    "        encoder_outputs, hidden = self.encoder(src, src_len)\n",
    "                \n",
    "        #first input to the decoder is the <sos> tokens\n",
    "        output = trg[0,:]\n",
    "        \n",
    "        mask = self.create_mask(src)\n",
    "                \n",
    "        #mask = [batch size, src sent len]\n",
    "                \n",
    "        for t in range(1, max_len):\n",
    "            output, hidden, attention = self.decoder(output, hidden, encoder_outputs, mask)\n",
    "            outputs[t] = output\n",
    "            attentions[t] = attention\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            top1 = output.max(1)[1]\n",
    "            output = (trg[t] if teacher_force else top1)\n",
    "            if inference and output.item() == self.eos_idx:\n",
    "                return outputs[:t], attentions[:t]\n",
    "            \n",
    "        return outputs, attentions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь мы можем инициализировать модель. Как сказано ранее, входная и выходная размерность определяются размерами словарей. Сделаем так, чтобы количество слоёв у энкодера и декодера, а также размерности векторов скрытых состояний были одинаковыми. Давайте зададим размерность скрытого состояния равную \"100\", размерность для эмбеддингов — \"256\". Также зададим dropout — он будет достаточно большим (\"0.8\"). Далее мы увидим, что если ставить дропаут достаточно маленьким, то сеть будет плохо учиться и результат будет достаточно некрасивым. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = len(SRC.vocab)\n",
    "OUTPUT_DIM = len(TRG.vocab)\n",
    "ENC_EMB_DIM = 128\n",
    "DEC_EMB_DIM = 128\n",
    "ENC_HID_DIM = 100\n",
    "DEC_HID_DIM = 100\n",
    "ENC_DROPOUT = 0.8\n",
    "DEC_DROPOUT = 0.8\n",
    "PAD_IDX = SRC.vocab.stoi['<pad>']\n",
    "SOS_IDX = TRG.vocab.stoi['<sos>']\n",
    "EOS_IDX = TRG.vocab.stoi['<eos>']\n",
    "\n",
    "attn = Attention(ENC_HID_DIM, DEC_HID_DIM)\n",
    "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, ENC_DROPOUT)\n",
    "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, DEC_DROPOUT, attn)\n",
    "\n",
    "model = Seq2Seq(enc, dec, PAD_IDX, SOS_IDX, EOS_IDX, device).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь инициализируем веса для обеих моделей. В статье, которую мы пытаемся имплементировать, брали равномерное распределение от -0.08 до +0.08. Создадим функцию \"init_weights\" и добавим её в нашу модель с помощью метода apply. Равномерное распределение мы берём из nn.init.uniform (то есть, берём просто равномерное распределение из pytorch). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (embedding): Embedding(612, 128)\n",
       "    (rnn): GRU(128, 100, bidirectional=True)\n",
       "    (fc): Linear(in_features=200, out_features=100, bias=True)\n",
       "    (dropout): Dropout(p=0.8, inplace=False)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (attention): Attention(\n",
       "      (attn): Linear(in_features=300, out_features=100, bias=True)\n",
       "    )\n",
       "    (embedding): Embedding(395, 128)\n",
       "    (rnn): GRU(328, 100)\n",
       "    (out): Linear(in_features=428, out_features=395, bias=True)\n",
       "    (dropout): Dropout(p=0.8, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def init_weights(m):\n",
    "    for name, param in m.named_parameters():\n",
    "        if 'weight' in name:\n",
    "            nn.init.normal_(param.data, mean=0, std=0.01)\n",
    "        else:\n",
    "            nn.init.constant_(param.data, 0)\n",
    "            \n",
    "model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также посчитаем количество параметров, которое содержит наша модель. У нас получилось около 1 миллиона параметров — достаточно много, но замечательно, что у нас достаточно высокий процент дропаута, это поможет нам не переобучиться. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модель содержит 615,651 параметров\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'Модель содержит {count_parameters(model):,} параметров')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве оптимизатора будем использовать Adam, в качестве loss-функции — кросс энтропию. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = nn.CrossEntropyLoss(ignore_index = PAD_IDX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь мы можем написать функцию, которая задаст наш цикл обучения. Сначала мы переводим модель в training mode (с помощью model.train). Это включит dropout и батч-нормализацию (если бы она была, но, в нашем случае, мы её не используем). А потом будем итерироваться через батч-итератор. Что мы делаем на каждой итерации? На каждой итерации мы берём входное и выходное предложение из батча, вместо входного предложения мы получаем пару — \"входное предложение и его длина\" (как мы уже обсуждали ранее). Далее мы делаем zero_grad — обнуляем градиенты, посчитанные на предыдущем шаге, затем мы передаём source и target в нашу модель и получаем некоторый выход и веса attention, мы считаем градиенты с помощью \"loss backward\", предварительно посчитав функцию потерь, и дальше клипаем (clip) градиенты, делаем шаг нашим оптимизатором и считаем лосс. Замечательно, на выход наша функция будет возвращать нормализованный лосс по нашей эпохе. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion, clip):\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    \n",
    "    for i, batch in enumerate(iterator):\n",
    "        \n",
    "        src, src_len = batch.src\n",
    "        trg = batch.trg\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output, attetion = model(src, src_len.to('cpu'), trg, 0.4)\n",
    "        \n",
    "        #trg = [trg sent len, batch size]\n",
    "        #output = [trg sent len, batch size, output dim]\n",
    "        \n",
    "        output = output[1:].view(-1, output.shape[-1])\n",
    "        trg = trg[1:].view(-1)\n",
    "        \n",
    "        #trg = [(trg sent len - 1) * batch size]\n",
    "        #output = [(trg sent len - 1) * batch size, output dim]\n",
    "        \n",
    "        loss = criterion(output, trg)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также у нас есть функция, которую мы будем использовать для оценивания качества модели (для evaluate). Здесь, вначале, мы переводим нашу модель в состояние оценивания качества (это означает \"выключить dropout\", \"выключить батч-нормализацию\") и дальше проделываем примерно такие же шаги, как и в функции \"train\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for i, batch in enumerate(iterator):\n",
    "\n",
    "            src, src_len = batch.src\n",
    "            trg = batch.trg\n",
    "\n",
    "            output, attention = model(src, src_len.to('cpu'), trg, 0) #turn off teacher forcing\n",
    "\n",
    "            #trg = [trg sent len, batch size]\n",
    "            #output = [trg sent len, batch size, output dim]\n",
    "\n",
    "            output = output[1:].view(-1, output.shape[-1])\n",
    "            trg = trg[1:].view(-1)\n",
    "\n",
    "            #trg = [(trg sent len - 1) * batch size]\n",
    "            #output = [(trg sent len - 1) * batch size, output dim]\n",
    "\n",
    "            loss = criterion(output, trg)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кроме того, давайте напишем функцию, которая будет замерять время, потраченное на каждую эпоху, и назовём её \"epoch_time\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можем начать тренировать нашу модель. На каждой итерации будем печатать перплексию (увидеть разницу в перплексии гораздо проще, чем в кросс-энтропии, поскольку она по порядку больше). На каждой итерации мы будем печатать перплексию, а в конце каждой эпохи будем проверять, получила ли наша модель score лучше, чем во всех предыдущих эпохах. Если это произошло, мы обновим переменную best_valid_loss и сохраним параметры лучшей модели с помощью вызова функции state dict. Потом, когда мы будем оценивать качество моделей на тестовой выборке, загрузим параметры той модели, которая давала наилучший валидационный score (сделать мы это сможем с помощью вот этого кода - через одну ячейку).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "N_EPOCHS = 50\n",
    "CLIP = 1\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "# for epoch in range(N_EPOCHS):\n",
    "    \n",
    "#     start_time = time.time()\n",
    "    \n",
    "#     train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n",
    "#     valid_loss = evaluate(model, valid_iterator, criterion)\n",
    "    \n",
    "#     end_time = time.time()\n",
    "    \n",
    "#     epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "#     if valid_loss < best_valid_loss:\n",
    "#         best_valid_loss = valid_loss\n",
    "#         torch.save(model.state_dict(), 'models/5.5.conala_model_attention_test.pt')\n",
    "    \n",
    "#     print(f'Эпоха: {epoch+1:02} | Время: {epoch_mins}m {epoch_secs}s')\n",
    "#     print(f'Перплексия (обучение): {math.exp(train_loss):7.3f}')\n",
    "#     print(f'Перплексия (валидация): {math.exp(valid_loss):7.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На обучении наш лосс падает, на валидации — тоже. При этом, если мы посмотрим, что происходит в процессе обучения — под конец обучения лосс на валидации практически перестаёт падать и, в принципе, выходит на некоторое плато — начинает флуктуировать. Лосс на трейне всё ещё продолжает падать, но, при этом, тоже начинает немного флуктуировать.   \n",
    "Отлично, мы обучили модель, теперь мы можем посмотреть, какой лосс она даёт на тестовой выборке — он примерно равен лоссу на валидации и перплексия на тесте — выше, чем перплексия на обучении. В принципе, это достаточно ожидаемый результат. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Перплексия (валидация):  29.741\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('models/5.5.conala_model_attention_test.pt'))\n",
    "\n",
    "test_loss = evaluate(model, test_iterator, criterion)\n",
    "\n",
    "print(f'Перплексия (валидация): {math.exp(test_loss):7.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Предсказание кода по вопросу"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция, которая будет генерировать кодовый сниппет по нашему вопросу. И наконец — посмотреть, какое же качество получилось у нашей модели. Напишем функцию \"translate sentence\", которая будет по токенизированному вопросу выдавать ответ на этот вопрос на языке программирования. То есть, выдавать кодовый сниппет, который отвечает на наш вопрос. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_sentence(model, sentence):\n",
    "    model.eval()\n",
    "    tokenized = tokenize_question(sentence) \n",
    "    tokenized = ['<sos>'] + [t.lower() for t in tokenized] + ['<eos>']\n",
    "    numericalized = [SRC.vocab.stoi[t] for t in tokenized] \n",
    "    sentence_length = torch.LongTensor([len(numericalized)]).to(device) \n",
    "    tensor = torch.LongTensor(numericalized).unsqueeze(1).to(device) \n",
    "    translation_tensor_logits, attention = model(tensor, sentence_length.to('cpu'), None, 0) \n",
    "    translation_tensor = torch.argmax(translation_tensor_logits.squeeze(1), 1)\n",
    "    translation = [TRG.vocab.itos[t] for t in translation_tensor]\n",
    "    translation, attention = translation[1:], attention[1:]\n",
    "    return translation, attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция, которая будет визуализировать веса attention, то есть, мы сможем посмотреть, какие слова имеют больший вес относительно каких слов. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_attention(candidate, translation, attention):\n",
    "    \n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.add_subplot(111)\n",
    "    \n",
    "    attention = attention.squeeze(1).cpu().detach().numpy()\n",
    "    \n",
    "    cax = ax.matshow(attention, cmap='bone')\n",
    "   \n",
    "    ax.tick_params(labelsize=15)\n",
    "    ax.set_xticklabels([''] + ['<sos>'] + [t.lower() for t in tokenize_question(candidate)] + ['<eos>'], \n",
    "                       rotation=45)\n",
    "    ax.set_yticklabels([''] + translation)\n",
    "\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте возьмём 3 произвольных примера из обучающей, валидационной и тестовой выборки, и посмотрим, что у нас получилось. Мы берём пример из обучающей выборки. Вопрос звучит как \"how to convert today daytime string back to datetime object\". Ответ должен быть примерно вот таким — то есть мы должны использовать модуль \"datetime\", вызвать оттуда функцию \"strptime\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src = object datetime to back string datetime a convert to how\n",
      "trg = datetime . strptime ( '2010 - 11 - 13 10 : 33 : 54 . 227806' , ' y - m - d h : m : s . f' )\n"
     ]
    }
   ],
   "source": [
    "example_idx = 2\n",
    "\n",
    "src = ' '.join(vars(train_data.examples[example_idx])['src'])\n",
    "trg = ' '.join(vars(train_data.examples[example_idx])['trg'])\n",
    "\n",
    "print(f'src = {src}')\n",
    "print(f'trg = {trg}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наша сеть смогла предсказать, что нам нужно использовать функцию daytime.strptime, что достаточно хорошо, но, при этом, у неё в словаре нету вот этих чисел, которые, скорее всего, встретились в нашей выборке один или два раза, и поэтому не попали в наш словарь, и из-за этого наша сеть не может ничего написать в скобках функции — она не имеет в словаре вот этих символов. Достаточно ожидаемый результат. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted trg =  datetime . datetime . strptime ( <unk> ) <unk> m : m : m - m h : m : m h : m : m h : m : m h : m : <unk> h : m : <unk> h : m : <unk> h : m : <unk> ) <unk> )\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dmitry/anaconda3/envs/stpk_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:12: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  if sys.path[0] == '':\n",
      "/home/dmitry/anaconda3/envs/stpk_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "translation, attention = translate_sentence(model, src)\n",
    "\n",
    "print('predicted trg = ', ' '.join(translation))\n",
    "\n",
    "display_attention(src, translation, attention)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если мы посмотрим на матрицу attention — мы видим, что слова datetime являются ключевыми в этом вопросе, остальные слова практически никакого веса не вносят. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на какой-нибудь вопрос из валидационной и тестовой выборки. Из за валидационной мы берём вопрос \"python convert a tuple to string\" (ОК, ответ должен быть примерно таким), Выглядит достаточно странно, но, в валидационной выборке он был именно таким. При этом, эта выборка собиралась руками, так что, наверное, какая-то логика в этом есть. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src = string to tuple convert python\n",
      "trg = \" \" \" \" \" \" . join ( ( 'a' , 'b' , 'c' , 'd' , 'g' , 'x' , 'r' , 'e' ) )\n"
     ]
    }
   ],
   "source": [
    "example_idx = 8\n",
    "\n",
    "src = ' '.join(vars(valid_data.examples[example_idx])['src'])\n",
    "trg = ' '.join(vars(valid_data.examples[example_idx])['trg'])\n",
    "\n",
    "print(f'src = {src}')\n",
    "print(f'trg = {trg}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наша сеть предсказывает вот такой ответ. Он не очень логичный, и он даже синтаксически никак не согласовывается, то есть здесь закрывается круглая скобка, хотя должна бы закрыться квадратная. Так что можно считать, что это не очень хороший пример. Здесь я постаралась показать не только хорошие примеры, которые обучились плюс-минус адекватно, но и любые остальные, чтобы было видно, что, всё-таки, сеть на таком маленьком количестве данных и проучившись небольшое количество эпох обучилась неидеально. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted trg =  int ( ' , <unk> )\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dmitry/anaconda3/envs/stpk_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:12: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  if sys.path[0] == '':\n",
      "/home/dmitry/anaconda3/envs/stpk_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "translation, attention = translate_sentence(model, src)\n",
    "\n",
    "print('predicted trg = ', ' '.join(translation))\n",
    "\n",
    "display_attention(src, translation, attention)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ну и давайте посмотрим на какой-нибудь пример из тестовой выборки, например — вопрос про то, как работать с кодировками UTF-8 (кодировкой, которая помогает нам работать с русскими символами). Ответ должен быть вот таким: сначала сделать \"decode\", потом \"encode\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src = 8 utf to 1251 cp from string a convert to how\n",
      "trg = d . decode ( 'cp1251' ) . encode ( 'utf8' )\n"
     ]
    }
   ],
   "source": [
    "example_idx = 4\n",
    "\n",
    "src = ' '.join(vars(test_data.examples[example_idx])['src'])\n",
    "trg = ' '.join(vars(test_data.examples[example_idx])['trg'])\n",
    "\n",
    "print(f'src = {src}')\n",
    "print(f'trg = {trg}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наша сеть смогла предсказать decode (декодирование), но, при этом, почему-то она здесь поставила слова \"soup\". Возможно, как-то это коррелирует с библиотекой beautifulsoup и, как-то, нашей сети показалось, что это здесь будет уместно. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted trg =  print('.<unk>(')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dmitry/anaconda3/envs/stpk_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:12: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  if sys.path[0] == '':\n",
      "/home/dmitry/anaconda3/envs/stpk_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "translation, attention = translate_sentence(model, src)\n",
    "\n",
    "print('predicted trg = ', ''.join(translation))\n",
    "\n",
    "display_attention(src, translation, attention)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если мы посмотрим на матрицу attention, то и здесь важно было только слово \"UTF\" — кажется, что если говорить про декодирование то слово \"UTF\" очень хорошо связано со словом \"soup\" (видимо, это отсылка к \"beautifulsoup\") и со словом \"decode\", с остальными скобками и \"unknown token\" немного — тоже. В предыдущем примере матрица attention выглядела примерно так же, то есть — слово \"string\", которое здесь было, видимо, ключевым, по мнению нашей сети было связано достаточно плотно, практически, со всеми остальными символами в нашем примере. Но учитывая, что это не слишком удачный пример, эта матрица не несёт достаточно информации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./img/Perplexion.png\">  \n",
    "  \n",
    "+Можно использовать перплексию для сравнения двух нейросетей с разными архитектурами на одной и той же задачи (обе нейросети обучены переводить текст с языка А на язык Б)  \n",
    "+Перплексия связного текста ниже, чем перплексия произвольного набора слов  \n",
    "-Можно использовать перплексию для сравнения нейросетей с одинаковой архитектурой, где первая сеть решает задачу перевода с языка А на язык Б, а вторая с языка В на язык Г  \n",
    "-Чтобы посчитать перплексию обязательно нужен ground truth (например, написанный человеком перевод текста). Другими словами, перплексию нельзя посчитать на данных без разметки.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выводы:  \n",
    "seq2seq модели достаточно просто обучать. Можно использовать уже готовые модули из pytorch — например, GRU юниты или LSTM. Но, при этом, если мы используем недостаточно большое количество данных, либо мы учим модель недостаточно долго, либо мы подобрали неправильно параметры — например, использовали мало дропаута или наша модель переобучилась — мы не получим какого-то очень крутого результата. При этом, задача, для решения которой мы пытались здесь обучить сеть, достаточно сложная, и генерировать код по словесному описанию проблемы на естественном языке — это сложная задача, в принципе, даже для человека, не то что для нейронной сети. При этом, наша сеть научилась генерировать, в принципе, какие-то логичные ответы, то есть, зачастую, всплывают ключевые слова, которые действительно относятся к сути проблемы. Если использовать больший объём обучающих данных, а также немного поиграть с параметрами сети — наверняка, мы сможем получить гораздо более красивый результат. !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Домашнее задание №1**\n",
    "\n",
    "При обучении seq2seq модели из семинара качество работы модели оказалось не слишком хорошим. У этого есть несколько причин:\n",
    "\n",
    "Слишком маленький датасет. На 2000 пар сложно обучить хорошую модель для решения такой сложной задачи.\n",
    "Модель очень простая, есть смысл попробовать усложнить ее (использовать другие архитектуры, например, Трансформер, разобранный в предыдущих лекциях и семинарах).\n",
    "Стоит более аккуратно подбирать параметры модели. Обратите внимание на:\n",
    " Процесс построения словаря. Может быть, нужно поварьировать параметры min_freq, max_freq.\n",
    "Dropout. Есть ли смысл добавлять еще больше dropout в модель?\n",
    "Стратегия изменения learning rate в процессе обучения.\n",
    "В качестве домашнего задания мы предлагаем Вам поэкспериментировать с кодом этого семинара и улучшить качество работы модели. В репозитории курса выложены два датасета: один из них (conala, 2000 пар на обучение) был разобран видео, второй (StaQC, 50000 пар на обучение) Вам предлагается использовать в домашней работе. Для начала Вы можете проверить, помогает ли улучшить качество работы модели использование большего количества данных без каких-либо дополнительных улучшений.\n",
    "\n",
    "Опишите то, что у Вас получилось, в ответе к этому шагу.\n",
    "\n",
    "Балл за этот шаг зачитывается автоматически, вне зависимости от текста, который Вы впишете в поле ответа :)К тому же, после нажатия кнопки \"Отправить\" Вы получите доступ к ответам других участников и сможете обменяться своими находками.\n",
    "\n",
    "Успехов! :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Домашнее задание №2**\n",
    "\n",
    "Попробуйте адаптировать код из семинара для решения задачи перевода текстов с немецкого на английский язык. В качестве данных для обучения можно использовать датасет Multi30k. Скачать его можно с помощью следующего кода:\n",
    "\n",
    "from torchtext.datasets import TranslationDataset, Multi30k\n",
    "\n",
    "\n",
    "spacy_de = spacy.load('de')\n",
    "spacy_en = spacy.load('en')\n",
    "\n",
    "\n",
    "def tokenize_de(text):\n",
    "    return [tok.text for tok in spacy_de.tokenizer(text)][::-1]\n",
    "\n",
    "def tokenize_en(text):\n",
    "    return [tok.text for tok in spacy_en.tokenizer(text)]\n",
    "\n",
    "\n",
    "SRC = Field(tokenize = tokenize_de, \n",
    "            init_token = '<sos>', \n",
    "            eos_token = '<eos>', \n",
    "            lower = True)\n",
    "\n",
    "TRG = Field(tokenize = tokenize_en, \n",
    "            init_token = '<sos>', \n",
    "            eos_token = '<eos>', \n",
    "            lower = True)\n",
    "\n",
    "train_data, valid_data, test_data = Multi30k.splits(\n",
    "    exts = ('.de', '.en'), \n",
    "    fields = (SRC, TRG)\n",
    ")\n",
    "Обратите внимание, что здесь при создании SRC и TRG отсутствует параметр include_lengths. Для корректной работы с этим примером, Вам нужно будет немного изменить метод forward класса Encoder из кода семинара.\n",
    "\n",
    "Опишите то, что у Вас получилось, в ответе к этому шагу.\n",
    "\n",
    "Балл за этот шаг зачитывается автоматически, вне зависимости от текста, который Вы впишете в поле ответа :)\n",
    "\n",
    "К тому же, после нажатия кнопки \"Отправить\" Вы получите доступ к ответам других участников и сможете обменяться своими находками.\n",
    "\n",
    "Успехов! :)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
