{"cells":[{"cell_type":"markdown","metadata":{"id":"6zKzKpfTDr-P"},"source":["# Тематическая классификация длинных текстов - TFIDF и LogReg"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":119339,"status":"ok","timestamp":1640002020449,"user":{"displayName":"Дмитрий Крапухин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggc2v_CQHmxf2sl_IRluFRrUm2MTBhbfr-oOZ_PGnk=s64","userId":"11342788103765688294"},"user_tz":-180},"id":"FGKkFh6lDr-d","outputId":"1f538d00-3e50-40f1-dafc-655342181659"},"outputs":[],"source":["# Если Вы запускаете ноутбук на colab или kaggle,\n","# выполните следующие строчки, чтобы подгрузить библиотеку dlnlputils:\n","\n","# !git clone https://github.com/Samsung-IT-Academy/stepik-dl-nlp.git && pip install -r stepik-dl-nlp/requirements.txt\n","# import sys; sys.path.append('./stepik-dl-nlp')\n","\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","from sklearn.datasets import fetch_20newsgroups\n","from sklearn.metrics import accuracy_score\n","\n","import numpy as np\n","\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","import collections\n","\n","import torch\n","from torch import nn\n","from torch.nn import functional as F\n","\n","import dlnlputils\n","from dlnlputils.data import tokenize_text_simple_regex, tokenize_corpus, build_vocabulary, \\\n","    vectorize_texts, SparseFeaturesDataset\n","from dlnlputils.pipeline import train_eval_loop, predict_with_model, init_random_seed\n","\n","init_random_seed()"]},{"cell_type":"markdown","metadata":{"id":"gmstRNTMDr_D"},"source":["## Предобработка текстов и подготовка признаков"]},{"cell_type":"code","execution_count":2,"metadata":{"ExecuteTime":{"end_time":"2019-09-12T12:42:57.847399Z","start_time":"2019-09-12T12:42:57.268037Z"},"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":115806,"status":"ok","timestamp":1608394466477,"user":{"displayName":"Дмитрий Крапухин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggc2v_CQHmxf2sl_IRluFRrUm2MTBhbfr-oOZ_PGnk=s64","userId":"11342788103765688294"},"user_tz":-180},"id":"rBfnLd1tDr_F","outputId":"320aadfc-c56f-4392-947a-e485230702a9"},"outputs":[{"name":"stdout","output_type":"stream","text":["Количество обучающих текстов 11314\n","Количество тестовых текстов 7532\n","\n","From: lerxst@wam.umd.edu (where's my thing)\n","Subject: WHAT car is this!?\n","Nntp-Posting-Host: rac3.wam.umd.edu\n","Organization: University of Maryland, College Park\n","Lines: 15\n","\n"," I was wondering if anyone out there could enlighten me on this car I saw\n","the other day. It was a 2-door sports car, looked to be from the late 60s/\n","early 70s. It was called a Bricklin. The doors were really small. In addition,\n","the front bumper was separate from the rest of the body. This is \n","all I know. If anyone can tellme a model name, engine specs, years\n","of production, where this car is made, history, or whatever info you\n","have on this funky looking car, please e-mail.\n","\n","Thanks,\n","- IL\n","   ---- brought to you by your neighborhood Lerxst ----\n","\n","Метка 7\n"]}],"source":["train_source = fetch_20newsgroups(subset='train')\n","test_source = fetch_20newsgroups(subset='test')\n","\n","print('Количество обучающих текстов', len(train_source['data']))\n","print('Количество тестовых текстов', len(test_source['data']))\n","print()\n","print(train_source['data'][0].strip())\n","\n","print()\n","print('Метка', train_source['target'][0]) # класс число от 0до19 т.к. 20 классов"]},{"cell_type":"markdown","metadata":{"id":"_UPeLHrsDr_R"},"source":["### Подготовка признаков"]},{"cell_type":"code","execution_count":3,"metadata":{"ExecuteTime":{"end_time":"2019-09-12T12:43:00.294422Z","start_time":"2019-09-12T12:42:57.849386Z"},"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":118141,"status":"ok","timestamp":1608394468856,"user":{"displayName":"Дмитрий Крапухин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggc2v_CQHmxf2sl_IRluFRrUm2MTBhbfr-oOZ_PGnk=s64","userId":"11342788103765688294"},"user_tz":-180},"id":"Hv-999nCDr_T","outputId":"6e8b5288-8b92-49d3-ddfc-cd1c98db9c36"},"outputs":[{"name":"stdout","output_type":"stream","text":["from lerxst where thing subject what this nntp posting host rac3 organization university maryland college park lines wondering anyone there could enlighten this other door sports looked from late early called bricklin doors were really small addition front bumper separate from rest body this know anyone tellme model name engine specs years production where this made history whatever info have this funky looking please mail thanks brought your neighborhood lerxst\n"]}],"source":["# Строки - тексты, столбцы - признаки. Две матрицы. Токенизируем\n","# токенайзер все слова и цифры (регуляркой) длиннее 4 символов \n","# переводит в нижний регистр. Принимает строку, отдает список токенов\n","train_tokenized = tokenize_corpus(train_source['data'])\n","test_tokenized = tokenize_corpus(test_source['data'])\n","\n","print(' '.join(train_tokenized[0]))"]},{"cell_type":"markdown","metadata":{"id":"Bdk2R2IaMGv9"},"source":["Делаем словарь (только по обучающей подвыборке). Нумеруем токены  \n","\n","build_vocabulary принимает на вход список списков. Внешний список - датасет, а внутренниие списки - отдельные документы и элементы внутренних списков - это токены в строковом виде.\n","1. Считаем частоты токенов (через defaultdict)\n","2. Удаляем очень редкие и очень частые токены\n","3. Сортируем токены по убыванию частоты, т.е. наиболее часто встречающиеся токены получили наименьшие идентификаторы. Добавляем в список токенов фиктивный токен (В начало), он получит идентификатор 0. \n","4. Слов может быть очень много поэтому оставляем только конкретное количество слов\n","5. Нумеруем слова по порядку сортировки частоты, строим словарь  \n","Функция возвращает этот словарь и еще вектор весов, содержащий относительные частоты всех токенов в датасете. Пригодится на этапе формирования матрицы признаков"]},{"cell_type":"code","execution_count":4,"metadata":{"ExecuteTime":{"end_time":"2019-09-12T12:43:00.825372Z","start_time":"2019-09-12T12:43:00.297392Z"},"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":118407,"status":"ok","timestamp":1608394469181,"user":{"displayName":"Дмитрий Крапухин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggc2v_CQHmxf2sl_IRluFRrUm2MTBhbfr-oOZ_PGnk=s64","userId":"11342788103765688294"},"user_tz":-180},"id":"D9V3MAmpDr_a","outputId":"60e29470-b294-4e97-c0bb-0f67f1ff7507"},"outputs":[{"name":"stdout","output_type":"stream","text":["Количество уникальных токенов 21628\n","[('that', 0), ('this', 1), ('have', 2), ('with', 3), ('writes', 4), ('article', 5), ('posting', 6), ('host', 7), ('nntp', 8), ('there', 9)]\n"]}],"source":["MAX_DF = 0.8 # токены из более чем 80% документов выкидываем\n","MIN_COUNT = 5 # слова встретившиеся менее 5 раз выкидываем\n","vocabulary, word_doc_freq = build_vocabulary(train_tokenized, max_doc_freq=MAX_DF, min_count=MIN_COUNT)\n","UNIQUE_WORDS_N = len(vocabulary)\n","print('Количество уникальных токенов', UNIQUE_WORDS_N)\n","print(list(vocabulary.items())[:10]) # 10 самых частотных токенов\n","# 20к токенов всего. "]},{"cell_type":"code","execution_count":5,"metadata":{"ExecuteTime":{"end_time":"2019-09-12T12:43:01.524600Z","start_time":"2019-09-12T12:43:00.829107Z"},"colab":{"base_uri":"https://localhost:8080/","height":281},"executionInfo":{"elapsed":119199,"status":"ok","timestamp":1608394470030,"user":{"displayName":"Дмитрий Крапухин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggc2v_CQHmxf2sl_IRluFRrUm2MTBhbfr-oOZ_PGnk=s64","userId":"11342788103765688294"},"user_tz":-180},"id":"eQPHhk9vDr_k","outputId":"f5195cc8-3329-4069-8af7-274b2af41c95"},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["# Проверяем закон Ципфа\n","plt.hist(word_doc_freq, bins=20)\n","plt.title('Распределение относительных частот слов')\n","plt.yscale('log');"]},{"cell_type":"markdown","metadata":{"id":"Xw9fvK8ZOr93"},"source":["Токенов, которые встретились хотя бы в половине документов обучающей выборки — очень мало. Токенов, которые встретились хотя бы в 10% обучающей выборки — больше, порядка нескольких сотен. Мода  распределения находится около нуля, то есть большая часть слов (порядка 10000 уникальных токенов) встречаются менее, чем в 5% процентах документов. Закон Ципфа выполняется.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"I1FKVmAfbu5v"},"source":["Строим матрицу признаков.  \n","Vectorize_texts - принимает 3 параметра: список токенизированных текстов (список списков строк), словарь (то есть, отображение из строк в числа) из токенов в их идентификаторы или в их номера, а также вектор, содержащий действительные числа и описывающий относительные частоты токенов. Функция принимает ещё два параметра — именно, это алгоритм взвешивания токенов по частоте (по умолчанию выбран TF-IDF), а также флаг, который говорит, нужно ли перемасштабировать данные после вTкторизации, или не нужно. Сначала мы проверяем, что нам передали режим, с которым мы умеем работать. Далее мы строим прямоугольную матрицу, в которой количество строк соответствует количеству текстов, а количество столбцов соответствует количеству уникальных токенов. Эта матрица будет содержать счётчики: сколько каждый токен встретился в каждом документе. У нас очень мало частых слов — более того, мы их специально выкинули, — матрица счётчиков будет крайне разреженная. Мы можем использовать разреженные матрицы из библиотеки scipy. Разреженные матрицы хранят только ненулевые элементы. Алгоритм подсчёта предельно прост — мы идём по всем текстам, по всем токенам в каждом тексте, и если токен есть в словаре, то мы увеличиваем на единичку соответствующую ячейку матрицы. Если мы получили какой-то неизвестный токен, то, возможно, нам дали либо новые тексты, которых не было в обучающей выборке, либо этот токен был в обучающей выборке, но мы его отфильтровали по частоте. Далее мы реализуем процедуру взвешивания. По умолчанию, в этой функции реализовано 4 алгоритма взвешивания. Первый алгоритм — это бинарные вектора. Этот алгоритм приводит к тому, что матрица весов будет содержать единичку, если токен хотя бы один раз встретился в документе, и нолик, если токена в документе не было. Следующий алгоритм — это относительные частоты слов в документе — TF (term frequency). В этом алгоритме мы сначала преобразовываем матрицу в другой формат разреженных матриц[2]. Формат CSR обеспечивает эффективные операции над строками матриц, но крайне неэффективен для операций над столбцами. Часто выгоднее несколько раз конвертировать матрицу (сначала в один формат, сделать операцию, конвертировать в другой, сделал другую операцию...), чем делать операцию в неподходящем для неё формате. Итак, мы конвертируем в разреженную матрицу для строк и делим каждый счётчик в каждой строке на сумму элементов в этой строке — по сути, мы делим количество употреблений токена в документе на длину этого документа, то есть мы получаем относительную частоту токена в документе. Следующий режим — это IDF (inverse document frequency). Этот алгоритм взвешивания приводит к тому, что, в результирующей матрице признаков, убирается вся информация о частоте токена в документе. Но в этой матрице есть информация о частоте токена в корпусе. Здесь мы сначала получаем матрицу индикаторов (есть ли токен документе, или нет), а затем домножаем индикаторы на вектор весов слов, который мы вычислили на этапе построения словаря. Функция \"multiply\" реализует операцию поэлементного произведения.[1] Следующий алгоритм объединяет предыдущие два — здесь мы сначала находим TF для каждого токена, а затем домножаем TF на IDF. Всё просто. Ну, и напоследок — мы масштабируем датасет так, чтобы все элементы матрицы укладывались в диапазон от нуля до единицы. Стандартизация входных весов необходима для стабильной работы многих алгоритмов машинного обучения. Способ стандартизации весов зависит от природы данных. Часто используется приведение к нормальному распределению с мат.ожиданием в нуле и единичной дисперсией. Но такой подход нам здесь не подходи.. Потому что у нас матрица разреженная, и если мы сдвинем эту матрицу на её мат.ожидание, то мы получим не разреженную матрицу, и, скорее всего, она у нас для нормального датасета даже в память не влезет. Поэтому мы используем другой способ стандартизации, а именно мин-макс-стандартизацию, то есть мы говорим, что минимально допустимое значение признака в датасете — это 0, а максимально допустимое — это 1. Ну, и напоследок, мы переводим нашу разреженную матрицу в формат, ориентированный на эффективную работу со строками, потому, что алгоритмы машинного обучения, которые мы далее будем использовать, читают документы один за другим и настраивают свои веса, то есть нам нужно уметь эффективно брать отдельный документ. Давайте, например, будем использовать алгоритм TF-IDF. Обращаю ваше внимание, что для векторизации и обучающей, и тестовой выборки, используется один и тот же набор параметров, то есть один и тот же словарь, один и тот же вектор частот и один и тот же режим векторизации."]},{"cell_type":"code","execution_count":6,"metadata":{"ExecuteTime":{"end_time":"2019-09-12T12:44:16.094816Z","start_time":"2019-09-12T12:43:01.526554Z"},"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":198201,"status":"ok","timestamp":1608394549087,"user":{"displayName":"Дмитрий Крапухин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggc2v_CQHmxf2sl_IRluFRrUm2MTBhbfr-oOZ_PGnk=s64","userId":"11342788103765688294"},"user_tz":-180},"id":"yWn7FuuTDr_y","outputId":"a49d2b2f-8ce4-4214-f396-eeea4b00d4a0"},"outputs":[{"name":"stdout","output_type":"stream","text":["Размерность матрицы признаков обучающей выборки (11314, 21628)\n","Размерность матрицы признаков тестовой выборки (7532, 21628)\n","\n","Количество ненулевых элементов в обучающей выборке 1126792\n","Процент заполненности матрицы признаков 0.46%\n","\n","Количество ненулевых элементов в тестовой выборке 721529\n","Процент заполненности матрицы признаков 0.44%\n"]}],"source":["VECTORIZATION_MODE = 'tfidf'\n","train_vectors = vectorize_texts(train_tokenized, vocabulary, word_doc_freq, mode=VECTORIZATION_MODE)\n","test_vectors = vectorize_texts(test_tokenized, vocabulary, word_doc_freq, mode=VECTORIZATION_MODE)\n","\n","print('Размерность матрицы признаков обучающей выборки', train_vectors.shape)\n","print('Размерность матрицы признаков тестовой выборки', test_vectors.shape)\n","print()\n","print('Количество ненулевых элементов в обучающей выборке', train_vectors.nnz)\n","print('Процент заполненности матрицы признаков {:.2f}%'.format(train_vectors.nnz * 100 / (train_vectors.shape[0] * train_vectors.shape[1])))\n","print()\n","print('Количество ненулевых элементов в тестовой выборке', test_vectors.nnz)\n","print('Процент заполненности матрицы признаков {:.2f}%'.format(test_vectors.nnz * 100 / (test_vectors.shape[0] * test_vectors.shape[1])))"]},{"cell_type":"markdown","metadata":{"id":"MV3V8alAgHZV"},"source":["Давайте посмотрим на характеристики матрицы, которые у нас получились. Количество строк в этих матрицах соответствует количеству примеров в обучающей и в тестовой выборке соответственно, а количество столбцов соответствует количеству уникальных токенов, то есть размеру словаря. А ещё на экране вы видите процент заполненности матриц. Для того, чтобы посчитать, мы взяли количество ненулевых элементов и поделили на полный размер матрицы, то есть на произведение количества строк и количества столбцов. Как видите, в этих матрицах заполнено меньше 0.5% элементов, то есть, используя разреженные матрицы, мы экономим гигантское количество памяти. Давайте, для интереса, посмотрим — как же значения этой матрицы распределены. В принципе, здесь также выполняется закон Ципфа. \n","\n"]},{"cell_type":"code","execution_count":7,"metadata":{"ExecuteTime":{"end_time":"2019-09-12T12:44:16.857114Z","start_time":"2019-09-12T12:44:16.098773Z"},"colab":{"base_uri":"https://localhost:8080/","height":281},"executionInfo":{"elapsed":198878,"status":"ok","timestamp":1608394549837,"user":{"displayName":"Дмитрий Крапухин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggc2v_CQHmxf2sl_IRluFRrUm2MTBhbfr-oOZ_PGnk=s64","userId":"11342788103765688294"},"user_tz":-180},"id":"RTjsGGpBDsAo","outputId":"89004c51-0a43-4535-e983-099d7dbe07a7"},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["plt.hist(train_vectors.data, bins=20)\n","plt.title('Распределение весов признаков')\n","plt.yscale('log');"]},{"cell_type":"markdown","metadata":{"id":"qLIPygAkgPtA"},"source":["Все значения матрицы лежат строго в диапазоне от нуля до единицы — то чего мы и хотели получить. Давайте теперь проанализируем распределение классов в нашем датасете. "]},{"cell_type":"markdown","metadata":{"id":"7j_bTieFDsAu"},"source":["### Распределение классов"]},{"cell_type":"code","execution_count":8,"metadata":{"ExecuteTime":{"end_time":"2019-09-12T12:44:16.864960Z","start_time":"2019-09-12T12:44:16.859476Z"},"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":198843,"status":"ok","timestamp":1608394549847,"user":{"displayName":"Дмитрий Крапухин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggc2v_CQHmxf2sl_IRluFRrUm2MTBhbfr-oOZ_PGnk=s64","userId":"11342788103765688294"},"user_tz":-180},"id":"SDKobYEmDsAy","outputId":"e40f70a1-36fa-40a0-e116-0c59661ab28f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Количество уникальных меток 20\n"]}],"source":["UNIQUE_LABELS_N = len(set(train_source['target']))\n","print('Количество уникальных меток', UNIQUE_LABELS_N)"]},{"cell_type":"code","execution_count":9,"metadata":{"ExecuteTime":{"end_time":"2019-09-12T12:44:17.106036Z","start_time":"2019-09-12T12:44:16.867310Z"},"colab":{"base_uri":"https://localhost:8080/","height":281},"executionInfo":{"elapsed":198810,"status":"ok","timestamp":1608394549861,"user":{"displayName":"Дмитрий Крапухин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggc2v_CQHmxf2sl_IRluFRrUm2MTBhbfr-oOZ_PGnk=s64","userId":"11342788103765688294"},"user_tz":-180},"id":"I5yEzmeiDsA3","outputId":"cc54002d-e9e0-441b-9088-469b15319aa6"},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["plt.hist(train_source['target'], bins=np.arange(0, 21))\n","plt.title('Распределение меток в обучающей выборке');"]},{"cell_type":"markdown","metadata":{"id":"VxTwt-k2gZ-1"},"source":["У нас всего 20 классов - классы распределены практически равномерно в обучающей выборке. Да и в тестовой — тоже равномерно. Поэтому, так как классы распределены почти равномерно, мы можем использовать accuracy (или долю правильных предсказаний) как рабочую метрику. Если бы распределение классов было скошенным, эта метрика было бы уже неподходящей, она бы давала сильно завышенные оценки."]},{"cell_type":"code","execution_count":10,"metadata":{"ExecuteTime":{"end_time":"2019-09-12T12:44:17.312198Z","start_time":"2019-09-12T12:44:17.109884Z"},"colab":{"base_uri":"https://localhost:8080/","height":281},"executionInfo":{"elapsed":199215,"status":"ok","timestamp":1608394550317,"user":{"displayName":"Дмитрий Крапухин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggc2v_CQHmxf2sl_IRluFRrUm2MTBhbfr-oOZ_PGnk=s64","userId":"11342788103765688294"},"user_tz":-180},"id":"6ECoeQAaDsA7","outputId":"600e384f-8b92-47af-a581-86c7627b2d15","scrolled":true},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["plt.hist(test_source['target'], bins=np.arange(0, 21))\n","plt.title('Распределение меток в тестовой выборке');"]},{"cell_type":"markdown","metadata":{"id":"mnNsY0F8DsA_"},"source":["### PyTorch Dataset\n","\n","Прежде чем обучить модельку, сначала мы обернём наши матрицы признаков в \"Dataset\" — это специальная идиома в pytorch, которая призвана повысить удобство подключения различных датасетов, которые могут подгружаться с жёсткого диска, из памяти; загружаться сразу все — в память, или читаться по чуть-чуть. Здесь мы используем \"SparseFeaturesDataset\". Давайте посмотрим, как он работает. Вот он — это очень простой класс, который принимает на вход в конструктор две матрицы — это матрица признаков, которая разрежена, и матрица меток. По контракту, Dataset должен реализовывать два метода — первый метод \"len\", он должен возвращать длину датасета, то есть количество примеров в нём, и второй — метод \"get item\", он должен возвращать один обучающий пример, то есть, в случае нашего семинара — это вектор признаков и метка. Предлагаю вам обратить внимание на то, что \"features\" — это разреженная матрица, а pytorch не умеет работать с разреженными матрицами. Но, с другой стороны, мы не хотим конвертировать всю матрицу обучающего датасета в плотное представление, потому что у нас памяти не хватит. Поэтому мы храним весь dataset в разреженном виде, но, когда нам нужно выбрать один пример из датасета, мы выбираем только его из разреженной матрицы, конвертируем в плотное представление и заворачиваем в \"torch.Tensor\". Аналогично поступаем и с метками."]},{"cell_type":"code","execution_count":11,"metadata":{"ExecuteTime":{"end_time":"2019-09-12T12:44:17.319292Z","start_time":"2019-09-12T12:44:17.315074Z"},"id":"MilS0d7wDsBA"},"outputs":[],"source":["train_dataset = SparseFeaturesDataset(train_vectors, train_source['target'])\n","test_dataset = SparseFeaturesDataset(test_vectors, test_source['target'])"]},{"cell_type":"markdown","metadata":{"id":"tbX-iUn8DsBH"},"source":["## Обучение модели на PyTorch\n","\n","Наша модель — это логистическая регрессия. Логистическая регрессия — это линейная регрессия, выход который сжимается в диапазон от нуля до единицы с помощью логистической функции, то есть сигмоиды. Таким образом, сама модель состоит всего лишь из одного слоя — это линейный слой, у которого количество входов соответствует количеству уникальных токенов, то есть размеру словаря, и количество выходов соответствует количеству меток в датасете. Эту нашу модель мы обучаем с помощью функции \"train_eval_loop\", которая реализует цикл обучения нейросети. Это функция общего назначения, сюда можно подавать модели не только для классификации, не только текстов, в ней реализованы некоторые стандартные фишки, которые используются при обучении нейросетей. Давайте посмотрим, как она работает. Эта функция принимает целую кучу параметров, но среди этих параметров есть четыре главных — это экземпляр нашей модели, это обучающий датасет, валидационный датасет и наша функция потерь, то есть критерий, минимизируя значение которого мы будем настраивать параметры нашей модели. Что делают остальные параметры — предлагаю пока не рассматривать. Сначала мы переносим нашу модель на то устройство, на котором мы будем производить вычисления — это может быть центральный процессор, либо видеокарта. Затем мы создаём оптимизатор, то есть — говорим, как именно мы должны делать градиентный шаг на каждой итерации. Затем, опционально, мы настраиваем расписание изменения скорости обучения. Менять длину градиентного шага в процессе обучения — это часто хорошая идея, которая приводит к получению лучших значений метрик и функции потерь. Затем мы берём наши Dataset-ы, которые умеют возвращать обучающий пример по индексу (как мы только что рассмотрели), и передаём эти \"Dataset\" в \"DataLoader\" — это объект из pytorch, который умеет в многопоточном режиме собирать батчи примеров. В этом семинаре многопоточный режим нам, в принципе, не нужен, но, в общем случае (и в дальнейших семинарах) он вам может пригодиться. Основной смысл использования многопоточного режима — в том, чтобы всегда загружать видеокарты на 100% — таким образом, максимально быстро учить. Далее мы определяем набор переменных, которые позволят нам, в ходе обучения, выбрать лучшую модель. То есть, процесс обучения — стохастический, и модель может как улучшаться в ходе обучения, так и ухудшаться, и не всегда нужно брать последнюю модель. Хорошая практика для выбора лучшей модели в процессе обучения заключается в том, чтобы иметь отложенную выборку, состоящую из некоторого количества примеров, не входящих в обучающих выборку. И, после некоторого количества шагов по обучающей выборке, оценивать качество модели на валидационной выборке (то есть на этой отложенной выборке) и сравнивать качество моделей именно по значениям метрик, вычисленных на отложенной выборке. Далее начинается цикл — обучение состоит из нескольких эпох. Эпоха, в данном случае, носит условный характер — это некоторое количество градиентных шагов. Не обязательно эпоха — это полный проход по датасету. Наша эпоха начинается с того, что мы переводим модель в режим обучения. В данном семинаре это не так важно, но если в нашей нейросети есть такие модули, как dropout или batch norm, критически важно не забывать переводить модель в режим обучения или в режим применения. Далее идёт цикл, реализующий одну эпоху обучения. Мы делаем заданное количество градиентных шагов по обучающей выборке, на каждом шаге мы берём батч примеров — DataLoader нам возвращает уже не отдельные примеры, а целые пачки примеров. Таким образом, в настоящем семинаре, переменная \"batch_x\" — это прямоугольная матрица, в которой количество строк равно количеству примеров в батче, то есть размеру батча, а количество столбцов — это количество признаков. Мы копируем данные на то же, устройство на котором была и модель, выполняем прямой проход по модели, получаем предсказания, находим значение критерия (то есть значение функции потерь), очищаем оценки градиента с предыдущего шага, находим новое значение градиентов, и делаем градиентный шаг. Также мы запоминаем среднее значение функции потерь на эпохе. Это полезно для мониторинга процесса обучения."]},{"cell_type":"markdown","metadata":{"id":"raS58cZ0iJd3"},"source":["По характеру изменения функции потерь от эпохи к эпохе мы иногда можем понять, что не так с процессом обучения, мы можем увидеть, что модель вообще не сходится или — она очень быстро достигает определённой точки и дальше не учится, или значение функции потерь изменяется практически случайно, с большой дисперсией. Это важный диагностический показатель. Далее мы выводим некоторую полезную информацию, которая говорит нам о том, как именно идёт процесс обучения. Теперь оценим качество модели, переводим модель в режим \"eval\" (то есть, в режим предсказания) и объявляем переменные для оценки среднего значения функции потерь на отложенной выборке. Далее мы повторяем практически те же самые действия, что и делали при обучении, но не делаем сам градиентный шаг — мы только получаем предсказание модели и оцениваем значение функции потерь. Важный момент, который позволит сэкономить память на видеокарте — это включить режим \"torch no_grad\". Когда этот режим включён, pytorch не сохраняет промежуточные данные, необходимые для вычисления градиентов. Далее мы сравниваем среднее значение функции потерь на валидации на последней эпохе и лучшее значение функции потерь, полученное аналогичным образом на предыдущих эпохах, и если новое среднее значение функции потерь — лучше, то мы сохраняем текущий вариант модели. Мы делаем это с помощью стандартной функции \"copy.deepcopy()\". А если улучшить значение функции потерь на отложенной выборке после этой эпохи не получилось, то мы проверяем — а как давно у нас вообще получалось улучшить модель? Если с последней хорошей эпохи прошло уже больше заданного количества эпох, то мы говорим — \"ну кажется приехали — кажется, дальше улучшить модель не получится\". И, в таком случае, мы прекращаем обучение. Ну, и напоследок — если пользователь задал расписание изменения скорости обучения, то мы обновляем скорость обучения с учётом нового значения функции потерь. Тело этого цикла мы обернули в try-except и добавили обработку двух видов исключений. Первое — это \"interrupt\", то есть — чтобы пользователь мог досрочно остановить обучение, нажав \"Ctrl-C\" в Jupyter ноутбуке. И второй обработчик ловит вообще все исключения и печатает их в удобоваримой виде. Вот и всё — наша функция возвращает два объекта. Первый — это лучшее значение функции потерь, а второй объект — это модель с лучшими весами, то есть это веса модели, которые получились после лучшей эпохи (не обязательно, эта эпоха — последняя). "]},{"cell_type":"markdown","metadata":{"id":"AcYniMsiiiBo"},"source":["Во-первых, будем менять длину градиентного шага тогда, когда в течение пяти эпох значение функции потерь на валидации не улучшилось. То есть, если у нас функция потерь вышла на плато,то уменьшаем размер шага, и иногда это позволяет спуститься в более узкие локальные минимумы, которые мы, в противном случае, перепрыгивали бы, и ещё чуть-чуть улучшить значение функции потерь, но это не всегда даёт прирост. В качестве функции потерь мы используем функцию CrossEntropy — это функция из pytorch, она реализует категориальную кросс-энтропию вместе с сигмоидой. Это позволяет нам убрать сигмоиду из самой модели и сделать процесс вычислений чуть более численно стабильным, то есть избежать слишком больших чисел или слишком маленьких. Это должно положительно сказаться на точности вычислений. А также мы задаём здесь длину градиентного шага по умолчанию (то есть \"learning rate\") как 0.1, говорим, что — максимум, мы будем делать 200 проходов по датасету, то есть 200 эпох, размер батча — это 32, в общем-то и всё. Давайте посмотрим, как оно у нас всё учится. "]},{"cell_type":"code","execution_count":12,"metadata":{"ExecuteTime":{"end_time":"2019-09-12T12:46:22.371272Z","start_time":"2019-09-12T12:44:17.322178Z"},"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":439132,"status":"ok","timestamp":1608394790308,"user":{"displayName":"Дмитрий Крапухин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggc2v_CQHmxf2sl_IRluFRrUm2MTBhbfr-oOZ_PGnk=s64","userId":"11342788103765688294"},"user_tz":-180},"id":"siIUyBMADsBT","outputId":"54d024cd-8e48-4f72-c666-b4101bc7205c","scrolled":false},"outputs":[{"name":"stdout","output_type":"stream","text":["Эпоха 0\n","Эпоха: 354 итераций, 1.21 сек\n","Среднее значение функции потерь на обучении 2.2252603193460883\n","Среднее значение функции потерь на валидации 2.1137116389759516\n","Новая лучшая модель!\n","\n","Эпоха 1\n","Эпоха: 354 итераций, 0.80 сек\n","Среднее значение функции потерь на обучении 0.9165930989603538\n","Среднее значение функции потерь на валидации 1.6822081627482075\n","Новая лучшая модель!\n","\n","Эпоха 2\n","Эпоха: 354 итераций, 0.84 сек\n","Среднее значение функции потерь на обучении 0.46601720162704163\n","Среднее значение функции потерь на валидации 1.4644031009431613\n","Новая лучшая модель!\n","\n","Эпоха 3\n","Эпоха: 354 итераций, 0.82 сек\n","Среднее значение функции потерь на обучении 0.2836355813226457\n","Среднее значение функции потерь на валидации 1.3450514989889275\n","Новая лучшая модель!\n","\n","Эпоха 4\n","Эпоха: 354 итераций, 0.75 сек\n","Среднее значение функции потерь на обучении 0.19072482339238042\n","Среднее значение функции потерь на валидации 1.2602526944572643\n","Новая лучшая модель!\n","\n","Эпоха 5\n","Эпоха: 354 итераций, 0.79 сек\n","Среднее значение функции потерь на обучении 0.136434181693331\n","Среднее значение функции потерь на валидации 1.2005530964520017\n","Новая лучшая модель!\n","\n","Эпоха 6\n","Эпоха: 354 итераций, 0.74 сек\n","Среднее значение функции потерь на обучении 0.10175144308283504\n","Среднее значение функции потерь на валидации 1.1543886633747715\n","Новая лучшая модель!\n","\n","Эпоха 7\n","Эпоха: 354 итераций, 0.78 сек\n","Среднее значение функции потерь на обучении 0.07793638799444767\n","Среднее значение функции потерь на валидации 1.1209757128509426\n","Новая лучшая модель!\n","\n","Эпоха 8\n","Эпоха: 354 итераций, 0.72 сек\n","Среднее значение функции потерь на обучении 0.06176925028574332\n","Среднее значение функции потерь на валидации 1.0886761942657375\n","Новая лучшая модель!\n","\n","Эпоха 9\n","Эпоха: 354 итераций, 0.72 сек\n","Среднее значение функции потерь на обучении 0.04921779004951655\n","Среднее значение функции потерь на валидации 1.0575872033329334\n","Новая лучшая модель!\n","\n","Эпоха 10\n","Эпоха: 354 итераций, 0.73 сек\n","Среднее значение функции потерь на обучении 0.04008679809101389\n","Среднее значение функции потерь на валидации 1.0522329764345946\n","Новая лучшая модель!\n","\n","Эпоха 11\n","Эпоха: 354 итераций, 0.73 сек\n","Среднее значение функции потерь на обучении 0.03305460212983738\n","Среднее значение функции потерь на валидации 1.0252166978888593\n","Новая лучшая модель!\n","\n","Эпоха 12\n","Эпоха: 354 итераций, 0.73 сек\n","Среднее значение функции потерь на обучении 0.027422167195038774\n","Среднее значение функции потерь на валидации 1.0234042292429228\n","Новая лучшая модель!\n","\n","Эпоха 13\n","Эпоха: 354 итераций, 0.75 сек\n","Среднее значение функции потерь на обучении 0.023065595327229318\n","Среднее значение функции потерь на валидации 1.0005470140505646\n","Новая лучшая модель!\n","\n","Эпоха 14\n","Эпоха: 354 итераций, 0.76 сек\n","Среднее значение функции потерь на обучении 0.019530061214088887\n","Среднее значение функции потерь на валидации 0.9915656006689799\n","Новая лучшая модель!\n","\n","Эпоха 15\n","Эпоха: 354 итераций, 0.75 сек\n","Среднее значение функции потерь на обучении 0.01649772615098305\n","Среднее значение функции потерь на валидации 0.9758863211688349\n","Новая лучшая модель!\n","\n","Эпоха 16\n","Эпоха: 354 итераций, 0.73 сек\n","Среднее значение функции потерь на обучении 0.013959536465716228\n","Среднее значение функции потерь на валидации 0.9762190796308599\n","\n","Эпоха 17\n","Эпоха: 354 итераций, 0.75 сек\n","Среднее значение функции потерь на обучении 0.012367881236316394\n","Среднее значение функции потерь на валидации 0.9614354176288944\n","Новая лучшая модель!\n","\n","Эпоха 18\n","Эпоха: 354 итераций, 0.73 сек\n","Среднее значение функции потерь на обучении 0.010551378728774518\n","Среднее значение функции потерь на валидации 0.9536970996503102\n","Новая лучшая модель!\n","\n","Эпоха 19\n","Эпоха: 354 итераций, 0.72 сек\n","Среднее значение функции потерь на обучении 0.009276586619605664\n","Среднее значение функции потерь на валидации 0.9553902922040325\n","\n","Эпоха 20\n","Эпоха: 354 итераций, 0.74 сек\n","Среднее значение функции потерь на обучении 0.00806020985759984\n","Среднее значение функции потерь на валидации 0.9670731623546552\n","\n","Эпоха 21\n","Эпоха: 354 итераций, 0.73 сек\n","Среднее значение функции потерь на обучении 0.007328501263880671\n","Среднее значение функции потерь на валидации 0.940357809602204\n","Новая лучшая модель!\n","\n","Эпоха 22\n","Эпоха: 354 итераций, 0.73 сек\n","Среднее значение функции потерь на обучении 0.006772764367485514\n","Среднее значение функции потерь на валидации 0.9329071005774756\n","Новая лучшая модель!\n","\n","Эпоха 23\n","Эпоха: 354 итераций, 0.73 сек\n","Среднее значение функции потерь на обучении 0.005589803532134258\n","Среднее значение функции потерь на валидации 0.9329797934930203\n","\n","Эпоха 24\n","Эпоха: 354 итераций, 0.72 сек\n","Среднее значение функции потерь на обучении 0.005256559551952638\n","Среднее значение функции потерь на валидации 0.9690160364922831\n","\n","Эпоха 25\n","Эпоха: 354 итераций, 0.73 сек\n","Среднее значение функции потерь на обучении 0.004769139289283746\n","Среднее значение функции потерь на валидации 0.943762775194847\n","\n","Эпоха 26\n","Эпоха: 354 итераций, 0.72 сек\n","Среднее значение функции потерь на обучении 0.004408708987474747\n","Среднее значение функции потерь на валидации 0.9343350825168318\n","\n","Эпоха 27\n","Эпоха: 354 итераций, 0.73 сек\n","Среднее значение функции потерь на обучении 0.0041216855921643114\n","Среднее значение функции потерь на валидации 0.9609600280301046\n","\n","Эпоха 28\n","Эпоха: 354 итераций, 0.72 сек\n","Среднее значение функции потерь на обучении 0.004165094240984911\n","Среднее значение функции потерь на валидации 0.9498705243912794\n","Epoch    29: reducing learning rate of group 0 to 5.0000e-02.\n","\n","Эпоха 29\n","Эпоха: 354 итераций, 0.73 сек\n","Среднее значение функции потерь на обучении 0.00323216373835543\n","Среднее значение функции потерь на валидации 0.9344181765691709\n","\n","Эпоха 30\n","Эпоха: 354 итераций, 0.71 сек\n","Среднее значение функции потерь на обучении 0.002957751256075693\n","Среднее значение функции потерь на валидации 0.9425015765226493\n","\n","Эпоха 31\n","Эпоха: 354 итераций, 0.74 сек\n","Среднее значение функции потерь на обучении 0.0028751204439799306\n","Среднее значение функции потерь на валидации 0.9348566154554739\n","\n","Эпоха 32\n","Эпоха: 354 итераций, 0.73 сек\n","Среднее значение функции потерь на обучении 0.002601818282122324\n","Среднее значение функции потерь на валидации 0.9306228053519281\n","Новая лучшая модель!\n","\n","Эпоха 33\n","Эпоха: 354 итераций, 0.73 сек\n","Среднее значение функции потерь на обучении 0.002713365101707326\n","Среднее значение функции потерь на валидации 0.9447156048174632\n","\n","Эпоха 34\n","Эпоха: 354 итераций, 0.74 сек\n","Среднее значение функции потерь на обучении 0.0025348416413673814\n","Среднее значение функции потерь на валидации 0.9425541345598334\n","\n","Эпоха 35\n","Эпоха: 354 итераций, 0.73 сек\n","Среднее значение функции потерь на обучении 0.0026104606819236493\n","Среднее значение функции потерь на валидации 0.9399300308550819\n","\n","Эпоха 36\n","Эпоха: 354 итераций, 0.73 сек\n","Среднее значение функции потерь на обучении 0.002411079751594008\n","Среднее значение функции потерь на валидации 0.9386625610670801\n","\n","Эпоха 37\n","Эпоха: 354 итераций, 0.72 сек\n","Среднее значение функции потерь на обучении 0.002353707103624001\n","Среднее значение функции потерь на валидации 0.9418996386861397\n","\n","Эпоха 38\n","Эпоха: 354 итераций, 0.73 сек\n","Среднее значение функции потерь на обучении 0.0023111867171509643\n","Среднее значение функции потерь на валидации 0.9422608107580976\n","Epoch    39: reducing learning rate of group 0 to 2.5000e-02.\n","\n","Эпоха 39\n","Эпоха: 354 итераций, 0.72 сек\n","Среднее значение функции потерь на обучении 0.0019421245732428873\n","Среднее значение функции потерь на валидации 0.943559743211431\n","\n","Эпоха 40\n","Эпоха: 354 итераций, 0.73 сек\n","Среднее значение функции потерь на обучении 0.0018815843961553485\n","Среднее значение функции потерь на валидации 0.939611838656967\n","\n","Эпоха 41\n","Эпоха: 354 итераций, 0.73 сек\n","Среднее значение функции потерь на обучении 0.0018609494529845387\n","Среднее значение функции потерь на валидации 0.9446352492954772\n","\n","Эпоха 42\n","Эпоха: 354 итераций, 0.71 сек\n","Среднее значение функции потерь на обучении 0.0018222675610091643\n","Среднее значение функции потерь на валидации 0.9422184630470761\n","\n","Эпоха 43\n","Эпоха: 354 итераций, 0.73 сек\n","Среднее значение функции потерь на обучении 0.0017888265336984716\n","Среднее значение функции потерь на валидации 0.9431692603028426\n","Модель не улучшилась за последние 10 эпох, прекращаем обучение\n"]}],"source":["model = nn.Linear(UNIQUE_WORDS_N, UNIQUE_LABELS_N)\n","\n","scheduler = lambda optim: \\\n","    torch.optim.lr_scheduler.ReduceLROnPlateau(optim, patience=5, factor=0.5, verbose=True)\n","\n","best_val_loss, best_model = train_eval_loop(model=model,\n","                                            train_dataset=train_dataset,\n","                                            val_dataset=test_dataset,\n","                                            criterion=F.cross_entropy,\n","                                            lr=1e-1,\n","                                            epoch_n=200,\n","                                            batch_size=32,\n","                                            l2_reg_alpha=0,\n","                                            lr_scheduler_ctor=scheduler)"]},{"cell_type":"markdown","metadata":{"id":"yGiw4sOVi96u"},"source":["На каждой эпохе модель улучшается по валидации. Начиная с 25 эпохи нам не удаётся улучшить модель, поэтому, спустя пять эпох, мы решаем понизить скорость обучения, то есть разделить learning rate на 2. И мы продолжаем обучение с таким learning rate, но, в данном случае, нам это не помогает, и на 35 эпохе мы прекращаем обучение. "]},{"cell_type":"markdown","metadata":{"id":"RpzOzaetDsBb"},"source":["## Оценка качества\n","\n","Для того, чтобы оценить качество модели, нам нужно взять датасет и предсказать классы для объектов из этого датасета с помощью нашей модели. Для того, чтобы это было делать удобно, мы написали специальную функцию \"predict_with_model\". Это простая функция, которая принимает на вход модель, датасет, идентификатор устройства (на котором необходимо производить вычисления), размер батча. И, в цикле, идёт по этому датасету, применяет модель и сохраняет результаты в список, а потом этот список преобразовывает в матрицу. Таким образом, на выходе у нас получается матрица, в которой количество строк соответствует количеству элементов в нашем датасете (количеству примеров в нашем датасете), а количество столбцов соответствует количеству классов. Для целей анализа процесса обучения мы вычисляем значение функции потерь на обучающей выборке, а также оцениваем \"accuracy\", то есть долю верных ответов. Как мы говорили ранее, эта метрика может использоваться только тогда, когда датасет идеально сбалансирован. В противном случае она приводит к завышенной оценке качества работы классификатора. Также мы проделываем все те же действия для валидационной выборки. \n","\n"]},{"cell_type":"code","execution_count":13,"metadata":{"ExecuteTime":{"end_time":"2019-09-12T12:46:25.105663Z","start_time":"2019-09-12T12:46:22.373012Z"},"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":443398,"status":"ok","timestamp":1608394794617,"user":{"displayName":"Дмитрий Крапухин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggc2v_CQHmxf2sl_IRluFRrUm2MTBhbfr-oOZ_PGnk=s64","userId":"11342788103765688294"},"user_tz":-180},"id":"ZhfAx87yDsBd","outputId":"ce56c36b-369e-4db4-af2b-4145597b555d"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 354/353.5625 [00:00<00:00, 534.59it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Среднее значение функции потерь на обучении 0.0022322540171444416\n","Доля верных ответов 0.9994696835778681\n","\n"]},{"name":"stderr","output_type":"stream","text":["236it [00:00, 528.06it/s]                             "]},{"name":"stdout","output_type":"stream","text":["Среднее значение функции потерь на валидации 0.928935170173645\n","Доля верных ответов 0.7681890600106214\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["train_pred = predict_with_model(best_model, train_dataset)\n","\n","train_loss = F.cross_entropy(torch.from_numpy(train_pred),\n","                             torch.from_numpy(train_source['target']).long())\n","\n","print('Среднее значение функции потерь на обучении', float(train_loss))\n","print('Доля верных ответов', accuracy_score(train_source['target'], train_pred.argmax(-1)))\n","print()\n","\n","\n","\n","test_pred = predict_with_model(best_model, test_dataset)\n","\n","test_loss = F.cross_entropy(torch.from_numpy(test_pred),\n","                            torch.from_numpy(test_source['target']).long())\n","\n","print('Среднее значение функции потерь на валидации', float(test_loss))\n","print('Доля верных ответов', accuracy_score(test_source['target'], test_pred.argmax(-1)))"]},{"cell_type":"markdown","metadata":{"id":"8wfP6kNHjWC9"},"source":["Во-первых, мы видим, что обучающую выборку модель практически запомнила — она идеально работает на обучающей выборке. Но на валидационной выборке она даёт верные ответы только в 77% случаев. Значение функции потерь на обучении — порядка нескольких тысячных, а на валидации — почти 1, то есть, значение функции потерь на валидации на два порядка больше, чем значение функции потерь на обучении. Это верный сигнал к тому, что наша модель переобучилась. Но даже, несмотря на такое сильное переобучение, в целом, доля верных ответов не такая плохая."]},{"cell_type":"markdown","metadata":{"id":"7OMfw8V1DsBw"},"source":["# Альтернативная реализация на scikit-learn\n","\n","Давайте теперь посмотрим, как всё то, что мы сейчас описали, реализовать по-быстрому, по простому, с помощью библиотеки scikit-learn. Весь вышеприведённый ноутбук на scikit-learn укладывается всего лишь в 5 строчек — мы задаём параметры алгоритма векторизации текстов, указываем токенизатор, задаём те же параметры для фильтрации токенов по частоте. Говорим, что мы будем использовать логистическую регрессию и обучаем. Давайте посмотрим, какого качества можно достичь с помощью проверенной реализации логистической регрессии."]},{"cell_type":"code","execution_count":14,"metadata":{"ExecuteTime":{"end_time":"2019-09-12T12:46:31.791405Z","start_time":"2019-09-12T12:46:25.107897Z"},"id":"DZDz9FfKDsBx","scrolled":false},"outputs":[],"source":["from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.pipeline import Pipeline\n","from sklearn.linear_model import LogisticRegression\n","\n","sklearn_pipeline = Pipeline((('vect', TfidfVectorizer(tokenizer=tokenize_text_simple_regex,\n","                                                      max_df=MAX_DF,\n","                                                      min_df=MIN_COUNT)),\n","                             ('cls', LogisticRegression())))\n","sklearn_pipeline.fit(train_source['data'], train_source['target']);"]},{"cell_type":"markdown","metadata":{"id":"R3knUnESDsGo"},"source":["## Оценка качества"]},{"cell_type":"code","execution_count":15,"metadata":{"ExecuteTime":{"end_time":"2019-09-12T12:46:35.454567Z","start_time":"2019-09-12T12:46:31.792832Z"},"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":471050,"status":"ok","timestamp":1608394822334,"user":{"displayName":"Дмитрий Крапухин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggc2v_CQHmxf2sl_IRluFRrUm2MTBhbfr-oOZ_PGnk=s64","userId":"11342788103765688294"},"user_tz":-180},"id":"Jc91qEIvDsGo","outputId":"64fa8418-434c-48ae-98c3-80d489b1a232"},"outputs":[{"name":"stdout","output_type":"stream","text":["Среднее значение функции потерь на обучении 2.4954788918565254\n","Доля верных ответов 0.9716280714159449\n","\n","Среднее значение функции потерь на валидации 2.653902258232566\n","Доля верных ответов 0.8190387679235263\n"]}],"source":["sklearn_train_pred = sklearn_pipeline.predict_proba(train_source['data'])\n","sklearn_train_loss = F.cross_entropy(torch.from_numpy(sklearn_train_pred),\n","                                                 torch.from_numpy(train_source['target']))\n","print('Среднее значение функции потерь на обучении', float(sklearn_train_loss))\n","print('Доля верных ответов', accuracy_score(train_source['target'], sklearn_train_pred.argmax(-1)))\n","print()\n","\n","sklearn_test_pred = sklearn_pipeline.predict_proba(test_source['data'])\n","sklearn_test_loss = F.cross_entropy(torch.from_numpy(sklearn_test_pred),\n","                                                torch.from_numpy(test_source['target']))\n","print('Среднее значение функции потерь на валидации', float(sklearn_test_loss))\n","print('Доля верных ответов', accuracy_score(test_source['target'], sklearn_test_pred.argmax(-1)))"]},{"cell_type":"markdown","metadata":{"id":"r2TQSSJdj2Dx"},"source":["Здесь доля верных ответов на обучающей выборке — поменьше, то есть наша реализация давала accuracy 0.99, реализация scikit-learn даёт 0.96. Но, с другой стороны, на валидации, реализация scikit-learn работает лучше на 4%. Это говорит о том, что модель из scikit-learn переобучилась гораздо меньше. Об этом говорит и гораздо меньший разброс значения функции потерь. Здесь значения функции потерь на обучении и на валидации имеют один порядок и отличаются в первом знаке после запятой."]},{"cell_type":"markdown","metadata":{"id":"92avhYklkVeY"},"source":["В качестве домашнего задания можно попробовать сделать:\n","\n","- изменить способ взвешивания признаков\n","- реализовать взвешивание признаков с помощью точечной взаимной информации (PMI)\n","- изменить способ стандартизации данных (см. начиная с 4:25 на шаге 6), например, запоминая сдвиг и масштаб с обучающей выборки и применяя эти параметры для стандартизации тестовой выборки; и/или стандартизируя каждый столбец по отдельности\n","- добавить регуляризацию\n","- извлекать признаки не через токены, а через N-граммы\n","- добавить стемминг или простую лемматизацию\n","- изменить архитектуру нейросети, например, сделав два слоя вместо одного\n","- проанализировать, как сильно падает качество классификации с уменьшением размера словаря (для фильтрации словаря можно использовать разные эвристики, например, тот же PMI)  "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pOwGnFMTkV4X"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["# Задачи"]},{"cell_type":"markdown","metadata":{"id":"zTDdSQPQL-Im"},"source":["## 1"]},{"cell_type":"markdown","metadata":{"id":"7CeVjqm-vdJA"},"source":["Текст -> Результат.  \n","Контактный телефон: 123123. -> контактный телефон : 123123 .  \n","Что-нибудь надо придумать.\t-> что - нибудь надо придумать .  \n","Значение числа Е=2.7182.\t-> значение числа е = 2.7182 .  \n","Демон123, как тебя зовут в реале?\t-> демон 123 , как тебя зовут в реале ?  \n","-1-.15=-1.15\t-> -1 -.15 = -1.15.   \n","\\- 1 - .15 = -1.15\t-> - 1 - .15 = -1.15.  \n","Какого ;%:?* тут происходит? ->\tкакого ; % : ? * тут происходит ?"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":427,"status":"ok","timestamp":1640004336178,"user":{"displayName":"Дмитрий Крапухин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggc2v_CQHmxf2sl_IRluFRrUm2MTBhbfr-oOZ_PGnk=s64","userId":"11342788103765688294"},"user_tz":-180},"id":"mCKa_WKfFt4j","outputId":"980a920d-70aa-4eb2-886b-a069b66624d9"},"outputs":[{"name":"stdout","output_type":"stream","text":["абв123 - ТЕСТ ПРОЙДЕН\n","123абв - ТЕСТ ПРОЙДЕН\n","-123абв - ТЕСТ ПРОЙДЕН\n","123.23 - ТЕСТ ПРОЙДЕН\n","123,23 - ТЕСТ ПРОЙДЕН\n","Мама мыла -56.035 раму. - ТЕСТ ПРОЙДЕН\n","Мама мыла -56,035 раму. - ТЕСТ ПРОЙДЕН\n","Мама мыла -.035 раму. - ТЕСТ ПРОЙДЕН\n","Мама мыла -,035 раму. - ТЕСТ ПРОЙДЕН\n","Мама (ну та самая) мыла раму! - ТЕСТ ПРОЙДЕН\n","Мама мыла раму. - ТЕСТ ПРОЙДЕН\n","Мама_мыла_раму. - ТЕСТ ПРОЙДЕН\n","Это мама, которая    мыла раму 3раза? Да, всё-таки это - она! Офигеть... - ТЕСТ ПРОЙДЕН\n","вот такая дробь .52 - ТЕСТ ПРОЙДЕН\n","и вот такая дробь -.52 - ТЕСТ ПРОЙДЕН\n","Согласно ст.89 §§ 22-24 и 27 следует... - ТЕСТ ПРОЙДЕН\n","вот такая дробь 0.52 - ТЕСТ ПРОЙДЕН\n","а это вроде и не дробь 25. - ТЕСТ ПРОЙДЕН\n","абв абв123 123 .123 -.123 -.123/123 123/1234 -123/1234 1.123 -1.123 123. -123. ..... ,,,,, - ТЕСТ ПРОЙДЕН\n","Список:\n","    1. Пункт №1* (со звёздочкой) ;\n","    2. Пункт второй [#2] 2 < 3 & 2 > 1;\n","    3.Пункт третий {и последний} - ТЕСТ ПРОЙДЕН\n"," - ТЕСТ ПРОЙДЕН\n"]}],"source":["# Задаем шаблоны в таком порядке: сначала последовательность букв, затем \n","# числа с разделителем и возможным знаком минус, \n","# потом числа целиком из цифр без разделителя, \n","# в конце - непробельный символ.\n","import re\n","TOKENIZE_RE = re.compile(r'[а-яё]+|-?\\.?\\,?\\d+\\.?\\,?\\d+|\\S', re.I)\n","\n","tests = {\n","    'абв123': ['абв', '123'],\n","    '123абв': ['123', 'абв'],\n","    '-123абв': ['-123', 'абв'],\n","    '123.23': ['123.23'],\n","    '123,23': ['123,23'],\n","    'Мама мыла -56.035 раму.': ['мама', 'мыла', '-56.035', 'раму', '.'],\n","    'Мама мыла -56,035 раму.': ['мама', 'мыла', '-56,035', 'раму', '.'],\n","    'Мама мыла -.035 раму.': ['мама', 'мыла', '-.035', 'раму', '.'],\n","    'Мама мыла -,035 раму.': ['мама', 'мыла', '-,035', 'раму', '.'],\n","    'Мама (ну та самая) мыла раму!': ['мама', '(', 'ну', 'та', 'самая', ')', 'мыла', 'раму', '!'],\n","    'Мама мыла раму.': ['мама', 'мыла', 'раму', '.'],\n","    'Мама_мыла_раму.': ['мама', '_', 'мыла', '_', 'раму', '.'],\n","    'Это мама, которая    мыла раму 3раза? Да, всё-таки это - она! Офигеть...': ['это', 'мама', ',', 'которая', 'мыла', 'раму', '3', 'раза', '?', 'да', ',', 'всё', '-', 'таки', 'это', '-', 'она', '!', 'офигеть', '.', '.', '.'],\n","    'вот такая дробь .52': ['вот', 'такая', 'дробь', '.52'],\n","    'и вот такая дробь -.52': ['и', 'вот', 'такая', 'дробь', '-.52'],\n","    'Согласно ст.89 §§ 22-24 и 27 следует...': ['согласно', 'ст', '.89', '§', '§', '22', '-24', 'и', '27', 'следует', '.', '.', '.'],\n","    'вот такая дробь 0.52': ['вот', 'такая', 'дробь', '0.52'],\n","    'а это вроде и не дробь 25.': ['а', 'это', 'вроде', 'и', 'не', 'дробь', '25', '.'],          \n","    'абв абв123 123 .123 -.123 -.123/123 123/1234 -123/1234 1.123 -1.123 123. -123. ..... ,,,,,': \\\n","    ['абв', 'абв', '123', '123', '.123', '-.123', '-.123', '/', '123', \n","     '123', '/', '1234', '-123', '/', '1234', '1.123', '-1.123', '123', \n","     '.', '-123', '.', '.', '.', '.', '.', '.', ',', ',', ',', ',', ','],\n","    \"\"\"Список:\n","    1. Пункт №1* (со звёздочкой) ;\n","    2. Пункт второй [#2] 2 < 3 & 2 > 1;\n","    3.Пункт третий {и последний}\"\"\": \\\n","    ['список', ':', '1', '.', 'пункт', '№', '1', '*', '(', 'со', 'звёздочкой',\n","     ')', ';', '2', '.', 'пункт', 'второй', '[', '#', '2', ']', '2', '<', '3',\n","     '&', '2', '>', '1', ';', '3', '.', 'пункт', 'третий', '{', 'и', 'последний', '}'],\n","    '': []\n","}\n","\n","def tokenize(txt):\n","    return TOKENIZE_RE.findall(txt)\n","\n","\n","for test in tests:\n","    tokens = tokenize(test.strip().lower())\n","    try:\n","        assert tokens == tests[test]\n","        print(f'{test} - ТЕСТ ПРОЙДЕН')\n","    except AssertionError:\n","        print(f'{test} - ТЕСТ ПРОВАЛЕН')\n","        print('Ожидается:')\n","        print(tests[test])\n","        print('Получено:')\n","        print(tokens)"]},{"cell_type":"markdown","metadata":{"id":"Gqq2eo2wbrwv"},"source":["## 2\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1171,"status":"ok","timestamp":1640008439057,"user":{"displayName":"Дмитрий Крапухин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggc2v_CQHmxf2sl_IRluFRrUm2MTBhbfr-oOZ_PGnk=s64","userId":"11342788103765688294"},"user_tz":-180},"id":"Q3jZV0mdAwAk","outputId":"99d16714-75e4-4924-ec24-659f6b8f09c4"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'казнить': 2, 'нельзя': 5, 'помиловать': 3, 'наказывать': 1, 'освободить': 2, 'не': 1, 'обязательно': 1}\n","{'казнить': 2, 'нельзя': 3, 'помиловать': 3, 'наказывать': 1, 'освободить': 2, 'не': 1, 'обязательно': 1}\n","{'казнить': 0.5, 'нельзя': 0.75, 'помиловать': 0.75, 'наказывать': 0.25, 'освободить': 0.5, 'не': 0.25, 'обязательно': 0.25}\n","[('наказывать', 0.25), ('не', 0.25), ('обязательно', 0.25), ('казнить', 0.5), ('освободить', 0.5), ('нельзя', 0.75), ('помиловать', 0.75)]\n","наказывать не обязательно казнить освободить нельзя помиловать\n","0.25 0.25 0.25 0.5 0.5 0.75 0.75\n"]}],"source":["from collections import Counter\n","doclist = ['Казнить нельзя, помиловать. Нельзя наказывать.',\n","           'Казнить, нельзя помиловать. Нельзя освободить.',\n","           'Нельзя не помиловать.',\n","           'Обязательно освободить.',]\n","word_count = {}\n","for word in doclist:\n","    words = [x for x in word.lower().split()]\n","    words_clean = [x.replace(',','').replace('.','') for x in words]\n","    for w in words_clean:\n","        if word_count.get(w):\n","            word_count[w] += 1\n","        else:\n","            word_count[w] = 1\n","\n","print(word_count)\n","\n","doc_count = {}\n","for key in word_count.keys():\n","    for word in doclist:\n","        words = [x for x in word.lower().split()]\n","        words_clean = [x.replace(',','').replace('.','') for x in words]\n","        if key in words_clean:\n","            if doc_count.get(key):\n","                doc_count[key] += 1\n","            else:\n","                doc_count[key] = 1\n","print(doc_count)\n","\n","DF = dict()\n","for k,v in doc_count.items():\n","    DF[k] = v/len(doclist)\n","print(DF)\n","\n","answer = sorted(DF.items(), key=lambda x:x[1])\n","print(answer)\n","answer_1 = []; \n","answer_2 = [];\n","for k, v in answer:\n","    answer_1.append(k)\n","    answer_2.append(str(v))\n","    \n","print(\" \".join(answer_1))\n","print(\" \".join(answer_2))"]},{"cell_type":"markdown","metadata":{"id":"zr5xwMKK-Rfu"},"source":["## 3 (ver. 1)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1097,"status":"ok","timestamp":1640088496621,"user":{"displayName":"Дмитрий Крапухин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggc2v_CQHmxf2sl_IRluFRrUm2MTBhbfr-oOZ_PGnk=s64","userId":"11342788103765688294"},"user_tz":-180},"id":"hOu6MA9GGCVa","outputId":"6a0a69d8-d800-4db5-8b2c-2e31550c6794"},"outputs":[{"data":{"text/plain":["[['казнить', 'нельзя', 'помиловать', 'нельзя', 'наказывать'],\n"," ['казнить', 'нельзя', 'помиловать', 'нельзя', 'освободить'],\n"," ['нельзя', 'не', 'помиловать'],\n"," ['обязательно', 'освободить']]"]},"metadata":{},"output_type":"display_data"}],"source":["import numpy as np \n","from collections import Counter\n","doclist = ['Казнить нельзя, помиловать. Нельзя наказывать.',\n","           'Казнить, нельзя помиловать. Нельзя освободить.',\n","           'Нельзя не помиловать.',\n","           'Обязательно освободить.',]\n","\n","doclist_clean = []\n","for string in doclist:\n","    string_clean = []\n","    for word in string.split():\n","        string_clean += [word.lower().replace(',','').replace('.','') ]\n","    doclist_clean += [string_clean]\n","doclist_clean"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1640088496621,"user":{"displayName":"Дмитрий Крапухин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggc2v_CQHmxf2sl_IRluFRrUm2MTBhbfr-oOZ_PGnk=s64","userId":"11342788103765688294"},"user_tz":-180},"id":"mZzfdCPLpgrz","outputId":"4979e56d-5297-4232-e3b9-ccacd4e33915"},"outputs":[{"data":{"text/plain":["[{'казнить': 0.2, 'нельзя': 0.4, 'помиловать': 0.2, 'наказывать': 0.2},\n"," {'казнить': 0.2, 'нельзя': 0.4, 'помиловать': 0.2, 'освободить': 0.2},\n"," {'нельзя': 0.3333333333333333,\n","  'не': 0.3333333333333333,\n","  'помиловать': 0.3333333333333333},\n"," {'обязательно': 0.5, 'освободить': 0.5}]"]},"metadata":{},"output_type":"display_data"}],"source":["tf = []\n","for string in doclist_clean:\n","    word_count = {}\n","    for w in string:\n","        if word_count.get(w):\n","            word_count[w] += 1/len(string)\n","        else:\n","            word_count[w] = 1/len(string)\n","    tf += [word_count]\n","tf"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1640088497479,"user":{"displayName":"Дмитрий Крапухин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggc2v_CQHmxf2sl_IRluFRrUm2MTBhbfr-oOZ_PGnk=s64","userId":"11342788103765688294"},"user_tz":-180},"id":"RIeZFqDIpsDU","outputId":"636f7fed-5013-405e-a1c4-e63b74a64d9d"},"outputs":[{"name":"stdout","output_type":"stream","text":["idf_dict"]},{"data":{"text/plain":["{'обязательно': 4.0,\n"," 'не': 4.0,\n"," 'казнить': 2.0,\n"," 'освободить': 2.0,\n"," 'наказывать': 4.0,\n"," 'нельзя': 1.3333333333333333,\n"," 'помиловать': 1.3333333333333333}"]},"metadata":{},"output_type":"display_data"}],"source":["idf_dict = {}\n","word_set = set([word for sublist in doclist_clean for word in sublist])\n","for key in word_set:\n","    strings_number = sum([key in string for string in doclist_clean])\n","    idf = len(doclist_clean)/strings_number\n","    idf_dict[key] =  idf\n","print('idf_dict',end='')\n","idf_dict"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1640088498027,"user":{"displayName":"Дмитрий Крапухин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggc2v_CQHmxf2sl_IRluFRrUm2MTBhbfr-oOZ_PGnk=s64","userId":"11342788103765688294"},"user_tz":-180},"id":"L4SyTKzQpdQa","outputId":"9f0f7ccc-b250-4688-eb4f-a659cbde7a81"},"outputs":[{"data":{"text/plain":["[{'казнить': 0.3646431135879092,\n","  'нельзя': 0.4486296488282838,\n","  'помиловать': 0.2430954090586061,\n","  'наказывать': 0.7292862271758184},\n"," {'казнить': 0.3646431135879092,\n","  'нельзя': 0.4486296488282838,\n","  'помиловать': 0.2430954090586061,\n","  'освободить': 0.3646431135879092},\n"," {'нельзя': 0.38357609660237446,\n","  'не': 1.1507282898071234,\n","  'помиловать': 0.38357609660237446},\n"," {'обязательно': 1.6218604324326575, 'освободить': 0.8109302162163288}]"]},"metadata":{},"output_type":"display_data"}],"source":["tfidf = []\n","for string in tf:\n","    tfidf_single = {}\n","    for k in string.keys():\n","        tfidf_single[k] = np.log(string[k]+1)*idf_dict[k]\n","    tfidf += [tfidf_single]\n","\n","tfidf"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1640088498027,"user":{"displayName":"Дмитрий Крапухин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggc2v_CQHmxf2sl_IRluFRrUm2MTBhbfr-oOZ_PGnk=s64","userId":"11342788103765688294"},"user_tz":-180},"id":"1CbBOkcbw8_I","outputId":"16cab4ac-9be8-4c7b-cbce-e14d4a4fb775"},"outputs":[{"data":{"text/plain":["{'обязательно': 0.4054651081081644,\n"," 'не': 0.28768207245178085,\n"," 'казнить': 0.1823215567939546,\n"," 'освободить': 0.2938933324510595,\n"," 'наказывать': 0.1823215567939546,\n"," 'нельзя': 0.3202088485647355,\n"," 'помиловать': 0.21744172867989667}"]},"metadata":{},"output_type":"display_data"}],"source":["mean_dict = {}\n","for key in word_set:\n","    sm = 0\n","    for string in tfidf:\n","        if string.get(key):\n","            sm += string.get(key)\n","    mean_dict[key] = sm/4\n","mean_dict\n"]},{"cell_type":"markdown","metadata":{"id":"Wp-Dowv5AJl5"},"source":["## 3 (ver. 2)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":231,"status":"ok","timestamp":1640088753169,"user":{"displayName":"Дмитрий Крапухин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggc2v_CQHmxf2sl_IRluFRrUm2MTBhbfr-oOZ_PGnk=s64","userId":"11342788103765688294"},"user_tz":-180},"id":"haVuycwI6DLd","outputId":"e9888541-3f76-47cd-bfca-d91a319ec7fc"},"outputs":[{"data":{"text/plain":["[['казнить', 'нельзя', 'помиловать', 'нельзя', 'наказывать'],\n"," ['казнить', 'нельзя', 'помиловать', 'нельзя', 'освободить'],\n"," ['нельзя', 'не', 'помиловать'],\n"," ['обязательно', 'освободить']]"]},"metadata":{},"output_type":"display_data"}],"source":["doclist_clean"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":362,"status":"ok","timestamp":1640092004432,"user":{"displayName":"Дмитрий Крапухин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggc2v_CQHmxf2sl_IRluFRrUm2MTBhbfr-oOZ_PGnk=s64","userId":"11342788103765688294"},"user_tz":-180},"id":"BoKesjoKzKHo","outputId":"9e6a8f10-c01d-4229-bb97-30b54d7d32b0"},"outputs":[{"name":"stdout","output_type":"stream","text":["['казнить', 'наказывать', 'не', 'нельзя', 'обязательно', 'освободить', 'помиловать']\n"]},{"data":{"text/plain":["array([[1, 1, 0, 2, 0, 0, 1],\n","       [1, 0, 0, 2, 0, 1, 1],\n","       [0, 0, 1, 1, 0, 0, 1],\n","       [0, 0, 0, 0, 1, 1, 0]])"]},"metadata":{},"output_type":"display_data"}],"source":["word_set = sorted(word_set)\n","word_np = []\n","for word in word_set:\n","    word_single = []\n","    for string in range(len(doclist)):\n","        word_single_n = 0\n","        for words in doclist_clean[string]:\n","            word_single_n += int(word == words)\n","        word_single += [word_single_n]\n","    word_np += [word_single]\n","print(word_set)\n","word_array = np.array(word_np).T\n","word_array\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":238,"status":"ok","timestamp":1640092006782,"user":{"displayName":"Дмитрий Крапухин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggc2v_CQHmxf2sl_IRluFRrUm2MTBhbfr-oOZ_PGnk=s64","userId":"11342788103765688294"},"user_tz":-180},"id":"29HWBqxg-tBz","outputId":"a9f210c6-dd2e-4135-81ac-28840e71ef1c"},"outputs":[{"data":{"text/plain":["array([[0.2       , 0.2       , 0.        , 0.4       , 0.        ,\n","        0.        , 0.2       ],\n","       [0.2       , 0.        , 0.        , 0.4       , 0.        ,\n","        0.2       , 0.2       ],\n","       [0.        , 0.        , 0.33333333, 0.33333333, 0.        ,\n","        0.        , 0.33333333],\n","       [0.        , 0.        , 0.        , 0.        , 0.5       ,\n","        0.5       , 0.        ]])"]},"metadata":{},"output_type":"display_data"}],"source":["tf = np.divide(word_array,word_array.sum(axis=1).reshape(-1,1))\n","tf"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":382,"status":"ok","timestamp":1640093369055,"user":{"displayName":"Дмитрий Крапухин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggc2v_CQHmxf2sl_IRluFRrUm2MTBhbfr-oOZ_PGnk=s64","userId":"11342788103765688294"},"user_tz":-180},"id":"JCCOmWib4s1Q","outputId":"ab2cf749-a3bb-4a3e-85d3-0ac48251d179"},"outputs":[{"name":"stdout","output_type":"stream","text":["['казнить', 'наказывать', 'не', 'нельзя', 'обязательно', 'освободить', 'помиловать']\n","[[1 1 0 1 0 0 1]\n"," [1 0 0 1 0 1 1]\n"," [0 0 1 1 0 0 1]\n"," [0 0 0 0 1 1 0]]\n"]},{"data":{"text/plain":["array([2.        , 4.        , 4.        , 1.33333333, 4.        ,\n","       2.        , 1.33333333])"]},"metadata":{},"output_type":"display_data"}],"source":["print(word_set)\n","word_in_string = np.array(word_array != 0).astype(int)\n","print(word_in_string) \n","# idf = word_in_string*(1/(word_in_string.sum(axis=0)/word_in_string.shape[0]))\n","idf = 1/(word_in_string.sum(axis=0)/word_in_string.shape[0])\n","idf"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":292,"status":"ok","timestamp":1640093387664,"user":{"displayName":"Дмитрий Крапухин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggc2v_CQHmxf2sl_IRluFRrUm2MTBhbfr-oOZ_PGnk=s64","userId":"11342788103765688294"},"user_tz":-180},"id":"q3s9LA2A4LQu","outputId":"e2a58870-df9e-4ce1-fd3a-4b4a70287497"},"outputs":[{"data":{"text/plain":["array([[0.36464311, 0.72928623, 0.        , 0.44862965, 0.        ,\n","        0.        , 0.24309541],\n","       [0.36464311, 0.        , 0.        , 0.44862965, 0.        ,\n","        0.36464311, 0.24309541],\n","       [0.        , 0.        , 1.15072829, 0.3835761 , 0.        ,\n","        0.        , 0.3835761 ],\n","       [0.        , 0.        , 0.        , 0.        , 1.62186043,\n","        0.81093022, 0.        ]])"]},"metadata":{},"output_type":"display_data"}],"source":["ltfidf = np.log(tf+1)*idf\n","ltfidf"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":263,"status":"ok","timestamp":1640093389917,"user":{"displayName":"Дмитрий Крапухин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggc2v_CQHmxf2sl_IRluFRrUm2MTBhbfr-oOZ_PGnk=s64","userId":"11342788103765688294"},"user_tz":-180},"id":"_K6wdzAZCIuO","outputId":"3c0766fe-00ee-4f15-c604-caf97ef08273"},"outputs":[{"data":{"text/plain":["array([0.18232156, 0.18232156, 0.28768207, 0.32020885, 0.40546511,\n","       0.29389333, 0.21744173])"]},"metadata":{},"output_type":"display_data"}],"source":["ltfidf_mean = ltfidf.mean(axis=0)\n","ltfidf_mean"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":262,"status":"ok","timestamp":1640093391181,"user":{"displayName":"Дмитрий Крапухин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggc2v_CQHmxf2sl_IRluFRrUm2MTBhbfr-oOZ_PGnk=s64","userId":"11342788103765688294"},"user_tz":-180},"id":"xYRu_lX3CnRk","outputId":"dbe5ce8f-fa29-450e-a639-3c025d06cdee"},"outputs":[{"data":{"text/plain":["array([0.2105268 , 0.36464311, 0.57536414, 0.21566403, 0.81093022,\n","       0.38517496, 0.15937143])"]},"metadata":{},"output_type":"display_data"}],"source":["diff_power = (ltfidf - ltfidf_mean)\n","std = np.sqrt(np.sum(diff_power**2,axis=0)/(ltfidf.shape[0] - 1))\n","std"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":232,"status":"ok","timestamp":1640093932022,"user":{"displayName":"Дмитрий Крапухин","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggc2v_CQHmxf2sl_IRluFRrUm2MTBhbfr-oOZ_PGnk=s64","userId":"11342788103765688294"},"user_tz":-180},"id":"5ZVeymX9E4hG","outputId":"836a6646-b552-4bec-8ce3-5c344acf0e9a"},"outputs":[{"name":"stdout","output_type":"stream","text":["[[ 1.5  -0.5  -0.5   0.87 -0.76  0.6   0.16]\n"," [-0.5  -0.5  -0.5   0.87  0.18  0.6   0.16]\n"," [-0.5   1.5  -0.5  -0.87 -0.76  0.29  1.04]\n"," [-0.5  -0.5   1.5  -0.87  1.34 -1.48 -1.36]]\n","1.5 -0.5 -0.5 0.87 -0.76 0.6 0.16\n","-0.5 -0.5 -0.5 0.87 0.18 0.6 0.16\n","-0.5 1.5 -0.5 -0.87 -0.76 0.29 1.04\n","-0.5 -0.5 1.5 -0.87 1.34 -1.48 -1.36\n"]}],"source":["np.set_printoptions(precision=2)\n","answer = (ltfidf - ltfidf_mean)/std\n","answer = answer[:,[1,2,4,0,5,3,6]]\n","print(answer)\n","\n","\n","# 1.5  -0.5 -0.5 0.87 -0.76 0.60 0.16\n","# -0.5 -0.5 -0.5 0.87 0.18  0.60 0.16\n","\n","for string in answer:\n","    print(' '.join([str(round(x,2)) for x in string]))"]}],"metadata":{"colab":{"collapsed_sections":["Gqq2eo2wbrwv","hJw-RtHdf1Wb"],"name":"task1_20newsgroups.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"},"latex_envs":{"LaTeX_envs_menu_present":true,"autoclose":false,"autocomplete":true,"bibliofile":"biblio.bib","cite_by":"apalike","current_citInitial":1,"eqLabelWithNumbers":true,"eqNumInitial":1,"hotkeys":{"equation":"Ctrl-E","itemize":"Ctrl-I"},"labels_anchors":false,"latex_user_defs":false,"report_style_numbering":false,"user_envs_cfg":false},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":true}},"nbformat":4,"nbformat_minor":0}
